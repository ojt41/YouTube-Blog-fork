{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e691f1-e5d5-4aa4-a53e-6ddcdd23e18d",
   "metadata": {},
   "source": [
    "# Exploring Llama 3.2-Vision (locally) with Ollama\n",
    "\n",
    "Code authored by: Shaw Talebi\n",
    "\n",
    "[Blog link](https://towardsdatascience.com/multimodal-models-llms-that-can-see-and-hear-5c6737c981d3)\n<br>",
    "[Video link](https://youtu.be/Ot2c5MKN_-w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004ada7-b590-45ae-87d8-6968558bd932",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353a71c8-f7c8-4e7d-93df-d3a55cd6b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b99af-7ca5-4628-9377-ddd0f5bf30c7",
   "metadata": {},
   "source": [
    "### pull model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726a200d-921e-4a8e-a38b-4ac38a99ad25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.pull('llama3.2-vision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77b5ab-7cd6-4815-b12c-6f7c58dbb5aa",
   "metadata": {},
   "source": [
    "#### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f526327-a9b5-46a9-9008-e9cb65ed260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image shows a man sitting on a yellow ottoman with his hands clasped together. He is wearing a black polo shirt with a name tag that says \"Shaw\" and a black baseball cap with white text that reads, \"THE DATA ENREPRENEUR.\" The background of the image appears to be an office or lounge area, with a large screen on the wall behind him displaying a presentation slide. There are also several chairs and tables in the background, suggesting that this may be a meeting room or common area for employees to gather and work.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is in this image?',\n",
    "        'images': ['images/shaw-sitting.jpeg']\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfabe75-b6e2-41f4-8538-371192135ae2",
   "metadata": {},
   "source": [
    "#### Image captioning - streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc29b737-6f86-4cee-a7c4-274ba2f10c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image features a man sitting on a yellow chair. He is wearing a black polo shirt with a blue name tag that says \"Shaw\", khaki pants, and a black baseball cap with white text that reads \"THE DATA ENTHUSIAST\". The man has his hands clasped together in front of him and appears to be smiling.\n",
      "\n",
      "The background of the image consists of a room with various pieces of furniture. There is a green ottoman to the left of the yellow chair, and two blue chairs on the right side of the image. A brown table or desk sits behind the man, along with a fireplace. The walls are painted teal blue and have a wooden accent wall featuring holes for hanging items.\n",
      "\n",
      "The overall atmosphere suggests that this may be a modern office space or co-working area where people can come to work, relax, or socialize."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you write a caption for this image?',\n",
    "        'images': ['images/shaw-sitting.jpeg']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d3738-a3c0-4d44-83b8-7f90ddce9cd6",
   "metadata": {},
   "source": [
    "#### Explaining memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ac5d88-6438-4ff6-849b-a888c90d8790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meme depicts Patrick Star from SpongeBob SquarePants, surrounded by various AI tools and symbols. The caption reads \"Trying to build with AI today...\" The image humorously illustrates the challenges of using AI in building projects, implying that it can be overwhelming and frustrating."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you explain this meme to me?',\n",
    "        'images': ['images/ai-meme.jpeg']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73926c2f-826f-4a15-8a67-b5ca4e4b6d9e",
   "metadata": {},
   "source": [
    "#### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e911d1-533d-48ba-923a-549544aba5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription of the text in markdown format:\n",
      "\n",
      "5 AI Projects You Can Build This Weekend (with Python)\n",
      "\n",
      "1. **Resume Optimization (Beginner)**\n",
      "\t* Idea: build a tool that adapts your resume for a specific job description\n",
      "2. **YouTube Lecture Summarizer (Beginner)**\n",
      "\t* Idea: build a tool that takes YouTube video links and summarizes them\n",
      "3. **Automatically Organizing PDFs (Intermediate)**\n",
      "\t* Idea: build a tool to analyze the contents of each PDF and organize them into folders based on topics\n",
      "4. **Multimodal Search (Intermediate)**\n",
      "\t* Idea: use multimodal embeddings to represent user queries, text knowledge, and images in a single space\n",
      "5. **Desktop QA (Advanced)**\n",
      "\t* Idea: connect a multimodal knowledge base to a multimodal model like Llama-3.2-11B-Vision\n",
      "\n",
      "Note that I've added some minor formatting changes to make the text more readable in markdown format. Let me know if you have any further requests."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you transcribe the text from this screenshot in a markdown format?',\n",
    "        'images': ['images/5-ai-projects.jpeg']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
