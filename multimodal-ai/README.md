# Multimodal AI (Series)

In this series, I explore recent developments in multimodal AI systems. Each topic is accompanied by a YouTube video and Medium blog post. For those with code examples, the notebooks are freely available in this repo.

**Topics**
- Multimodal Models (LLMs): [Video](https://youtu.be/Ot2c5MKN_-w) | [Blog](https://towardsdatascience.com/multimodal-models-llms-that-can-see-and-hear-5c6737c981d3) | [Code](https://github.com/ShawhinT/YouTube-Blog/tree/main/multimodal-ai/1-mm-llms)
- Multimodal Embeddings: [Video](https://youtu.be/YOvxh_ma5qE) | [Blog](https://towardsdatascience.com/multimodal-embeddings-an-introduction-5dc36975966f) | [Code](https://github.com/ShawhinT/YouTube-Blog/tree/main/multimodal-ai/2-mm-embeddings)
- Mulitmodal RAG: [Video](https://youtu.be/Y7pNmocrmi8) | [Blog](https://medium.com/towards-data-science/multimodal-rag-process-any-file-type-with-ai-e6921342c903) | [Code](https://github.com/ShawhinT/YouTube-Blog/tree/main/multimodal-ai/3-multimodal-rag)
- Fine-tuning CLIP: [Video](https://youtu.be/W4s6b2ZM6kI) | [Blog](https://medium.com/towards-data-science/fine-tuning-multimodal-embedding-models-bf007b1c5da5) | [Code](https://github.com/ShawhinT/YouTube-Blog/tree/main/multimodal-ai/4-ft-mm-embeddings) | [Dataset](https://huggingface.co/datasets/shawhin/yt-title-thumbnail-pairs) | [Model](https://huggingface.co/shawhin/clip-title-thumbnail-embeddings)
- Fine-tuning FLUX.1: [Video](https://youtu.be/bZr2vhoXSy8) | [Blog](https://shawhin.medium.com/i-trained-flux-1-on-my-face-and-how-you-can-too-bbf0cb3824b0) | [Code](https://github.com/ShawhinT/YouTube-Blog/tree/main/multimodal-ai/5-ft-flux)

### Supplemental Materials

ðŸŽ¥ [YouTube Playlist](https://www.youtube.com/playlist?list=PLz-ep5RbHosXxOAPMThZM1rMec8sV7FcX) <br>
ðŸ“° [Medium Reading List](https://shawhin.medium.com/list/multimodal-ai-fe9521d0e77a)
<br><br>
