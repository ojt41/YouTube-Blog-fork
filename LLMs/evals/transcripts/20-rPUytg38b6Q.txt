hey guys welcome back in this video we'll be talking about the fast fourier transform if you missed the last video it was a bit of a primer introduction on time series signals and the fourier transform so if you missed that definitely check that out and stay tuned for the next video which will kind of extend this idea to a thing called wavelets in the wavelet transform so let's get right into it alright so in the last video we were looking at the fourier transform so if you give it some function in terms of time or space it'll spit out a function in terms of frequency or wave number but most of the time we don't know a functional form of anything we're dealing with in the real world so that's where this idea of the discrete for you transform is very useful like we were looking on the previous video you can have an audio signal so you're playing your favorite record you record it with a microphone and then you can kind of digitize it so you have it in a form that your computer can understand and just how you can digitize your audio signal you can discretize your fourier transform so basically you convert your infinite integral to a sum over n elements so let's take a closer look at this expression so we have f f sub k is equal to the sum over zero to big n minus one uh with x sub n times e to the minus 2 pi i kn over big n so we can define this term let's call it big r sub k n and then we'll set that equal to e to the minus 2 pi i k n divided by big n so we can rewrite our sum in terms of these two elements and then just so we're all on the same page f sub k is an element of what i'll call a column vector x sub n is an element of a column vector and then r sub k n is an element of a matrix so because of the nice properties of matrix multiplication it turns out we can write our sum equivalently as matrix multiplication so that's nice discrete fourier transform is just matrix multiplication but so what how does this help us if we're coming to code this whole thing up we're still going to naively need two for loops to do this double sum this is what they call n squared time so that means the time complexity of this operation will take n square so if you have n elements you're going to have to do n squared computations so we converted our discrete fourier transform to matrix multiplication didn't seem entirely useful but let's just consider a concrete example so let's assume the case where big n equals big k so big n is the size of our column vector where x sub n was an element of and big k is the length of the column vector where f k is an element of that uh so we recall that big r sub k n is equal to e to the 2 pi i k n over big n and then we can just plug it in so we can plug in k and n which will correspond to the indices of our matrix and then big n is equal to four so we plug in those values and we get this matrix on the right here lots of ones lots of minus ones lots of eyes and minus sighs and just looking at it and this matrix is symmetric which means that if you were to swap the rows and columns it would be the same matrix as you started with so that's pretty nice and then this is a special element in the matrix so this element kind of defines the resolution of the discrete fourier transform so we can call it something special like k9 and then we can write our any fourier matrix in terms of this k naught and so this is for the four by four case that we have here and then we can write a few more examples so we have the eight by eight case which uh looks like that big scary matrix on the top there um where k naught is defined on the right hand side here uh we have the four by four case which is the same thing as before and then we have the two by two case and then again k naught is defined as e to the minus two pi i over big n and this extends to any fourier matrix of any size now where n where your fourier matrix has to be square and n gives you the dimensionality of that square matrix so this is the trick so we had the n squared there was a lot of symmetry in our four-year matrices we saw the symmetric matrix there were a lot of redundant terms a lot of ones a lot of minus ones a lot of eyes minus size uh in the 2x2 case the 4x4 case the 8x8 case so it would be really nice if we could leverage this redundancy and symmetry to make our algorithm a bit more efficient and that's exactly the idea behind the fast fourier transform so it's just a fast way of computing the discrete fourier transform and the basic idea is given by this expression so r sub n is our n by n for your matrix any fourier matrix you want that's n by n with the added caveat then n is a power of two that's an important point um and then it turns out you can write any for your matrix uh that's m by n by this expression here i can define these terms individually but i think it's better to just look at a concrete example so again let's return to our four by four case um so here we have i sub big n over two so big n is four so we're looking at i sub two and that's just our two by two identity matrix then we have d sub two which will be the first two diagonal elements of the four by four fourier matrix so we have uh one and minus i respectively and it's a d is defined to be a diagonal matrix so we only keep the diagonal terms from the fourier the four by four fourier matrix and we set everything else to zero and then finally we have the 2x240 matrix which i flashed on the previous slide but it turns out to be this and then the last thing is we have this permutation matrix which is defined by this expression on the right here so basically you if you have a permutation matrix and you multiply it some vector by it it'll just reshuffle the elements in your vector such that the even indexed elements are in the top half and the odd indexed elements on the bottom half okay so it's just plug and chug so we're just plugging in the two by two identity matrix the two by two diagonal matrix and these slots here we plug in the 2x240 matrix here and here and then we have our 4x4 permutation matrix so it's just we're just plugging into this expression um and it may not be immediately obvious but one thing that is promising is that these matrix have a lot of zeros in them which is good we like zeros because that means there's no multiplication to do so on the left hand side again the time complexity is n squared uh but it turns out on the right hand side we don't have n squared time complexity uh so let's take a closer look this permutation matrix is basically free so if you represent your data in a smart way in a nice data structure and use a good algorithm you can basically do this in one step for this first matrix half of it is just an identity matrix basically and then the other half is two diagonal matrices stacked on top of each other so that means half the elements so in this case 40 elements are zero so that means there are only four non-trivial terms we have to worry about so that's where this time complexity of order n comes from and then for this middle matrix half the elements are zero so there's only um two n or eight elements that we have to worry about uh so it turns out as n gets larger and larger this gives you uh you can devise an algorithm that has n log n time complexity uh so the fast fourier transform is just efficient matrix multiplication and so you know it might not be immediately obvious why this is order n log n but i want to give you some uh intuition of what's going on here so let's look at another example we have the 16 by 16 for your matrix which is given we're just plugging into the expression that i showed on the previous slide but there's nothing stopping us from playing the same game for the eight by eight fourier matrix in this middle matrix right here so we can plug that in and then we get a whole bunch more zeros again we go from uh n squared uh time complexity to order n time complexity plus order two n time complexity plus constant time complexity and then we have a 4x440 matrix here so we plug that in and we pick up even more zeros so this is kind of the intuition of what's going on we just recursively apply this matrix multiplication we rewrite our kind of n by n for your matrix in terms of the n over 2 by n over 2 for your matrix and some other terms and we get the n log n time complexity let's try to bring everything together with a concrete example uh so i wrote this example in matlab the code is available at the github page linked here and in the description so we're going to look at the spectrum of an audio signal so in this case i'm just playing the low e string on electric guitar so we can see what that looks like the first step is we read in our audio file then in one line of code in matlab we can apply the fast fourier transform uh here we're just defining some terms we're getting the length of the audio signal we're converting our frequency indices to actual frequency values uh we're computing the two-sided and then from the two-sided the one-sided power spectrum in these lines here and then we just plot everything so at the top we have our audio signal and then the bottom we have our fourier transform so you see we have these kind of discrete peaks at different frequencies so the first one is e2 the low e string 82 hertz so that's what we expected but the cool thing is we're getting exactly or approximately the harmonic series so you're just getting integer multiples of the fundamental so the fundamental frequency in this case is a 282 hertz and then we're just getting integer multiples of it so we start with 82 164 247 330 415 and so on and um you know as someone that is into both physics and music it's really nice when those two fields come together and if you keep going down the harmonic series it turns out you approximately get a major scale which is pretty cool for the physics and slash music personalities that exist inside my brain so that was the fast for you transform if you found this video helpful like subscribe comment i'd love to hear your feedback stay tuned for the next video which will extend this idea to a thing called wavelets in the wavelet transform thanks for watching