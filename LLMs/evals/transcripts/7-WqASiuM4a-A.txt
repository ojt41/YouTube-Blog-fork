hey folks welcome back i'm finally sharing another data science series this video is the first in a three-part series on causality so this idea of causality is mainly based on the work of judea pearl and other researchers working this space pearl actually has a very accessible book out called the book of why geared toward a public audience which i will share in the description in this video i will introduce this idea of causality kind of highlight why traditional statistics isn't the most helpful for understanding it and then finally introducing a new mathematical formulism for understanding causality if you want to dive a bit more into the details check out the blog which i will link in the description and without any further ado let's get into the video well you're probably thinking is why is there a banana on the screen why did i click on this youtube video so we are constantly asking ourselves why why did this happen what is the cause of this or where is this going what's the effect we ask ourselves why to help us craft stories narratives to help us make sense of the world and even though this is a very natural thing for us in understanding and reasoning one of our most powerful tools in statistics is in many ways inadequate for handling cause and effect i'll try to highlight these inadequacies with what i call the three traps of statistics the first trap we have is spurious correlation so this is a statistical correlation with no causal implication so this is like the old saying correlation is not causation and you don't have to look far to find examples of this uh there's a website uh tylervegan.com i have it at the bottom left here and i'll link it in the description as well so here we have a case where we have a spurious correlation so the number of people who drown by falling into a pool correlates with the number of films nicholas cage appeared in so even though this relationship is hilarious it is not causal because we know these two things are not causally uh related to each other correlation is not causation which is something that we all know so sperry's correlation is pretty well known we've all heard correlations not causation uh however trap number two is less well-known and this is simpson's paradox which basically um highlights that how you look at your data matters so let's imagine we do a study for an experimental treatment for heart disease and we collect a bunch of data and we plot it so on the x-axis we have our experimental treatment this could be a drug or behavioral protocol the y-axis we have risk of heart disease and if we look at the plot we would say to ourselves this is a terrible treatment for heart disease it seems the more treatment someone gets the higher the risk of heart disease however if we were to look at two subpopulations say men and women we would get the exact opposite effect so this is summarized nicely by a quote from the man himself judea pearl who said we have a treatment that's good for a man good for a woman but bad for a person here's another example of simpson's paradox but with numbers i took this from the wikipedia page on simpson's paradox so here we have batting averages of derek jeter and david justice over the years 1995 and 1996 so if you look at those two years individually you see that david justice has a better batting average but if you were to combine those two years together derek jeter has a better batting average so again how you look at your data what variables you condition on how you slice your data set has an impact on the conclusions that you can make the final trap of statistics is symmetry which from many perspectives isn't much of a setback but when you're talking about something like causality which is inherently asymmetric it can cause some issues so i'll highlight this by an example let's say we want to model the causal effect between a disease and the severity of symptoms so we model this by a linear expression so y is the severity of our symptom x is the severity of a disease b is all other factors involved and m is just a coefficient that relates x and y but here we have an equal sign so the left left-hand side equals the right-hand side that's what equals means so that means using algebra we can rearrange this expression to get a equation of x in terms of y but here's the problem if we interpret the first equation as diseases cause symptoms then we have to interpret the second equation as symptoms cause disease which is not true we know that's not true so this fundamental symmetry makes algebra perhaps not the best formulism for representing causality so this whole video is supposedly an introduction on causality and i have not defined what it is there are few ways we can define causality the one i like is x causes y if when all confounders are adjusted an intervention in x results in the change in y but an intervention in y does not necessarily change x so i have a little cartoon here let's say we have four variables x w z and y if we intervene in x that means we jiggle it a bit we if x causes y we'll see why jiggle as well however if x causes y but y does not cause x if we intervene in y that is we jiggle y a bit x will not respond so that's causality it is fundamentally asymmetric so if we can't use algebra which relies on symmetry it has this equal sign how can we represent causality so there are the so-called structural causal models which is the kind of way we can represent causality and this consists of two parts one is a directed acyclic graph or a dag so this is a type of graph which comes from the mathematical field of graph theory which consists of vertices these circles here and edges which are these arrows and this is called a directed graph because the lines connecting the different uh circles together have arrowheads on them so that's called a directed graph because the information so to speak flows in one direction and it's acyclic because if you start at a vertex or one of these circles and you follow the arrow heads you'll never return back to the same variable or the same vertex so that's a directed acyclic graph and then there's a second part which are the structural equation models so these are equations that kind of outline the details of the causal connections and so they have these funny looking equal signs here which is basically saying you can't invert these expressions for example you can't invert f sub 1 to get an equation for x in terms of w so these are two key pieces of causality so that was the first video in the three-part series on causality in the next video we will be applying this idea to answering practical real world questions with causal inference if you like this video please consider liking subscribing sharing and commenting your thoughts if you're interested in diving a bit more into the details check out the blog on medium thanks for watching