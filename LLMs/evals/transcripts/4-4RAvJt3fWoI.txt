one of the most common asks I get from clients is how do I build a custom AI chatbot well a few months ago this was something you needed to hire a consultant for today that's not necessarily the case in this video I'll walk through three ways to make a custom AI assistant using a few new releases from open AI I'll review a no code solution via their new gpts feature a python solution via the new assistance API and then finally talk about how to fine-tune an assistant with your data and if you're new here welcome I'm sha I make videos about data science and Entrepreneurship and if you enjoy this content please consider subscribing that's a great no cost way you can support me in all the videos that I make before jumping into the solutions I wanted to quickly differentiate a AI chatbot from a AI assistant while these terms might be used interchangeably the way I like to think about it is that a chatbot is an AI you can have a conversation with while an AI assistant is essentially a chatbot that can use tools a tool could be web browsing it could be a calculator it could be a python interpreter or anything else that helps augment the abilities of a chatbot for example if you have the free version of chat GPT that's a chatbot because it comes with a basic chat functionality without any additional tools however if you have the premium version of chat GPT that's an assistant because it has built-in tools like web browsing and document retrieval turning chatbots into assistance via tools is a powerful way to to expand its capabilities and Effectiveness each of the approaches I talk about in this video can be used to develop an AI assistant and I'll use each of these approaches to build an AI that can respond to my YouTube comments in my likeness which I'll call Shaw GPT the first way I'm going to talk about is the easiest and fastest of the three and it consists of using open ai's new gpts feature so the way to get to that is we go to chat GPT and if you have the premium version version you can go to this Explorer GPT thing here and then you can go look at my gpts and so you can make these custom gpts and they'll appear here so I've already made a version of this Shaw GPT but we'll go ahead and create a new GPT so we can see what this looks like from scratch the thing about this gpts feature is it actually has a chat interface to help you build the AI assistance so not only is this a no code solution it has a step bystep chatbot that will help you build this Ai and so here the GPT Builder says hi I'll help you build a new GPT you can say something like make a creative who helps generate visuals for my new product or make software engineer who helps format my code what would you like to make make a YouTube comment responder let's see what that spits out so you can see that GPT Builder is thinking what's happening is you say this to GPT Builder and then behind the scenes it's going to go ahead and update the instructions for the AI assistant so if you go to the configure tab it'll start filling in these things it'll film the description for the assistant and it'll give it its instructions but let's go back how about the name shot GPT for this GPT does that work that's perfect okay so now it's going to generate a profile picture so it'll use Dolly 2 which is if you're not familiar that's a different AI that instead of generating text like chat GPT it generates images like this one here so that's a cool thing about this gbt Builder it'll generate a profile picture for you you can also just upload your own so I've got a folder here called sha GPT and I've got some different images that we can use so I'll just upload this one and then I'll tell GPT Builder to use this image instead so it's going to use the picture that I uploaded okay so now it's asking for a bit more guidance on how to answer questions outside the expertise in data science and Entrepreneurship so a lot of questions that I get on YouTube aren't actually about data science or entrepreneur preneurship it's usually people just saying great content or something like that just sharing feedback about the video so I'll provide those instructions here okay so here I wrote out instructions for both positive and negative feedback so for positive feedback unrelated to data science Express gratitude for their viewership suggestions or positive feedback given negative feedback thank the viewer rephrase their criticism to convey not convert convey understanding and offer an idea for improvement so these are just some general rules of thumb of how to respond to comments how do you envision sha GPT addressing comments that ask for personal advice on Career changes to Day signs or starting a new business okay so that's a good question I didn't see this last time I made sha GPT through this interface basically when people ask me these questions I tell them that there's no way to just give general advice to anyone without knowing more details and ultimately I only know what's worked for me and I don't necessarily know what's the best choice for other people and that's ultimately up to them but I'm always happy to kind of share my personal experience and what has worked for me so basically going to try to put that into words so that GPT Builder can instruct the model accordingly so the way I tried to convey that is acknowledge that advice for their unique situation is hard to give without a full understanding of their situation however sha GPT can share Shaw's personal experience in case it is helpful for the viewer okay here we go sha GPT will now take the approach that when addressing personal advice inquiries okay so for the Final Touch what tone of L language do you prefer shbg use more formal and professional or casual and friendly casual and friendly and concise I don't like reading a lot of text and so I try not to put that burden on other people so I like to keep text very concise okay sweet feel free to try out shot yout in the preview and see how it responds if there's anything else you'd like to address what would it be okay so we can now give it a whirl how do I start in data science so it gives a very long response doesn't feel very concise starting data science is exciting here's a quick guide to getting you going learn the basics explore online courses Hands-On practice understanding data manipulation diving into machine learning build a portfolio Network and learn continuously so it's casual it's friendly but it's not very concise and doesn't really sound like me the response sounds a lot like what chat GPT would say so if someone reads this comment or response from me they'll be like did sha just copy paste my comment into chat GPT and paste the response so one thing we can do to remove that ambiguity is we can have sh GPT sign off with its name just so people know that it was generated by an AI assistant and not by me personally we can add this to the GPT Builder Okay so it updated the instructions so now it should sign up as Shaw GPT so here's another one can you explain machine learning in simple terms so it gave a pretty good response I like this example just learning by example and experiences it signed off with sha GPT which is good again however the response is way too long I would never respond like this but it's good that it identifies itself I want to move over to this configure tab so I guess some weird things even though it said it was going to use the name sha GPT that never made it over it's still I guess in beta they're still working out some Kinks if anything isn't what you want from this chat interface you can always move over to the configure Tab and just set these things manually so you can set the name of the assistant you can set the description this was autogenerated friendly and informative responder for a data science and Entrepreneurship YouTube channel and then these are the instructions that it generated through the conversation we were having sha GPT is the Casual friendly and concise voice behind a YouTube channel on data science and Entrepreneurship it acknowledges the complexity of giving personalized advice offering insights from Shaw's experiences instead positive feedback is met with gratitude and criticism is handled constructively sha gbt always signs off its messages with its name sha gbt so we can see like a lot of the aspects of the conversation were incorporated into to the instructions another cool thing here is you can set these conversation starters which is nice for the UI you can just put like frequently asked questions for your AI assistant here another really cool thing about gpts is that it has builtin retrieval also called retrieval augmented generation so basically what this means is you can equip your assistant with specialized knowledge that lives in like a PDF or like a Word document or whatever so you can upload those files and the assistant will be able to read those files and incorporate the appropriate context as needed so for example I have a bunch of my articles here so I could upload four ways to quantify fat taals with python I can upload that PDF and then I can ask it a question what is a fat tail it didn't use the PDF in this case it just gave a standard definition of fat Tails as something more extreme than a normal distribution which is a common way of defining bat Tales however it's not the definition of fat tails that I used in that article so another thing we could try is like how can we quantify fat tails so even though it didn't use the definition of fat tailedness from that article it did seamlessly grab the four ways to quantify fat taals from the article the way this is working is that GPT 4 or whatever GPT is underlying these custom gpts here it has been trained to know when to seek outside knowledge if it doesn't know something and so so here it does it pretty seamlessly it feels like it read the article and is like rephrasing it in its own words which is pretty interesting okay so that's knowledge you can upload I think up to like 10 files or something actually probably more the next thing I want to point out are these capabilities so this is what makes these gpts assistant and not just chat Bots it's because it has these extended capabilities such as web browsing image generation and code interpreter so web browsing is exactly what you expect if the user says hey look up something or search the web for some resources or whatever the assistant knows when to call upon this web browsing capability to do that if the user asks the assistant to generate an image it knows to use Dolly and the code interpreter allows the assistant to not only write python code because that's what a chatbot can do but actually run that python code and then return the values to the user or use the values from that computation to inform the response to the user so since for this YouTube responder use case we don't need image generation because you can't have images on YouTube probably don't need a code interpreter either web browsing could be cool to provide additional resources and of course I could upload all these other articles as well so we can just do that to give it more knowledge so we can't bulk upload PDFs at this point but I can go through one by one and upload all of these articles to have it have a bit more specialized knowledge about the actual content that is on the channel the last thing are these actions which are pretty interesting so essentially this allows gpts to make API calls so we can learn more here how to create a GPT okay so this answers one question you can have 20 files uploaded that answers that okay here custom actions you can make third party API calls available to your GPT so that's pretty cool like the canonical case here is like if you want to grab weather data so if you want to get weather from a particular City you can endow the assistant with that capability to look up the weather in a particular City not necessarily for this YouTube comment responder I think here just knowledge and the web browsing is sufficient and so what's cool about these is you can save these gpts and make it available to everyone so you don't have to worry about like deploying your assistant into production because they have this built-in way to do it so you can make it published only to yourself anyone with the link or everyone in the world and then you can select a category so that's pretty cool it got the category right we can uh confirm but I won't because I've already published a version of sha GPT and I spent a bit more time making that one so I don't want to put this example version out there but if you want to interact with sha GPT I'll put a link in the description and you can kind of see for yourself the performance I guess another thing is people say like you can become a millionaire making a GPT or something and I don't know maybe based on my interaction with this interface I don't know how that would work however looking at the other gpts this doesn't feel so much as like a direct way to generate Revenue however it feels like a very big opportunity for these companies or really any company to do promotion and lead generation for their business so like canva being number one on here it's like that's amazing advertising cuz whatever it is they get 100 million daily users of chat GPT that's a lot of eyeballs seeing canva basically for free feels more like an opportunity for these companies to promote their business so like Ali Academy I don't know who that is but I can just like go to her website look at that geni Innovation for Creative so look at that of course this might be a way to generate revenue or whatever but to me it feels more an opportunity for advertising a business or something like that as opposed to direct monetization so just my thoughts on becoming a millionaire with custom gpts okay so when it's all done and published so this is publicly available data scientist GPT for YouTube comments and so we can have these things ready to go so people can ask their data science questions even though it has the Articles available to it that I wrote it doesn't explain it in the way that I explained it in the Articles it kind of gives a more traditional explanation of these things so that's kind of one downside for these custom gpts it still feels a lot like chat GPT but just with slightly different wrapping paper and of course if I spent a lot more time with it I could build something that doesn't sound so much like Chad GPT but the second obvious downside of this is it requires a pre premium version of chat GPT and some people just like a hobbyist or something or you're like a student it may not make sense to pay $2 a month for this and of course this isn't something you can easily integrate into like an app that you make or a website for people to use this they have to come to the chat GPT website so if you don't have premium or you want to incorporate this assistant into some application or some website we can turn to the assistance API which is way number two I'm going to talk about so if you don't have a premium account there's still a no code solution for building a AI assistant and that's through the assistance playground this is a relatively new feature so the playground's been around for a while this is the original version the complete playgrounds you can pick whatever model you like here and it'll just do the auto regressive text generation it'll just keep predicting the next word recursively chat is similar where you can set the model and whatever parameters you like and set the system message and just do like a chat however assistance takes things to the next level where it's a lot like the gpts configure tab that we saw earlier where you can have a name instructions models and then you can add tools to the chat bot so we can really just copy paste all this over so we have sha GPT here are your instructions we can select the model so we can have GPT for Turbo we can add functions so we can write custom functions here it has to be in a particular format shown here so you need to give it a name for the function you need to describe it in words and then you need to provide the inputs for the function so what information does the assistant need to pass to the function in order to generate an output also has the code interpreter so it can not only write python code it can run the python code receive a response and then it also has retrieval like we saw with the custom GPT the one thing missing here is web browsing natively I think that's something that they're going to add later but as of right now it's January 30th 2024 web browsing is not integrated into the assistance playground or assistance API but we do have functions code interpreter retrieval and we can also add files like we did before let's see if we can do bulk file upload here aha we can there we go bulk file upload available in the playground okay so we can just see how this works we can do like a side by-side comparison so we'll ask sha GPT what is fat tailedness and we'll ask sha GPT playground what is fat tailedness okay so again it's kind of giving the more traditional definition of something fat tailed has heavier Tails compared to a normal distribution so the response is very similar to what we see over here in the gpt's case so while using the playground to make an assistant in this way seems like a free hack a free version of the custom gpts it has one serious limitation which is that if you only use the playground your assistant is trapped in the playground it's not like the GPT T's interface we saw earlier where you can with one click deploy the assistant onto the chat GPT website so if you want to release the assistant from this playground you want to put it into a website an app or whatever you're going to need to do some coding so let's do that okay so here we got a jupit notebook this is available in the GitHub repository Linked In the description below so if you want this code feel free to grab it there kind of walking through this just importing some modules of course we're going to use the open AI assistance API which is still in b so that's why I put that there you'll need to import your secret key and if you don't have a secret key or don't know how to get your secret key for the open AI API I have a video all about that I'll link it in the description below maybe pop it up on the screen here so you can check that out but you can get a key in a very straightforward way you don't need to be premium user if you just have an open AI account you can get an API key and if you're new you get some free credits to start what I have is a text file called sk. and I'm in importing the secret key from that text file that's the way I like to do it and also importing time for a helper function we'll see in a second here the first thing we need to do is to set up the client so set up communication with the opening eye API so you just do that oneline in code I make a quick helper function because when we're using these assistants they have to think so it takes time for us to get a response from the API so what this function does is weights and periodically grabs the status of the API call and then when it's done it'll move on to the next step of the code and it'll tell us how long it took to do that so that's just like a helper function it's not super important this is kind of what we were doing before in the playground and in the gpt's chat interface but now we're going to do it in Python the first step is defining our instructions so this is essentially the system message so I'm using the same thing we had in the playground here sha GPT functioning as a virtual data science consultant on YouTube blah blah blah blah blah just copy paste that here and then we can create the assistant using this chunk of code here the way this works is we created this client object earlier and then we're going to be accessing the assistance API and we're just going to use this create method what that allows us to do is create an assistant set its name its description its instructions and the model that we want to use notice that this is everything we said here the name description isn't here but you can set the description via the assistance API the instructions and the model so it's all the same and then I just print the assistant not that it gives us a whole lot of useful information but it's just this object that looks like this okay in order to talk to the assistant you can set up this thread object which is new in the assistance API compared to the chat completion API which is what I talked about in a previous video we can create this thread which is just like a back and forth conversation it helps avoid doing this boiler plate code of keeping track of what the system message is and what the user says and what the assistant says and what the user says and assistant says so on and so forth It's all handled by the thread so that's super convenient you can generate the user message so here I just put something like great content thank you so that's a comment and then we can add this comment to the thread using this so we have to specify which thread we're going to add the message to which role is saying the message and then the content of the message we get the thread idea from here role is user and then content is here then finally we can send the message to the assistant to generate a response the way that works is you use this method here so we're in the threads module the runs subm module and we're going to use this create method to create a run which is just an API call essentially so we'll need to provide the thread ID which we just added this user message to and we need to provide the assistant ID and so where this comes from is the assistant object we made ear earlier if we do that we can run that and then it'll take a few seconds to run so that's why I run this helper function I made and then once the run is complete we can view that returned object so it took about 5 Seconds to do that first one so actually we can just like run this whole thing I think that's fine yeah we'll just run this whole thing all right so it took less time this time so it took about 3 seconds to run so automatically when we do this run when the assistant generates the response it gets automatically added to the thread so we don't have to do anything extra so all we can do is grab the messages from this thread that was just updated by the assistant and we can print the most recent message in the thread so the response from the assistant is you're welcome I'm glad you found it helpful if you have any more questions or topics you're curious about feel free to ask shot GPZ it signed off correctly which is nice and it is a pretty positive response it captures the sentiment that I convey it's just super long I never talk like this again I don't like reading and I don't want to burden people people with just putting way too much text for them to read I try to keep my responses pretty concise then here I just delete the assistant because what happens is every time you make an assistant it'll pop up here and if you're running this notebook as just like a tutorial or you're running it multiple times debugging or something you're going to have a very long list of assistants here if you don't delete them so that's what this line of code's doing okay so we have this problem that it's giving nice responses but these are just way too long they don't really sound like me one thing we can do to get sha GPT to sound more like me is to give it some examples to learn from so that's what I do here through so-called fuse shot prompting it's essentially where you put a set of examples in the instructions for the assistant so these are real past comments and my responses to these comments and all I did was append this sha GPT to them so it has that format we're looking for and then we just do the same thing we create another system in the same way we name it shot GPT we give it a description we give it the new set of instructions which is is what we defined here and then we Define the model then we can create a new thread so we can talk to the assistant we'll use the same user message great content thank you we'll add the message to the thread so again specifying the thread ID the role of who's saying it and the message then we'll run the thread so we'll send it to the assistant to generate a response by passing in the thread ID and assistant ID and then we'll wait a few seconds for the assistant to generate a response so it took about 3 seconds and then here we're just printing the assistance response so this is what sha GPT says now with the updated instructions to the same exact comment which is you're welcome happy to hear you found it useful shot GPT so that's a lot better I would probably have said just something like glad it was helpful happy to hear you found it useful maybe just one of these to make it a bit more concise cuz you're just saying the same thing in more words but this is a lot better than the original and a lot better than what we were seeing in the playground with the no code Solutions but of course we could have have added the few shot examples in the no code solution and we would have gotten the same results so another thing is technical questions which Chad GPT might respond in a certain way but it may not be the same way that I would respond to that technical question so before we tried adding PDF versions of my article so we could get the context of how I talk about fat tailedness for example but it for whatever reason it wasn't capturing that but now we've done this few shot prompting so let's see how its response changes we're just doing the same exact thing as before we're creating a new thread we're generating a user message so a new thread is as if we opened a new chat GPT chat so it's not going to remember this previous message that's why we're making the new thread add user message to thread so exactly what we did before but now the user message is what is fat tailedness and then we're going to send the message to the assistant we actually don't need this here I haven't gone through and cleaned up this code okay and then we wait for the assistant to process the prompt it takes a bit longer now presumably because it's a longer response it's not just like glad you liked it it's explaining what fat tailedness is and in fact when we print the results this is what we get fat tailedness refers to property probability distribution which tails are fatter than those of a normal distribution okay so it's just giving the same thing as we saw before but notice that we haven't added any documents like we did in the no code Solutions so let's do that I quickly deleted the assistant so we don't have them piling up here's how we can add documents to the assistant so the way that works is like this so we go to the files module and just do this create method so we just use this syntax open which is just opening a file so it's creating a python readable version of the file so we're going to open the file we specify the path which is in this articles folder this is just setting that we'll be opening this file for reading purposes as opposed to writing to it we also need to specify the purpose of this file so we'll say it's for assistant the other option is for fine-tuning which we'll see here in a little bit once we create this file it'll actually populate here but I think it actually got deleted at the end of this notebook so if you were to just run this chunk of Code by itself it's going to create a file in your files tab on your open AI account and actually any assistant that you make can use these files for retrieval all you have to do is provide the file ID as we'll see in a second here but notice where all these came from is when we were in the playground and we uploaded all 10 of these articles with the file uploaded we can create a new assistant that can access that particular file so the way that works is we created this file object and now we can just pass it to the assistant so this is the same exact method we were using before to generate the assistant we said the name the description the instructions but now we're going to define the tools so here we're going to use retrieval as a tool and when we do that we also need to specify the file IDs of the documents that the assistant can use so in this case we're just going to use this one that we created up here but of course if you have a ton of files uploaded here you can use all of them and you just need to specify all of the file IDs in this list here and then finally you specify the model so now that we added retrieval let's try the technical question once again so this one took a lot longer to run took about 45 seconds but we're running it in the same way this is interesting it generated kind of like a mixed response something close to what we were seeing before where it's kind of giving a traditional definition of fat tailedness it's just more fat tailed than a normal distribution but then it's bringing in Concepts from the articles that I provided which is you know fat tailedness ranges from thin tailed to very fat tailed which is almost verbatim from the article and then it adds these four different ways to quantify F tailedness and then it kind of gives some context these methods offer different insights into distributions shape allowing for more detailed understanding of the data's Behavior especially regarding the occurrences and impact of rare and extreme events sha GPT yeah that's pretty interesting that it added in those four heris and gave this dichotomy of thin tailed versus fat tailedness which is something I talk about in the article and then finally I delete the assistant and delete the file if you're running this multiple times you don't accumulate a bunch of files and assistants on your account and then some more resources I'll put all these in the description you can read more about the assistance AP API just from like a high level the documentation which is the API reference breaks down the python side of things and then finally more On Tools so here we just used retrieval but there are two other tools that you can use which are the code interpreter which we saw in both the playground and the gpts and the functions tool which is something we saw in the assistants playground so just going back to that we only used retrieval here but we could have also used the code interpreter and functions so if you want to read more about that I'll provide this link in the description kind of talks about the tools talks about the code interpreter which as it says here allows assistance API to write and run python code so that's on the code interpreter reading images and files okay that's cool and also had the input output logs that's cool knowledge retrieval which is what we did in all the different examples I talked about here and then function calling so this is the cool thing and you can almost have any function with this capability so the way this works is you need to give the name of the function along with a natural language description and then you need to also provide a so-called Json schema which essentially outlines what the inputs of the function are so the assistant knows what information to give to this function in order to get a response at this point we've seen both no code and python ways of generating an assistant and we saw that we can get pretty far by using things like retrieval and fuse shot prompting to improve the assistant performance however there's still still something missing from the assistant responses it just doesn't really feel like something I would say it's very verbose and doesn't quite explain things how I would explain it so to kind of better capture this feel aspect of the assistant responses let's turn to fine-tuning the model unlike the assistance API there's no no code solution for the fine-tuning bit you have to write some python code to fine-tune the model and it requires a bit more work because in order to do fine tuning you need to curate a training data set so here I'm going to kind of walk through the process of how I did that for this YouTube comment responder use case here's another Jupiter notebook example code is on the GitHub repository so check it out if you like here we're importing some modules again importing the open AI python Library importing the secret key in the same way that we did in the previous example and then here importing a few other libraries that we're going to use for the data preparation so again we're going to set up our client and then we're going to need to prepare the training data so this is what makes fine tuning a lot of work it's just acquiring the right data and a important rule in machine learning if there are any rules in machine learning is that data quality is the most important thing not how fancy your model is not how efficient your code is but how good your data is at capturing the thing that you're trying to model and so in this case what I did was I went to my YouTube channel and I took real comments that people left and then real comments that I responded with to create this input output pair so what that looks like is this so I got about 60 comments and responses just copy pasted into this numbers sheet I use numbers because I'm on Mac but you could use Excel to just copy paste it in there and then I exported it as a CSV file just to see some examples of this comment was this was a very thorough introduction to llms and answer answered many questions I had thank you to which I said great to hear glad it was helpful smiley face and of course we can have emojis in here this one says Mr Moneybags over here which was funny so these are just real world comments which we incorporate into F shop prompting but you just can't fit 60 comments and responses into your assistant instructions and if you do it's just going to create this like bulky overhead because the instructions are going to be passed to the assistant every time a thread is initiated so you can imagine that the API calls are just going to become more costly over the long run if you just have a really large instruction set and so that's where fine tuning is helpful in fact open AI has a nice guide on fine tuning here we go common use cases so I'll also put this in the description some common use cases when fine-tuning can improve results setting the style tone format and other qualitative aspects so that's the main motivation for using it in this use case another one's improving reliability at producing the desired output next is correcting failures to follow complex prompts handling many edge cases in specific ways so I guess that's good if there's like a specific prompts or specific situations where the assistant is failing you can just include those in your training data set and it'll learn how to not do that and then performing a new skill or task that's hard to articulate in a prompt and so I like how they put it here the high Lev way to think about it is you want to find tune when it's easier to show not tell kind of like how I was experiencing in the initial no code GPT solution it was asking me these questions and I wasn't necessarily sure how to give the best instructions that's another downside of these no code Solutions is that even though it doesn't require us to write python code it may not be obvious how to give good instructions using natural language showing not telling is just a better way to convey the desired behavior of the assistant going back to the training data prep we have all these comments and responses in the CSV file how however the fine-tuning API doesn't take CSV files as input the data need to be in a very specific format which they talk about here data preparation and Analysis for chat model fine tuning and basically it wants the examples the inputs and outputs in a Json L format so basically it wants it in a text file here's an example it wants it in this format where each row is an example and it consists of a system message a user message and then an assistant message and each line is in the Json format which you can essentially think of as a python dictionary what we need to do is take the CSV file from here and translate it into the proper format in order to use it for fine tuning the way that works here is I initialize these lists to hold all the comments and all the responses then I open the CSV file this is a CSV file YouTube comments. CSV in read mode this like a common syntax tax for reading text files in Python not entirely sure how it actually works but it's something I've used a lot so maybe I should figure out how it works but anyway my understanding is that it handles the opening and closing of the text file but if someone knows better than me drop it in the comments below I'm curious so the first thing we do is use this CSV do reader method to read the file and then what that allows us to do is go through the CSV file line by line and just grab each chunk of text so we're doing that in this for Loop and then we're actually going to skip the first line cuz as you can see here the first line says comment and response so what I'm doing is if the first element of the line is equal to comment to just skip that line that's how I'm skipping the first line here but this will probably be different if your first line isn't comment and response with that first line out of the way the for Loop will go to the next line which is this comment and this response and then what I'm going to do is append the comment to the comment list and then append the response to the response list but also appending this Shaw GPT sign off to the response so we get that desired behavior and of course you can do whatever string manipulation you like here to ensure that the output format of the assistant is whatever you like so here I just have like a simple thing that I'm adding to it but if you want it to be in like a Json format or you want it to have like a particular format you can do whatever string manipulation you like to ensure that it has that format so this will just go all the way through the CSV file just grabbing each comment and each response so we do that it'll save all the comments to the comment list so that's what this is and then it'll have all my responses here or should I say all of sha gpt's responses here and so that's what that looks like you can see emojis and all okay so all we did right now is just put all the comments and responses from the CSV file in a list we haven't actually made it into this Json L format so in order to do that we go to this next cell where we Define our instruction string and we generate each example line by line so the way that works is again going back to this example here each example is a dictionary so it's this key value pair where the key is always messages for whatever reason and then the value is a list which is this list here however the list is a list of dictionaries so it contains three dictionaries the first one corresponding to the system message the second dictionary corresponding to the user's message and the third dictionary corresponding to the assistance response that's the goal that's what we're trying to do here and so the way I do it is Define the system message just once then I just go like index by index through the comment list we go 0 to 58 through the comment list because there are 59 elements and we just generate each of these three dictionaries we generate the system message we generate the user message and then we generate the assistant response and so that's what we're doing here so roll system content is always going to be this instructions string then we have roll user the content is going to be the I element of the comment list and then we have the assistant role and its content is the I element of the response list okay and then we just take these three dictionaries put them into a list and then we create a dictionary I kind of do two things in one step here so sorry if it's unclear but we take this list and create a dictionary with the key is messages and the value is this messages list and then we append this dictionary to the example list so it's matching this format here where each line of this text file is a Json format so it's essentially a dictionary and in the same way each element of this example list is a dictionary okay so there was a issue with with this line of code which I just fixed but what we're doing here is we're going to create our train test split we're going to designate a set of examples for training and then we're going to designate another set of examples for the validation data set and so the way I do that is I randomly generate nine integers between zero and the number of examples minus one and then I use those indices to create a new list for the validation data set so this is just creating a list here where it's going to go through each index in this index list here and it's going to copy that example from example list and put it into Data validation list and since these examples will still be an example list we can go through and iteratively remove them in this for Loop so now at this stage we've got two lists one is called example list which is a list of dictionaries that have the data in the proper format this should have 50 elements it does and then we have have validation data list which is just all the examples in our validation data set and so this is also a list of dictionaries and then we write these examples to two different files so the first one is for the training data and the second one is for the validation data and so kind of in a similar way as before we're opening this text file specifically a Json L file with the right flag on and then we'll just go through each element of example list and dump it into this Json file and then we'll do a new line character so it creates a new line for each example and then we'll do the same exact thing for the validation data set and so once we do that it should create these files here training data. Json L validation data. Json L and then we can upload these files to the open aai API for fine-tuning the way you do that is very similar to what we saw in the previous notebook when we're uploading the article for rag purposes for retrieval purposes so we just use this files. create method meod we open the file which we just saved but now we set the purpose as fine-tune as opposed to assistance do that for both the training and validation data I just put that there so it didn't run the job prematurely and then we can just run the fine-tuning job so the way it works here is we specify the training file the validation file ID which is just a property of these two objects we can set a suffix which is basically some unique identifier or some identifier we can put into the name of the fine-tuning job or name of the model so we can identify it and then we can specify what model we want to use so gp4 is not available for fine tuning the most state-of-the-art advanced model for fine tuning available is gbt 3.5 turbo so that's what we're going to use here and then we can just run this and it'll create this fine-tuning job and then if we go back to our open AI account click on this fine-tuning tab we can see this fine tuning job is running and so this actually kind of takes 15 or 20 minutes it's not something that runs like immediately fast but I did this yesterday so we can just use this model it's kind of like the cooking shows like we already cooked the pasta last night and we're going to eat it in front of you and so yeah it's already set up here so fine tuning jobs running once it finishes running after like 20 minutes or so we'll be able to use it another thing about fine-tuning is that your fine-tune models don't integrate into the assistance API they only work with the chat completions API which means those tools that we could include like retrieval like the code interpreter like the functions which we could just easily add to our system by specifying some keyword argument that's not available natively through the chat completions API so if you want to add rag you want to add tools you got to build out that functionality yourself using python code and of course you can use like Lang chain or llama index or some python library to do that but it's not integrated into chat completions I'm sure at some point the fine-tuning models will be incorporated to the assistance API but at this point it's not available okay so we're going to throw into test comment so we specify the model and then we have to define the messages like this so we Define the system message using the instruction string from before then we pass the user comment just like that then we can run that and then Sean GPT just says thanks it's more concise I'll say that for sure and I don't know if I've ever just said thanks to a comment but this is a pretty brief response let's see what another response looks like and so this is a comment that came in recently it wasn't in the training data set so let's see what the response to this looks like so the comment was I'm typing this after watching half of the video as I'm already amazed with the clarity of explanation exceptional and then sha GPT says wow thanks for the compliment that's pretty good that that is something that I would write I was playing around with this yesterday and it gave like a pretty cheeky answer I don't know if it'll generate that again but I found that funny it was something like thanks for commenting I hope the second half of the video is good and it had some emojis in there and I thought it was funny but now it's like generating responses that I would say oh yeah here we go this is something similar to what I saw yesterday so appreciate the compliment hope the second half doesn't disappoint so now let's see how it handles a technical question again the fine tune model doesn't have retrieval built into it if I wanted to add retrieval to this model I need to use like llama index or Lang chain or something like that to add it in there so let's see how it handles this of course it's not going to describe fat tilted how I did in the articles but it is giving a much more concise and closer response to what I would say compared to what we were seeing before like this monstrosity without the fine tuning there you go that's how you do fine tuning it takes a little bit more effort up front to get together your training data set but honestly it took me about maybe 20 to 30 minutes to manually copy paste those comments into the CSV file maybe another like 20 minutes to write this script to prepare the training data but you don't have to write the script you can just bring in your CSV file and it should be ready to go and then again I'll delete the training in valid ation files hopefully that doesn't ruin the fine-tuning job but it doesn't really matter and then more resources here I'll drop these in the description below so you can take a closer look at it so open AI guide for fine-tuning that was pretty helpful all of open ai's documentation is super clean and easy to understand let's see they have their API reference on fine tuning and then how to prepare your data for fine tuning is also available here so overall impressions of fine tuning I'm honestly pretty impressed I didn't expect it to work as well as it did especially because it only used 50 training examples in grad school if I wanted to train a good model I needed 100,000 examples to train a good predictive model but because of the power of GPT 3.5 turbo it's already a powerful model even fine tuning with just 50 examples results in really good results that's why personally I feel like fine-tuning is probably the biggest Innovation that we've seen in machine learning because if you can find the right base model for your use case and you can just tweak it with just a handful of examples you can get really good results in a fraction of the time that it would have taken you to develop that model from scratch okay so that's basically it we talked about three different ways to build a custom AI assistant using open AI we first talked about the no code solution which allowed you to build an assistant pretty quickly without any python coding next we looked at the assistance API which gave us a pretty straightforward way of creating assistance using python code which we can take and Port over to an application or a website and then finally we saw how we can fine tune an assistant to dramatically change its style and really Come Away with something that has good performance if you want to play around with the no Cod shot GPT I'll provide a link in the description below but if you want to interact with the fine tuned version of sha GPT drop a comment in the comment section below and I'll be sure to respond with shot GPT unless you explicitly don't want me to respond with shbt just let me know and I'll respond as myself so I hope this tutorial was helpful and gave you an idea of which approach might be best for your particular use case of building an AI assistant while open AI does currently have the state of the art large language models for building these things a natural question is how can we build these types of AI assistants using open-source Solutions so that's exactly what I'm going to cover in future videos of this series where we're going to explore both retrieval augmented generation or rag and model fine-tuning using open-source models and if you enjoyed this content this is just one video in a much larger series on using large language models in practice so if you want to learn more check out the series playlist Linked In the description below and in the comment section and as always thank you so much for your time and thanks for watching