[{"index": 14, "video_id": "e3p9-hYxwSQ", "answer": "A", "response": "Analyzing both blog posts against the provided transcript and criteria:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing includes personal anecdotes and insights, such as the author's background in AI and their personal journey, which aligns with the transcript but adds a personal touch.\n  - The structure is somewhat formulaic, but there are informal elements, like the use of emojis and a conversational tone in the \"Final Thoughts\" section.\n  - The post includes a distinctive voice, particularly in the \"About me\" section, where the author shares their personal experience and perspective.\n  - The content includes domain-specific knowledge, such as the mention of specific AI tools and projects, which are not explicitly detailed in the transcript.\n\n- **Content Quality:**\n  - The content is relevant and closely follows the video transcript, maintaining clarity and readability.\n  - The engagement level is moderate, with a clear structure and concise sections.\n  - The title and headers are engaging and not overly generic, fitting the content well.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing is more formal and structured, with less personal insight or anecdotal content compared to Option 1.\n  - The language is consistent and lacks the informal, imperfect elements that might suggest human authorship.\n  - The content closely follows the transcript, with little deviation or additional personal perspective.\n  - The sentence structures are more predictable and formulaic, which is a common pattern in AI-generated content.\n\n- **Content Quality:**\n  - The content is relevant and clear, with a structured approach that mirrors the transcript.\n  - The engagement level is high due to the clear, step-by-step guidance provided.\n  - The title and headers are clear but somewhat generic, lacking a distinctive human touch.\n\n**Decision:**\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, a distinctive voice, and informal elements that suggest human authorship. Option 2, while well-structured and clear, lacks these human elements and appears more formulaic and consistent, which are common traits of AI-generated content.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "After evaluating both blog posts against the provided transcript and criteria, here is the analysis:\n\n**Option 1:**\n- **Signs of Human Authorship:**\n  - The writing style is structured and follows a logical progression, but it lacks personal anecdotes or unique insights that go beyond the transcript.\n  - The language is formal and consistent, with perfect grammar, which is typical of AI-generated content.\n  - The content closely follows the transcript, with little deviation or additional personal perspective.\n  - The use of code snippets and technical instructions is precise and lacks the informal tone or personal touch that might be expected from a human writer sharing personal experiences.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the main points discussed.\n  - The structure is clear, with appropriate section headers and a logical flow.\n  - The title and headers are concise but lack a distinctive or engaging tone that might suggest human creativity.\n\n**Option 2:**\n- **Signs of Human Authorship:**\n  - The writing includes personal insights and reflections, such as the author's background and personal approach to learning AI, which are not present in the transcript.\n  - The language is more informal and conversational, with occasional use of first-person perspective (\"I\u2019d use it to explain confusing buzzwords\").\n  - The content includes unique insights and opinions, such as the author's specific recommendations for different audiences, which go beyond the transcript.\n  - The structure is less formulaic, with varied sentence structures and a more engaging narrative style.\n\n- **Content Quality:**\n  - The content is relevant and covers the main points from the transcript while adding personal insights and recommendations.\n  - The structure is clear, with engaging section headers and a logical progression of ideas.\n  - The title and headers are creative and reflect a personal touch, suggesting human authorship.\n\n**Decision:**\nOption 2 shows more characteristics of authentic human writing, with personal insights, varied sentence structures, and a distinctive voice. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.6762652705061082, "r": 0.6244963738920226, "f": 0.6493506493506493}, "rouge-2": {"p": 0.4, "r": 0.36935483870967745, "f": 0.38406708595387845}, "rouge-l": {"p": 0.4825479930191972, "r": 0.44560838033843675, "f": 0.46334310850439886}}, "rouge_scores_B": {"rouge-1": {"p": 0.6722783389450057, "r": 0.48267526188557613, "f": 0.5619136960600375}, "rouge-2": {"p": 0.250561797752809, "r": 0.17983870967741936, "f": 0.20938967136150236}, "rouge-l": {"p": 0.345679012345679, "r": 0.24818694601128122, "f": 0.28893058161350843}}}, {"index": 19, "video_id": "PFBI-ZfV5rs", "answer": "A", "response": "Analyzing both blog posts against the provided transcript, here are the evaluations:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing style in Option 1 includes informal language and personal insights, such as the anecdote about a friend's candy habit, which adds a human touch.\n  - The post contains varied sentence structures and occasional tangents, like the mention of the \"3 gifts of causal inference,\" which are not directly from the transcript.\n  - The author uses domain-specific knowledge, such as detailed explanations of the do-operator and confounding, which are expanded upon beyond the transcript.\n  - The voice is distinctive, with a conversational tone and personal reflections, such as the comment on the decision to go to grad school.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript, covering causal inference and its applications.\n  - The structure is clear, with sections and headers that are engaging and not overly formal.\n  - The post is complete, covering important points like the do-operator, confounding, and causal effects, with factual accuracy.\n  - The title and headers are concise and engaging, fitting the content well.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing in Option 2 is more formal and structured, with less personality and fewer personal insights.\n  - The language is consistent and lacks the informal, varied sentence structures seen in Option 1.\n  - The content closely follows the transcript, with little additional insight or unique perspective.\n  - The post lacks distinctive voice and perspective, appearing more generic and explanatory.\n\n- **Content Quality:**\n  - The content is relevant and covers the main points of causal inference as discussed in the transcript.\n  - The structure is logical, with clear sections and headers, but it feels more formulaic and less engaging.\n  - The post is complete and factually accurate, but it lacks the engaging and natural tone seen in Option 1.\n  - The title and headers are clear but appear more generic and predictable.\n\n**Decision:**\n\nOption 1 shows more characteristics of authentic human writing, with its informal language, personal anecdotes, varied sentence structures, and distinctive voice. It goes beyond the transcript with unique insights and a conversational tone, indicating human authorship.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1: \"Understanding Causal Inference in Data Science\"\n\n**Signs of Human Authorship:**\n- The writing is structured and follows a clear, logical flow, but it lacks personal anecdotes or unique insights that go beyond the transcript.\n- The language is formal and precise, with perfect grammar and a consistent tone throughout, which are common signs of AI-generated content.\n- The content closely follows the transcript, with little deviation or additional insights that would suggest a human's personal touch or domain-specific knowledge not present in the transcript.\n- The use of images and code snippets is professional and informative but lacks the informal, conversational tone often found in human-authored content.\n\n**Content Quality:**\n- The content is relevant to the video transcript and covers the key points discussed in the video.\n- The structure is clear, with appropriate section headers and a logical progression of ideas.\n- The title and section headers are concise and informative but lack the creativity or distinctiveness that might suggest human authorship.\n\n### Option 2: \"Causal Inference\"\n\n**Signs of Human Authorship:**\n- The writing includes informal language and personal touches, such as the use of humor (\"when your friend\u2019s candy habit gets out of control\") and a conversational tone, which are indicative of human authorship.\n- The author references previous posts and provides links, suggesting a series of posts with a personal narrative or journey, which is more typical of human writers.\n- There are unique insights and explanations that go beyond the transcript, such as the discussion on Bayesian vs. causal networks and the \"3 Gifts of Causal Inference,\" which add depth and a personal perspective.\n- The writing style is varied, with a mix of sentence structures and a distinctive voice that feels more personal and less formulaic.\n\n**Content Quality:**\n- The content is relevant and covers the main points from the transcript while adding additional context and explanations.\n- The structure is clear, with engaging section headers and a logical flow of ideas.\n- The title and section headers are creative and engaging, suggesting a human touch.\n\n### Decision\n\nBased on the analysis, **Option 2** shows more characteristics of authentic human writing. It includes informal language, personal anecdotes, and unique insights that go beyond the transcript, all of which are indicative of human authorship. The writing style is varied and engaging, with a distinctive voice that suggests a human perspective.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.5988372093023255, "r": 0.578110383536015, "f": 0.5882912898619705}, "rouge-2": {"p": 0.25448376151236063, "r": 0.24567150210575572, "f": 0.25}, "rouge-l": {"p": 0.23594961240310078, "r": 0.22778297474275022, "f": 0.23179438362684437}}, "rouge_scores_B": {"rouge-1": {"p": 0.6917989417989417, "r": 0.24462114125350795, "f": 0.3614374568071873}, "rouge-2": {"p": 0.2410596026490066, "r": 0.08516612072999533, "f": 0.12586445366528357}, "rouge-l": {"p": 0.2962962962962963, "r": 0.10477081384471469, "f": 0.15480304077401522}}}, {"index": 17, "video_id": "3JsgtpX_rpU", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing includes informal language and a conversational tone, such as \"This is harder than I thought\u2026\" and \"Bonus: For those interested in implementing something like this\u2026\".\n- **Personal Anecdotes and Insights:** The author shares personal experiences and insights, such as the challenges faced by businesses in using AI and the specific examples of AI use cases in sales.\n- **Varied Sentence Structures:** The writing style varies, with a mix of short and long sentences, and includes rhetorical questions and direct addresses to the reader.\n- **Distinctive Voice and Perspective:** The author provides a unique perspective on AI use cases, emphasizing the importance of solving the right problems and sharing personal opinions on the limitations of chatbots.\n- **Domain-Specific Knowledge:** The post includes specific examples and technical details, such as the use of Python scripts and the challenges of feature engineering, which suggest a deep understanding of the subject matter.\n\n**Content Quality:**\n- **Relevance and Engagement:** The content is highly relevant to the video transcript and engages the reader with practical examples and insights.\n- **Clarity and Readability:** The post is well-structured, with clear section headers and logical flow.\n- **Completeness and Accuracy:** The post covers the key points from the transcript and provides additional context and examples.\n- **Title and Headers:** The title and headers are concise and engaging, avoiding generic or overly explanatory language.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure and Repetitive Patterns:** The post follows a predictable structure with each use case presented in a similar format, which is common in AI-generated content.\n- **Overly Formal and Generic Language:** The language is formal and lacks personality, with phrases like \"In today's rapidly evolving business landscape\" and \"The integration of AI into sales processes can significantly enhance data handling.\"\n- **Exhaustive Lists and Comprehensive Coverage:** The post covers each use case in a comprehensive manner, but lacks focus and depth in individual sections.\n- **Information from Transcript Only:** The content closely follows the transcript without adding unique insights or personal anecdotes.\n- **Perfect Grammar and Consistent Tone:** The writing maintains perfect grammar and a consistent tone throughout, which is typical of AI-generated content.\n\n**Content Quality:**\n- **Relevance and Engagement:** The content is relevant to the transcript but lacks engagement due to its formal tone and lack of personal touch.\n- **Clarity and Readability:** The post is clear and easy to read, but the lack of varied sentence structures makes it less engaging.\n- **Completeness and Accuracy:** The post accurately covers the key points from the transcript but does not provide additional insights or examples.\n- **Title and Headers:** The title and headers are generic and appear AI-generated, lacking creativity and engagement.\n\n### Decision:\n\nBased on the analysis, **Option 1** shows more characteristics of authentic human writing, with its informal language, personal insights, varied sentence structures, and distinctive voice. Therefore, the blog post that is more likely written by a human is:\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "Based on the evaluation criteria provided, here is the analysis of each blog post:\n\n**Option 1:**\n\n- **Signs of Human Authorship vs. AI Generation:**\n  - The writing is highly structured and follows a formulaic pattern, which is a common sign of AI-generated content.\n  - The language is formal and lacks personal anecdotes or unique insights beyond the transcript.\n  - The content sticks closely to the information provided in the transcript, with no significant deviations or personal opinions.\n  - The sentence structures are consistent and lack the varied, imperfect nature typical of human writing.\n  - The use of code snippets and technical explanations is precise and lacks the informal, conversational tone that might be expected from a human writer sharing personal experiences.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the key points discussed.\n  - The clarity and readability are high, but the engagement level is low due to the lack of a distinctive voice.\n  - The structure is appropriate, with clear sections and headers, but the titles and headers are somewhat generic and lack creativity.\n  - The factual accuracy is maintained, and the content is complete in terms of covering the use cases mentioned in the transcript.\n\n**Option 2:**\n\n- **Signs of Human Authorship vs. AI Generation:**\n  - The writing includes personal insights and opinions, such as the mention of client requests and the author's experiences with AI consulting.\n  - There are informal language elements and a conversational tone, which suggest a human touch.\n  - The content includes unique insights and examples that go beyond the transcript, such as the discussion on the challenges of using LLMs and the specific business cases.\n  - The sentence structures are varied, and there are reasonable tangents that add depth to the discussion.\n  - The use of domain-specific knowledge and personal anecdotes adds authenticity to the writing.\n\n- **Content Quality:**\n  - The content is relevant and aligns well with the video transcript, but it also expands on the topics with additional insights.\n  - The clarity and readability are good, and the engagement level is higher due to the personal voice and anecdotes.\n  - The structure is appropriate, with concise and engaging titles and headers that do not appear AI-generated.\n  - The factual accuracy is maintained, and the content is complete, covering the use cases and providing additional context.\n\n**Decision:**\n\nOption 2 shows more characteristics of authentic human writing, with personal insights, varied sentence structures, and a distinctive voice. Therefore, the blog post that appears to be written by a human is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7394366197183099, "r": 0.20083463745435576, "f": 0.3158758375495692}, "rouge-2": {"p": 0.28507367072389495, "r": 0.07739130434782608, "f": 0.12173437286280946}, "rouge-l": {"p": 0.2746478873239437, "r": 0.07459572248304643, "f": 0.11732531108984001}}, "rouge_scores_B": {"rouge-1": {"p": 0.7484885126964933, "r": 0.10763345505129543, "f": 0.1882031012465795}, "rouge-2": {"p": 0.2324455205811138, "r": 0.033391304347826084, "f": 0.058394160583941604}, "rouge-l": {"p": 0.347037484885127, "r": 0.04990436445835507, "f": 0.08726056552143509}}}, {"index": 15, "video_id": "jGn95KDWZMU", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing includes informal language and personal anecdotes, such as the author's journey from grad school to becoming an independent consultant. This adds a personal touch that is less common in AI-generated content.\n- **Personal Anecdotes and Unique Insights:** The author shares personal experiences, like leaving a corporate job and interviewing seasoned freelancers, which adds depth and authenticity.\n- **Varied Sentence Structures:** The writing style varies, with some sentences being longer and more complex, while others are short and direct.\n- **Distinctive Voice and Perspective:** The author uses a conversational tone and includes personal reflections, such as the \"Hammer Problem\" and the importance of problem discovery.\n- **Domain-Specific Knowledge:** The author references specific tools and methodologies (e.g., LSTM, SHAP, Toyota's \"5 Whys\") that suggest a deep understanding of the field.\n\n**Content Quality:**\n- **Relevance to Video Content:** The blog closely follows the video's content but expands with personal insights and experiences.\n- **Clarity and Readability:** The content is clear and easy to follow, with a logical flow.\n- **Engagement and Reader Interest:** The use of personal stories and direct questions to the reader increases engagement.\n- **Completeness of Important Points:** The blog covers all the key points from the video and adds additional context.\n- **Factual Accuracy:** The content aligns with the video transcript and includes accurate references.\n- **Appropriate Structure:** The structure is well-organized, with clear sections and headers.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure and Repetitive Patterns:** The blog follows a predictable structure with a formal tone and lacks the personal touch found in Option 1.\n- **Overly Formal, Safe, or Generic Language:** The language is more formal and lacks the distinctive voice and personal anecdotes present in Option 1.\n- **Exhaustive Lists and Comprehensive Coverage:** The content is comprehensive but lacks focus on personal experiences or unique insights.\n- **Information Explicitly Stated in the Transcript:** The blog closely mirrors the transcript without adding much beyond what is explicitly stated.\n- **Perfect Grammar and Consistent Tone:** The writing is grammatically perfect and maintains a consistent tone throughout, which is typical of AI-generated content.\n- **Generic, Predictable Titles and Headers:** The titles and headers are straightforward and lack the creativity seen in Option 1.\n\n**Content Quality:**\n- **Relevance to Video Content:** The blog is relevant and accurately reflects the video's content.\n- **Clarity and Readability:** The content is clear and well-structured.\n- **Engagement and Reader Interest:** The lack of personal anecdotes and a distinctive voice makes it less engaging.\n- **Completeness of Important Points:** The blog covers the key points but does not add much beyond the transcript.\n- **Factual Accuracy:** The content is factually accurate and aligns with the transcript.\n- **Appropriate Structure:** The structure is logical and well-organized.\n\n### Decision:\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, a distinctive voice, and varied sentence structures. It goes beyond the transcript by adding personal insights and experiences, which are less common in AI-generated content. Therefore, Option 1 is more likely written by a human.\n\n<answer>A</answer>", "answer_swapped": "B", "response_swapped": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Personal Anecdotes and Insights:** The author shares personal experiences, such as their initial focus on technical skills and the shift in perspective after joining a data science team at a large enterprise. This adds a personal touch and unique insight beyond the transcript.\n- **Varied Sentence Structures:** The writing includes varied sentence lengths and structures, which contribute to a more natural flow.\n- **Distinctive Voice:** The author uses a conversational tone, especially in sections like \"Understanding the Importance of Problem Discovery,\" where they discuss their journey and learning experiences.\n- **Domain-Specific Knowledge:** The author references specific methodologies like Toyota's \"Five Whys,\" which shows an understanding of the domain beyond the transcript.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content closely follows the video transcript but adds personal insights and experiences, enhancing the relevance and completeness.\n- **Engagement and Interest:** The use of personal anecdotes and a conversational tone makes the content engaging.\n- **Structure and Clarity:** The post is well-structured with clear section headers and concise paragraphs.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure:** The post follows a predictable structure with a clear introduction, list of questions, and conclusion, which is common in AI-generated content.\n- **Lack of Personal Touch:** While the author mentions leaving a corporate job, the overall tone lacks personal anecdotes or unique insights that go beyond the transcript.\n- **Consistent Tone and Perfect Grammar:** The writing maintains a consistent tone and perfect grammar throughout, which is typical of AI-generated content.\n- **Generic Observations:** The content closely mirrors the transcript without adding significant new insights or personal experiences.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant and covers the points from the transcript but lacks additional depth or personal engagement.\n- **Clarity and Readability:** The post is clear and easy to read, with well-organized sections.\n- **Engagement and Interest:** The lack of personal anecdotes or a distinctive voice makes the content less engaging.\n\n### Decision:\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, varied sentence structures, and a distinctive voice. These elements suggest a human author who has added personal insights and experiences to the content. Option 2, while well-structured and clear, lacks the personal touch and varied writing style indicative of human authorship.\n\n<answer>A</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7816901408450704, "r": 0.7424749163879598, "f": 0.7615780445969125}, "rouge-2": {"p": 0.5306553911205074, "r": 0.5040160642570282, "f": 0.5169927909371782}, "rouge-l": {"p": 0.571830985915493, "r": 0.5431438127090301, "f": 0.5571183533447684}}, "rouge_scores_B": {"rouge-1": {"p": 0.7246207701283547, "r": 0.4153846153846154, "f": 0.5280612244897959}, "rouge-2": {"p": 0.29906542056074764, "r": 0.1713520749665328, "f": 0.2178723404255319}, "rouge-l": {"p": 0.38156359393232203, "r": 0.21872909698996656, "f": 0.2780612244897959}}}, {"index": 12, "video_id": "VKLLyv9cJSQ", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1: How to Freelance as a Data Scientist\n\n**Signs of Human Authorship:**\n- **Personal Anecdotes and Unique Insights:** The author mentions personal experiences, such as sitting down with the panelists and learning from them, which adds a personal touch and suggests human authorship.\n- **Imperfect but Natural Writing:** The writing includes informal language and a conversational tone, such as \"I mentioned that creating YouTube videos and writing Medium articles have significantly driven my inbound leads,\" which feels more personal and less formulaic.\n- **Distinctive Voice and Perspective:** The post includes a distinctive voice, with the author sharing their own experiences and insights, such as the importance of content creation for lead generation.\n- **Varied Sentence Structures:** The writing style varies, with a mix of short and long sentences, and the use of rhetorical questions, which adds to the natural flow of the text.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is highly relevant to the video transcript and covers all major points discussed by the panelists.\n- **Engagement and Reader Interest:** The use of personal anecdotes and insights makes the content engaging and relatable.\n- **Appropriate Structure:** The structure is clear, with well-defined sections and headers that guide the reader through the content.\n\n### Option 2: Navigating the World of Freelance Data Science\n\n**Signs of AI Generation:**\n- **Formulaic Structure and Repetitive Patterns:** The post follows a very structured format with predictable patterns, such as listing strategies and challenges, which is common in AI-generated content.\n- **Overly Formal and Generic Language:** The language is formal and lacks the personal touch or distinctive voice that would suggest human authorship.\n- **Exhaustive Lists and Comprehensive Coverage:** The post covers a wide range of topics in a comprehensive manner, which can be indicative of AI trying to cover all bases.\n- **Perfect Grammar and Consistent Tone:** The writing maintains perfect grammar and a consistent tone throughout, which is often a sign of AI generation.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant to the video transcript but lacks the depth and personal insights found in Option 1.\n- **Clarity and Readability:** The post is clear and easy to read, but it feels more like a generic overview rather than a personal account.\n- **Engagement and Reader Interest:** The lack of personal anecdotes or unique insights makes the content less engaging.\n\n### Decision\n\nBased on the analysis, Option 1 shows more characteristics of authentic human writing, with personal anecdotes, a distinctive voice, and varied sentence structures. Option 2, on the other hand, exhibits signs of AI generation, such as a formulaic structure and overly formal language.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1: \"Navigating the World of Freelance Data Science\"\n\n**Signs of Human Authorship:**\n- The writing is structured and follows a clear format, which could suggest AI generation. However, it lacks personal anecdotes or unique insights that go beyond the transcript.\n- The language is formal and lacks the informal tone or personal touch that might indicate human authorship.\n- The content is comprehensive and covers a wide range of topics, which is typical of AI-generated content.\n- The sentence structures are varied but follow a predictable pattern, which is common in AI writing.\n- The post does not include personal opinions or distinctive voice, sticking closely to the information that could be derived from the transcript.\n\n**Content Quality:**\n- The content is relevant to the video transcript and covers important points discussed in the panel.\n- The structure is appropriate, with clear sections and headers.\n- The title and headers are concise but lack a personal or engaging touch.\n- The post is factually accurate and complete but lacks engagement and reader interest due to its formal tone.\n\n### Option 2: \"How to Freelance as a Data Scientist\"\n\n**Signs of Human Authorship:**\n- The post includes personal anecdotes, such as the author's experience sitting down with freelancers, which adds a personal touch.\n- The writing style is informal and conversational, with occasional informal language and reasonable tangents, suggesting human authorship.\n- The post includes unique insights and opinions, such as the author's thoughts on freelancing and personal experiences, which go beyond the transcript.\n- The sentence structures are varied and do not follow a predictable pattern, indicating a more natural writing style.\n- The post includes domain-specific knowledge and personal reflections that were not explicitly in the transcript.\n\n**Content Quality:**\n- The content is relevant to the video transcript and captures key insights from the panel discussion.\n- The structure is clear, with engaging section headers and a concise, engaging title.\n- The post is engaging and maintains reader interest through personal anecdotes and a conversational tone.\n- The content is factually accurate and covers important points, with a focus on practical advice and personal experiences.\n\n### Decision\n\nOption 2 shows more characteristics of authentic human writing, with personal anecdotes, a conversational tone, and unique insights that go beyond the transcript. Therefore, I conclude that Option 2 is more likely written by a human.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7796167247386759, "r": 0.08712158084298648, "f": 0.1567288328517643}, "rouge-2": {"p": 0.23975588491717523, "r": 0.026771806853582554, "f": 0.04816533847096943}, "rouge-l": {"p": 0.32839721254355403, "r": 0.036698140757325026, "f": 0.06601873741353646}}, "rouge_scores_B": {"rouge-1": {"p": 0.7685393258426966, "r": 0.0665823031246958, "f": 0.12254770223058317}, "rouge-2": {"p": 0.2249718785151856, "r": 0.019470404984423675, "f": 0.0358390825194875}, "rouge-l": {"p": 0.35168539325842696, "r": 0.030468217657938286, "f": 0.05607811520200663}}}, {"index": 4, "video_id": "4RAvJt3fWoI", "answer": "A", "response": "After evaluating both blog posts, here is the analysis:\n\n**Option 1:**\n\n- **Signs of Human Authorship:**\n  - The writing includes personal anecdotes and opinions, such as the author's thoughts on the response length and style of the AI assistant.\n  - There are informal language and reasonable tangents, like the author's personal preferences for concise responses and the mention of not liking to read long texts.\n  - The post contains varied sentence structures and a distinctive voice, particularly when discussing the author's personal experiences and preferences.\n  - The author shares unique insights, such as the challenges of making the AI sound more like them and the process of fine-tuning with personal data.\n  - There is domain-specific knowledge that goes beyond the transcript, especially in the detailed explanation of the fine-tuning process and the author's personal experiences with it.\n\n- **Content Quality:**\n  - The content is highly relevant to the video transcript, covering all the methods discussed in the video.\n  - The writing is clear and readable, with a logical flow and structure.\n  - The post is engaging, with personal touches and insights that keep the reader interested.\n  - Important points from the video are covered comprehensively, with additional details and examples.\n  - The title and section headers are concise and engaging, fitting the content well.\n\n**Option 2:**\n\n- **Signs of AI Authorship:**\n  - The writing follows a formulaic structure with repetitive sentence patterns, especially in the method descriptions.\n  - The language is overly formal and lacks personality, with generic observations and safe language.\n  - The content is exhaustive and comprehensive but lacks focus, covering all points without much depth or personal insight.\n  - The information is mostly what is explicitly stated in the transcript, with little additional insight or personal touch.\n  - The grammar is perfect, and the tone is consistent throughout, which is typical of AI-generated content.\n  - The titles and headers are generic and predictable, lacking the creativity and engagement of human-written titles.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript, covering the methods discussed.\n  - The writing is clear and readable, but it lacks engagement and reader interest due to its generic nature.\n  - Important points are covered, but the post lacks the depth and personal insights that make content engaging.\n  - The structure is appropriate, but the content feels more like a technical manual than a personal blog post.\n\n**Decision:**\n\nBased on the analysis, **Option 1** shows more characteristics of authentic human writing, with personal anecdotes, varied sentence structures, and a distinctive voice. The content is engaging and goes beyond the transcript, providing unique insights and personal experiences. Therefore, the decision is:\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "After evaluating both blog posts against the provided transcript and criteria, here is the analysis:\n\n**Option 1:**\n\n- **Signs of Human Authorship:**\n  - The writing is structured in a very organized and formulaic manner, which is a common pattern in AI-generated content.\n  - The language is formal and lacks personal anecdotes or unique insights beyond the transcript.\n  - The content strictly follows the information provided in the transcript without adding personal opinions or tangents.\n  - The sentence structures are consistent and lack the varied, imperfect nature typical of human writing.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the important points.\n  - The clarity and readability are high, but the engagement level is low due to the lack of personal touch.\n  - The structure is appropriate, with clear sections and headers, but they appear somewhat generic.\n\n**Option 2:**\n\n- **Signs of Human Authorship:**\n  - The writing includes personal anecdotes and opinions, such as the author's thoughts on becoming a millionaire with custom GPTs.\n  - There are informal language and reasonable tangents, like discussing the potential for advertising through GPTs.\n  - The sentence structures are varied, and the writing style has a distinctive voice and perspective.\n  - The author shares unique insights and domain-specific knowledge, such as the challenges of giving advice without knowing personal details.\n\n- **Content Quality:**\n  - The content is highly relevant to the video transcript and includes additional insights that enhance reader engagement.\n  - The clarity and readability are good, with a conversational tone that keeps the reader interested.\n  - The structure is well-organized, with appropriate headers and sections that do not appear AI-generated.\n\n**Decision:**\n\nOption 2 shows more characteristics of authentic human writing, with personal insights, varied sentence structures, and a distinctive voice. Therefore, the blog post that appears to be written by a human is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7931224209078405, "r": 0.2919198055893074, "f": 0.4267633779883059}, "rouge-2": {"p": 0.3596587782058338, "r": 0.13235443037974684, "f": 0.1935006292101562}, "rouge-l": {"p": 0.30701513067400277, "r": 0.11300121506682867, "f": 0.16519872696321514}}, "rouge_scores_B": {"rouge-1": {"p": 0.8619599578503688, "r": 0.08282705548805185, "f": 0.15113163972286375}, "rouge-2": {"p": 0.3829113924050633, "r": 0.03675949367088607, "f": 0.06707936801256582}, "rouge-l": {"p": 0.40252897787144365, "r": 0.03867962737950587, "f": 0.07057736720554272}}}, {"index": 28, "video_id": "tFHeUSJAYbE", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing in Option 1 includes informal language and a conversational tone, such as \"This one _feels_ different\" and \"Okay, so LLMs are a special type of language model, **but what makes them special?**\"\n- **Personal Anecdotes and Opinions:** The author shares personal insights, such as their initial confusion about what makes an LLM \"large\" and their own questions about the technology.\n- **Varied Sentence Structures:** The text includes a mix of sentence lengths and structures, contributing to a more natural flow.\n- **Distinctive Voice and Perspective:** The author uses a distinctive voice, with phrases like \"For those enlightened enough to live outside the world of AI buzz\" and \"While this might be no big deal to us highly evolved humans.\"\n- **Domain-Specific Knowledge:** The post includes specific insights and explanations that go beyond the transcript, such as the comparison of LLMs to traditional language models and the detailed explanation of zero-shot learning.\n\n**Content Quality:**\n- **Relevance to Video Content:** The post closely follows the video transcript, covering the introduction to LLMs and the three levels of using them.\n- **Clarity and Readability:** The content is clear and easy to follow, with well-organized sections.\n- **Engagement and Reader Interest:** The informal tone and personal insights make the content engaging.\n- **Completeness of Important Points:** The post covers all major points from the video, including the explanation of LLMs and the three levels of usage.\n- **Factual Accuracy:** The information is accurate and aligns with the video transcript.\n- **Appropriate Structure:** The structure is logical, with clear section headers and concise paragraphs.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure and Repetitive Patterns:** The writing follows a predictable structure, with each section neatly divided and explained in a similar manner.\n- **Overly Formal and Generic Language:** The language is more formal and lacks the personal touch and informal tone seen in Option 1.\n- **Exhaustive Lists and Comprehensive Coverage:** The post covers all points in a comprehensive manner, but lacks focus and personal insights.\n- **Information Explicitly Stated in Transcript:** The content closely mirrors the transcript without adding unique insights or personal anecdotes.\n- **Perfect Grammar and Consistent Tone:** The writing maintains perfect grammar and a consistent tone throughout, which is typical of AI-generated content.\n- **Generic Titles and Headers:** The titles and headers are straightforward and lack the creativity seen in human writing.\n\n**Content Quality:**\n- **Relevance to Video Content:** The post is relevant and covers the key points from the video.\n- **Clarity and Readability:** The content is clear and well-structured.\n- **Engagement and Reader Interest:** The formal tone may not be as engaging as the more conversational style in Option 1.\n- **Completeness of Important Points:** The post covers all important points from the video.\n- **Factual Accuracy:** The information is accurate and aligns with the video transcript.\n- **Appropriate Structure:** The structure is logical, with clear section headers and concise paragraphs.\n\n### Decision:\n\nBased on the analysis, Option 1 shows more characteristics of authentic human writing, with its informal tone, personal insights, varied sentence structures, and distinctive voice. Option 2, while well-written, exhibits patterns typical of AI-generated content, such as a formulaic structure and lack of personal touch.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis\n\n**Signs of Human Authorship:**\n- The writing is highly structured and follows a formulaic approach, with clear sections and sub-sections that are neatly organized. This is a common pattern in AI-generated content.\n- The language is formal and lacks personal anecdotes or unique insights that go beyond the transcript. It sticks closely to the information provided in the transcript.\n- The sentence structures are consistent and lack the varied, sometimes imperfect nature of human writing.\n- The content is comprehensive and covers all points in a systematic manner, which can be indicative of AI generation.\n- The use of domain-specific knowledge is present, but it is directly aligned with the transcript, suggesting a lack of additional insights or personal perspective.\n\n**Content Quality:**\n- The content is relevant to the video transcript and covers the important points clearly.\n- The structure is appropriate, with sections divided into manageable paragraphs.\n- The title and headers are clear but lack a distinctive, engaging style that might suggest human creativity.\n\n### Option 2 Analysis\n\n**Signs of Human Authorship:**\n- The writing includes informal language and personal touches, such as the phrase \"For those enlightened enough to live outside the world of AI buzz,\" which adds personality and humor.\n- There are personal insights and opinions, such as the comparison to AOL Instant Messenger, which are not present in the transcript.\n- The sentence structures are varied, with some tangents and informal expressions that suggest a human touch.\n- The content includes unique perspectives and a distinctive voice, particularly in the way it addresses the reader directly and uses rhetorical questions.\n- The use of domain-specific knowledge is present, but it is interwoven with personal insights and a conversational tone.\n\n**Content Quality:**\n- The content is relevant and covers the important points from the transcript.\n- The writing is engaging and maintains reader interest through a conversational style.\n- The structure is clear, with sections divided into paragraphs, but it feels more fluid and less rigid than Option 1.\n- The title and headers are concise and engaging, with a natural-sounding style.\n\n### Decision\n\nBased on the analysis, Option 2 shows more characteristics of authentic human writing. It includes personal anecdotes, varied sentence structures, and a distinctive voice that goes beyond the transcript. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.6695011337868481, "r": 0.41540626099190997, "f": 0.5126980681571521}, "rouge-2": {"p": 0.2603516732841747, "r": 0.16150598170302605, "f": 0.1993485342019544}, "rouge-l": {"p": 0.2789115646258503, "r": 0.17305663032008442, "f": 0.21358801823312348}}, "rouge_scores_B": {"rouge-1": {"p": 0.7171610169491526, "r": 0.23812873724938446, "f": 0.35753894903617645}, "rouge-2": {"p": 0.2672322375397667, "r": 0.08866995073891626, "f": 0.13315719947159843}, "rouge-l": {"p": 0.350635593220339, "r": 0.11642631023566655, "f": 0.17480855558489572}}}, {"index": 9, "video_id": "Y7pNmocrmi8", "answer": "A", "response": "<option_1>\n# Multimodal RAG: Process Any File Type with AI\n#### A beginner-friendly guide with example (Python) code\n\nThis is the third article in a [larger series](https://shawhin.medium.com/list/multimodal-ai-fe9521d0e77a) on\nmultimodal AI. In the previous posts, we discussed [multimodal LLMs](https://towardsdatascience.com/multimodal-models-llms-that-can-see-and-hear-5c6737c981d3) and [embedding models](https://towardsdatascience.com/multimodal-embeddings-an-introduction-5dc36975966f), respectively. In this article, we will combine\nthese ideas to enable the development of multimodal RAG systems. I\u2019ll start by\nreviewing key concepts and then share example code for implementing such a\nsystem.\n\n![](https://cdn-images-1.medium.com/max/800/1*KUfCT0odhqkTsPzf1ljx6A.png)Image\nfrom Canva.\n\n* * *\n\nLanguage models like GPT, LLaMA, and Claude learn a tremendous amount of world\nknowledge via their pre-training. This makes them powerful tools for solving\ncustom problems and answering complex questions.\n\nHowever, **there is knowledge that even the most advanced language models are\nignorant of**. This includes proprietary information within organizations,\nevents that occurred after a model's pre-training data collection, and\nspecialized knowledge that is not prevalent on the internet.\n\nAlthough this ignorance limits a model\u2019s out-of-the-box capabilities, there is\n**a popular technique to overcome these limitations** : retrieval augmented\ngeneration (or RAG for short).\n\n### **What is RAG?**\n\n**RAG** is an approach for**improving a model\u2019s response quality by\ndynamically providing the relevant context** for a given prompt. Here\u2019s an\nexample of when this might be helpful.\n\nSay, I forgot the name of a Python library a colleague mentioned in\nyesterday\u2019s meeting. This isn\u2019t something ChatGPT can help me with because it\ndoes not know the meeting\u2019s contents.\n\nHowever, RAG could help with this by taking my question (e.g. \u201cWhat was the\nname of that Python library that Rachel mentioned in yesterday\u2019s meeting?\u201d),\nautomatically pulling the meeting transcript, then providing my original query\nand the transcript to an LLM.\n\n![](https://cdn-images-1.medium.com/max/800/1*STVyqpJkhoKZWYdR-2-xqA.png)Basic\ndesign of a RAG system. Image by author.\n\n### **Multimodal RAG**\n\nAlthough improving LLMs with RAG unlocks several practical use cases, there\nare some situations where relevant information exists in non-text formats,\ne.g., images, videos, charts, and tables. In such cases, we can go one step\nfurther and build **multimodal RAG systems** , **AI systems capable of\nprocessing text and non-text data**.\n\nMultimodal RAG enables more sophisticated inferences beyond what is conveyed\nby text alone. For example, it could analyze someone\u2019s facial expressions and\nspeech tonality to give a richer context to a meeting\u2019s transcription.\n\n![](https://cdn-images-1.medium.com/max/800/1*mqRCTYThFcZmGcVtw6s1cw.png)Basic\ndesign of a Multimodal RAG system. Image by author.\n\n### **3 Levels of MRAG**\n\nWhile there are several ways to implement a multimodal RAG (MRAG) system, here\nI will focus on three basic strategies at increasing levels of sophistication.\n\n  1. Translate modalities to text.\n  2. Text-only retrieval + MLLM\n  3. Multimodal retrieval + MLLM\n\nThe following discussion assumes **you already have a basic understanding of\nRAG and multimodal models**. The following articles discussed these topics:\n[RAG](https://towardsdatascience.com/how-to-improve-llms-with-rag-abdc132f76ac), [Multimodal LLMs](https://towardsdatascience.com/multimodal-models-llms-that-can-see-and-hear-5c6737c981d3), and [Multimodal Embeddings](https://towardsdatascience.com/multimodal-embeddings-an-introduction-5dc36975966f).\n\n#### **Level 1: Translate modalities to text**\n\nA simple way to make a RAG system multimodal is by **translating new\nmodalities to text before storing them in the knowledge base**. This could be\nas simple as converting meeting recordings into text transcripts, using an\nexisting multimodal LLM (MLLM) to generate image captions, or converting\ntables to a readable text format (e.g., .csv or .json).\n\n![](https://cdn-images-1.medium.com/max/800/1*7QqhRIlnU7TQsCMnVDb6KA.png)Visual overview of\nLevel 1 of MRAG. Image by author.\n\nThe key upside of this approach is that it **requires minimal changes to an\nexisting RAG system**. Additionally, by explicitly generating text\nrepresentations of non-text modalities, one has better control over the\nfeatures of the data to extract. For instance, captions of analytical figures\nmay include both a description and key insights.\n\nOf course, the downside of this strategy is that the **model\u2019s responses\ncannot directly use non-textual data** , which means that the translation\nfrom, say, image to text can create a critical information bottleneck.\n\n#### **Level 2: Text-only retrieval + MLLM**\n\nAnother approach is to generate text representations of all items in the\nknowledge base, e.g., descriptions and meta-tags, for retrieval, but to **pass\nthe original modality to a multimodal LLM (MLLM)**. For example, image\nmetadata is used for the retrieval step, and the associated image is passed to\na model for inference.\n\n![](https://cdn-images-1.medium.com/max/800/1*JoUZLYezY3q95zngSmDJIA.png)Visual overview of\nLevel 2 of MRAG. Image by author.\n\nThis maintains many of the benefits of Level 1 while mitigating its\nlimitations. Namely, text features of items in the knowledge base can be\noptimized for search, but the downstream model can use the full richness of\neach item\u2019s original modality.\n\nThe key difference with this approach is that it requires an **MLLM** , which\nis **an LLM capable of processing non-text data**. This unlocks more advanced\nreasoning capabilities, as demonstrated by models like GPT-4o or LLaMA 3.2\nVision.\n\n#### **Level 3: Multimodal retrieval + MLLM**\n\nAlthough we could use keyword-based search in the retrieval processes for\nLevel 1 and Level 2, it is a common practice to use so-called **vector\nsearch**. This consists of **generating vector representations (i.e.,\nembeddings)** of items in the knowledge base and then **performing a search by\ncomputing similarity scores** between an input query and each item in the\nknowledge base.\n\nTraditionally, this requires that the query and knowledge base items are text-\nbased. However, as we saw in the [previous article](https://towardsdatascience.com/multimodal-embeddings-an-introduction-5dc36975966f) of this series, there exist **multimodal embedding\nmodels** that **generate aligned vector representations of both text and non-\ntext data**.\n\nTherefore, we can use multimodal embeddings to perform multimodal retrieval.\nThis works the same way as text-based vector search, but now the embedding\nspace co-locates similar concepts independent of its original modality. The\nresults of such a retrieval strategy can then be passed directly to a MLLM.\n\n![](https://cdn-images-1.medium.com/max/800/1*YwMdXXTGBMj9QSjAwkojdA.png)Visual overview of\nLevel 3 of MRAG. Image by author.\n\n### **Example Code: Multimodal Blog Question-Answering Assistant**\n\nWith a basic understanding of how Multimodal RAG works, let\u2019s see how we can\nbuild such a system. Here, I will create a question-answering assistant that\ncan access the text and figures from the previous two blogs in this series.\n\nThe Python code for this example is freely available at the [GitHub repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/multimodal-ai/3-multimodal-rag).\n\n* * *\n\n#### Imports & Data Loading\n\nWe start by importing a few handy libraries and modules.\n\n    \n    \n    import json  \n    from transformers import CLIPProcessor, CLIPTextModelWithProjection  \n    from torch import load, matmul, argsort  \n    from torch.nn.functional import softmax\n\nNext, we\u2019ll import text and image chunks from the [Multimodal LLMs](https://towardsdatascience.com/multimodal-models-llms-that-can-see-and-hear-5c6737c981d3) and [Multimodal Embeddings](https://towardsdatascience.com/multimodal-embeddings-an-introduction-5dc36975966f) blog posts. These are saved in .json files, which\ncan be loaded into Python as a list of dictionaries.\n\n    \n    \n    # load text chunks  \n    with open('data/text_content.json', 'r', encoding='utf-8') as f:  \n            text_content_list = json.load(f)  \n      \n    # load images  \n    with open('data/image_content.json', 'r', encoding='utf-8') as f:  \n            image_content_list = json.load(f)\n\nWhile I won\u2019t review the data preparation process here, the code I used is on\nthe [GitHub repo](https://github.com/ShawhinT/YouTube-Blog/blob/main/multimodal-ai/3-multimodal-rag/1-data_prep.ipynb).\n\nWe will also load the multimodal embeddings (from CLIP) for each item in\n_text_content_list_ and _image_content_list_. These are saved as pytorch\ntensors.\n\n    \n    \n    # load embeddings  \n    text_embeddings = load('data/text_embeddings.pt', weights_only=True)  \n    image_embeddings = load('data/image_embeddings.pt', weights_only=True)  \n      \n    print(text_embeddings.shape)  \n    print(image_embeddings.shape)  \n      \n    # >> torch.Size([86, 512])  \n    # >> torch.Size([17, 512])\n\nPrinting the shape of these tensors, we see they are represented via\n512-dimensional embeddings. And we have 86 text chunks and 17 images.\n\n#### Multimodal Search\n\nWith our knowledge base loaded, we can now define a query for vector search.\nThis will consist of translating an input query into an embedding using CLIP.\nWe do this similarly to the examples from the [previous post](https://towardsdatascience.com/multimodal-embeddings-an-introduction-5dc36975966f).\n\n    \n    \n    # query  \n    query = \"What is CLIP's contrastive loss function?\"  \n      \n    # embed query (4 steps)  \n    # 1) load model  \n    model = CLIPTextModelWithProjection.from_pretrained(\"openai/clip-vit-base-patch16\")  \n    # 2) load data processor  \n    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")  \n    # 3) pre-process text  \n    inputs = processor(text=[text], return_tensors=\"pt\", padding=True)  \n    # 4) compute embeddings with CLIP  \n    outputs = model(**inputs)  \n      \n    # extract embedding  \n    query_embed = outputs.text_embeds  \n    print(query_embed.shape)  \n      \n    # >> torch.Size([1, 512])\n\nPrinting the shape, we see we have a single vector representing the query.\n\nTo perform a vector search over the knowledge base, we need to do the\nfollowing.\n\n  1. Compute similarities between the query embedding and all the text and image embeddings.\n  2. Rescale the similarities to range from 0 to 1 via the softmax function.\n  3. Sort the scaled similarities and return the top k results.\n  4. Finally, filter the results to only keep items above a pre-defined similarity threshold.\n\nHere\u2019s what that looks like in code for the text chunks.\n\n    \n    \n    # define k and simiarlity threshold  \n    k = 5  \n    threshold = 0.05  \n      \n    # multimodal search over articles  \n    text_similarities = matmul(query_embed, text_embeddings.T)  \n      \n    # rescale similarities via softmax  \n    temp=0.25  \n    text_scores = softmax(text_similarities/temp, dim=1)  \n      \n    # return top k filtered text results  \n    isorted_scores = argsort(text_scores, descending=True)[0]  \n    sorted_scores = text_scores[0][isorted_scores]  \n      \n    itop_k_filtered = [idx.item()   \n                        for idx, score in zip(isorted_scores, sorted_scores)   \n                        if score.item() >= threshold][:k]  \n    top_k = [text_content_list[i] for i in itop_k_filtered]  \n      \n    print(top_k)\n    \n    \n    # top k results  \n      \n    [{'article_title': 'Multimodal Embeddings: An Introduction',  \n      'section': 'Contrastive Learning',  \n      'text': 'Two key aspects of CL contribute to its effectiveness'}]\n\nAbove, we see the top text results. Notice we only have one item, even though\n_k_ =5. This is because the 2nd-5th items were below the 0.1 threshold.\n\nInterestingly, this item doesn\u2019t seem helpful to our initial query of _\u201cWhat\nis CLIP\u2019s contrastive loss function?\u201d_ This highlights **one of the key\nchallenges of vector search** : _items similar to a given query may not\nnecessarily help answer it_.\n\nOne way we can mitigate this issue is having less stringent restrictions on\nour search results by increasing _k_ and lowering the similarity _threshold_ ,\nthen hoping the LLM can work out what\u2019s helpful vs. not.\n\nTo do this, I\u2019ll first package the vector search steps into a Python function.\n\n    \n    \n    def similarity_search(query_embed, target_embeddings, content_list,   \n                          k=5, threshold=0.05, temperature=0.5):  \n        \"\"\"  \n           Perform similarity search over embeddings and return top k results.  \n        \"\"\"  \n        # Calculate similarities  \n        similarities = torch.matmul(query_embed, target_embeddings.T)  \n          \n        # Rescale similarities via softmax  \n        scores = torch.nn.functional.softmax(similarities/temperature, dim=1)  \n          \n        # Get sorted indices and scores  \n        sorted_indices = scores.argsort(descending=True)[0]  \n        sorted_scores = scores[0][sorted_indices]  \n          \n        # Filter by threshold and get top k  \n        filtered_indices = [  \n            idx.item() for idx, score in zip(sorted_indices, sorted_scores)   \n            if score.item() >= threshold  \n        ][:k]  \n          \n        # Get corresponding content items and scores  \n        top_results = [content_list[i] for i in filtered_indices]  \n        result_scores = [scores[0][i].item() for i in filtered_indices]  \n          \n        return top_results, result_scores\n\nThen, set more inclusive search parameters.\n\n    \n    \n    # search over text chunks  \n    text_results, text_scores = similarity_search(query_embed, text_embeddings,   \n                        text_content_list, k=15, threshold=0.01, temperature=0.25)  \n      \n    # search over images  \n    image_results, image_scores = similarity_search(query_embed, image_embeddings,   \n                        image_content_list, k=5, threshold=0.25, temperature=0.5)\n\nThis results in 15 text results and 1 image result.\n\n    \n    \n    1 - Two key aspects of CL contribute to its effectiveness  \n    2 - To make a class prediction, we must extract the image logits and evaluate   \n    which class corresponds to the maximum.  \n    3 - Next, we can import a version of the clip model and its associated data   \n    processor. Note: the processor handles tokenizing input text and image   \n    preparation.  \n    4 - The basic idea behind using CLIP for 0-shot image classification is to   \n    pass an image into the model along with a set of possible class labels. Then,   \n    a classification can be made by evaluating which text input is most similar to   \n    the input image.  \n    5 - We can then match the best image to the input text by extracting the text   \n    logits and evaluating the image corresponding to the maximum.  \n    6 - The code for these examples is freely available on the GitHub repository.  \n    7 - We see that (again) the model nailed this simple example. But let\u2019s try   \n    some trickier examples.  \n    8 - Next, we\u2019ll preprocess the image/text inputs and pass them into the model.  \n    9 - Another practical application of models like CLIP is multimodal RAG, which   \n    consists of the automated retrieval of multimodal context to an LLM. In the   \n    next article of this series, we will see how this works under the hood and   \n    review a concrete example.  \n    10 - Another application of CLIP is essentially the inverse of Use Case 1.   \n    Rather than identifying which text label matches an input image, we can   \n    evaluate which image (in a set) best matches a text input (i.e. query)\u2014in   \n    other words, performing a search over images.  \n    11 - This has sparked efforts toward expanding LLM functionality to include   \n    multiple modalities.  \n    12 - GPT-4o \u2014 Input: text, images, and audio. Output: text.FLUX \u2014 Input: text.   \n    Output: images.Suno \u2014 Input: text. Output: audio.  \n    13 - The standard approach to aligning disparate embedding spaces is   \n    contrastive learning (CL). A key intuition of CL is to represent different   \n    views of the same information similarly [5].  \n    14 - While the model is less confident about this prediction with a 54.64%   \n    probability, it correctly implies that the image is not a meme.  \n    15 - [8] Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex   \n    Capabilities\n\n![](https://cdn-images-1.medium.com/max/800/1*rq89PAcqQ_lHgkYhkf5T4g.png)Image\nsearch result.\n\n#### Prompting MLLM\n\nAlthough most of these text item results do not seem helpful to our query, the\nimage result is exactly what we\u2019re looking for. Nevertheless, given these\nsearch results, let\u2019s see how LLaMA 3.2 Vision responds to this query.\n\nWe first will structure the search results as well-formatted strings.\n\n    \n    \n    text_context = \"\"  \n    for text in text_results:  \n        if text_results:  \n            text_context = text_context + \"**Article title:** \"   \n                                                  + text['article_title'] + \"\\n\"  \n            text_context = text_context + \"**Section:**  \"   \n                                                  + text['section'] + \"\\n\"  \n            text_context = text_context + \"**Snippet:** \"   \n                                                  + text['text'] + \"\\n\\n\"\n    \n    \n    image_context = \"\"  \n    for image in image_results:  \n        if image_results:  \n            image_context = image_context + \"**Article title:** \"   \n                                              + image['article_title'] + \"\\n\"  \n            image_context = image_context + \"**Section:**  \"   \n                                              + image['section'] + \"\\n\"  \n            image_context = image_context + \"**Image Path:**  \"   \n                                              + image['image_path'] + \"\\n\"  \n            image_context = image_context + \"**Image Caption:** \"   \n                                              + image['caption'] + \"\\n\\n\"\n\nNote the metadata that accompanies each text and image item. This will help\nthe LLaMA better understand the context of the content.\n\nNext, we interleave the text and image results in a prompt.\n\n    \n    \n    # construct prompt template  \n    prompt = f\"\"\"Given the query \"{query}\" and the following relevant snippets:  \n      \n    {text_context}  \n    {image_context}  \n      \n    Please provide a concise and accurate answer to the query, incorporating   \n    relevant information from the provided snippets where possible.  \n      \n    \"\"\"\n\nThe final prompt is quite long, so I won\u2019t print it here. However, it is fully\ndisplayed in the [example notebook](https://github.com/ShawhinT/YouTube-Blog/blob/main/multimodal-ai/3-multimodal-rag/2-mrag_example.ipynb) on GitHub.\n\nFinally, we can use [ollama](https://ollama.com/) to pass this prompt to LLaMA\n3.2 Vision.\n\n    \n    \n    ollama.pull('llama3.2-vision')  \n      \n    response = ollama.chat(  \n        model='llama3.2-vision',  \n        messages=[{  \n            'role': 'user',  \n            'content': prompt,  \n            'images': [image[\"image_path\"] for image in image_results]  \n        }]  \n    )  \n      \n    print(response['message']['content'])\n    \n    \n    The image depicts a contrastive loss function for aligning text and image   \n    representations in multimodal models. The function is designed to minimize the   \n    difference between the similarity of positive pairs (text-image) and negative   \n    pairs (text-text or image-image). This loss function is commonly used in CLIP,   \n    which stands for Contrastive Language-Image Pre-training.  \n      \n    **Key Components:**  \n      \n    *   **Positive Pairs:** Text-image pairs where the text describes an image.  \n    *   **Negative Pairs:** Text-text or image-image pairs that do not belong to   \n    the same class.  \n    *   **Contrastive Loss Function:** Calculates the difference between positive   \n    and negative pairs' similarities.  \n      \n    **How it Works:**  \n      \n    1.  **Text-Image Embeddings:** Generate embeddings for both text and images   \n    using a multimodal encoder (e.g., CLIP).  \n    2.  **Positive Pair Similarity:** Calculate the similarity score between each   \n    text-image pair.  \n    3.  **Negative Pair Similarity:** Calculate the similarity scores between all   \n    negative pairs.  \n    4.  **Contrastive Loss Calculation:** Compute the contrastive loss by   \n    minimizing the difference between positive and negative pairs' similarities.  \n      \n    **Benefits:**  \n      \n    *   **Multimodal Alignment:** Aligns text and image representations for better   \n    understanding of visual content from text descriptions.  \n    *   **Improved Performance:** Enhances performance in downstream tasks like   \n    image classification, retrieval, and generation.\n\nThe model correctly picks up that the image contains the information it needs\nand explains the general intuition of how it works. However, it\n**misunderstands the meaning of positive and negative pairs** , thinking that\na negative pair corresponds to a pair of the same modality.\n\nWhile we went through the implementation details step-by-step, I packaged\neverything into a nice UI using Gradio in this\n[notebook](https://github.com/ShawhinT/YouTube-Blog/blob/main/multimodal-ai/3-multimodal-rag/3-mrag_UI.ipynb) on the GitHub repo.\n\n### Conclusion\n\nMultimodal RAG systems can synthesize knowledge stored in a variety of\nformats, expanding what\u2019s possible with AI. Here, we reviewed 3 simple\nstrategies for developing such a system and then saw an example implementation\nof a multimodal blog QA assistant.\n\nAlthough the example worked well enough for this demonstration, there are\nclear limitations to the search process. A few techniques that may improve\nthis include using a **reranker to refine similarity search** results and to\nimprove search quality via **fine-tuned multimodal embeddings**.\n\nIf you want to see future posts on these topics, let me know in the comments\n:)\n</option_1>\n\n<option_2>\n# Building Multimodal Retrieval-Augmented Generation (RAG) Systems\n### A Comprehensive Guide to Enhancing AI Models with Text and Non-Text Data\n\nIn the rapidly evolving field of artificial intelligence, language models like GPT, Claude, and Llama have made tremendous strides in understanding and generating human-like text. However, they still face significant limitations, particularly when it comes to accessing real-time information and domain-specific knowledge. This is where **Retrieval-Augmented Generation (RAG)** comes into play\u2014a method that enhances the capabilities of language models by integrating relevant context from external knowledge bases. In this blog post, we'll explore how to build multimodal RAG systems that can process both text and non-text data, enabling more sophisticated interactions and responses.\n\n![Multimodal RAG Concept](https://example.com/image-url) *Image Credit: Author*\n\n* * *\n\n### Understanding RAG: The Basics\n\nBefore delving into the multimodal aspect, it's essential to grasp the core concept of RAG. At its heart, RAG combines the strengths of retrieval systems with generative models. When a user query is posed, RAG retrieves relevant context from a knowledge base and feeds it into a language model to generate a more informed and accurate response.\n\nFor example, if you were to ask a model about a specific Python library mentioned in a meeting, a traditional language model might respond with a generic answer, lacking access to the specific meeting notes. RAG addresses this by automatically providing the relevant context, thus improving response accuracy.\n\nThe typical workflow of a RAG system looks like this:\n1. **User Query**: The user provides a question or topic.\n2. **Context Retrieval**: The system searches a knowledge base for relevant information.\n3. **Prompt Construction**: The query and retrieved context are formatted into a prompt.\n4. **Response Generation**: The prompt is passed to a language model to generate a response.\n\nThis process not only enhances the model's ability to provide accurate answers but also allows it to remain current with information that may not have been included during its training phase.\n\n* * *\n\n### Moving to Multimodal RAG Systems\n\nNow that we have a basic understanding of RAG, let's explore how to extend this framework to handle multiple types of data, including images, audio, and other non-textual formats. Here are three strategies for building multimodal RAG systems:\n\n#### Level 1: Text Conversion of All Modalities\n\nThe simplest approach is to convert all data types into text. This means extracting text from documents, generating captions for images, and transcribing audio. While this method is straightforward, it may not capture the full richness of the original data. \n\n- **Extract text from documents**: Split into manageable chunks.\n- **Generate captions for images**: Use models to create descriptive text for visual content.\n- **Transcribe audio**: Convert spoken content into text.\n\nThis method is effective but can overlook critical details present in non-text formats.\n\n#### Level 2: Text Retrieval with Multimodal Processing\n\nIn this level, we still retrieve text-based features but leverage a multimodal language model for processing. The steps involve:\n\n1. **Extracting Features**: Similar to Level 1, but this time we can include metadata like titles and dates.\n2. **Direct Input of Original Modalities**: After identifying relevant items, we can input the original images or audio directly into the multimodal model.\n\nThis approach allows for a more nuanced understanding of the data, as the model can analyze the original formats.\n\n#### Level 3: Full Multimodal Retrieval and Processing\n\nThe most sophisticated approach combines multimodal retrieval with a multimodal language model. Here, we generate vector representations of all data types and store them in a shared vector space. This method allows for direct similarity searches across different modalities, enhancing the system's ability to provide relevant responses.\n\n- **Generate multimodal embeddings**: Use models like CLIP to create vector representations of both text and images.\n- **Perform vector search**: Compute similarities between query embeddings and the knowledge base items.\n\nThis comprehensive method allows for a richer interaction with the data, making it possible to retrieve and generate responses based on a diverse array of inputs.\n\n* * *\n\n### Implementing a Multimodal RAG System with Python\n\nTo illustrate the practical implementation of a multimodal RAG system, let\u2019s walk through a simple example using Python. We will create a blog question-answering assistant that can respond to queries based on both text and images from blog posts.\n\n#### Step 1: Import Required Libraries\n\nWe'll start by importing necessary libraries, including the Transformers library for model handling.\n\n```python\nimport torch\nfrom transformers import CLIPProcessor, CLIPModel\n```\n\n#### Step 2: Load Data\n\nNext, we will load text and image data. For this example, assume we have JSON files containing our blog post content and images.\n\n```python\ntext_content = load_json('text_data.json')\nimage_content = load_json('image_data.json')\n```\n\n#### Step 3: Create Embeddings\n\nUsing the CLIP model, we generate embeddings for both our text and images.\n\n```python\nmodel = CLIPModel.from_pretrained('openai/clip-vit-base-patch16')\nprocessor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch16')\n\ntext_embeddings = model.get_text_features(**processor(text=text_content, return_tensors=\"pt\"))\nimage_embeddings = model.get_image_features(**processor(images=image_content, return_tensors=\"pt\"))\n```\n\n#### Step 4: Define a Query and Embed It\n\nWe will define a user query and embed it in the same vector space as our text and image content.\n\n```python\nquery = \"What is CLIP's contrastive loss function?\"\nquery_embedding = model.get_text_features(**processor(text=query, return_tensors=\"pt\"))\n```\n\n#### Step 5: Perform Vector Search\n\nNow, we compute the similarity between the query embedding and the embeddings in our knowledge base.\n\n```python\nsimilarity_scores = torch.matmul(query_embedding, text_embeddings.T)\ntop_k_indices = similarity_scores.topk(5).indices\n```\n\n* * *\n\n### Conclusion: Key Takeaways and Next Steps\n\nBuilding a multimodal RAG system involves integrating diverse data types to enhance the capabilities of language models. By employing strategies that range from simple text conversion to sophisticated multimodal embeddings, you can create systems that provide more accurate and relevant responses.\n\n**Key Takeaways**:\n- RAG improves the accuracy of language models by providing real-time context.\n- Multimodal RAG systems can process various data types, enriching user interactions.\n- Practical implementation requires thoughtful design and consideration of data modalities.\n\nAs you explore the potential of multimodal RAG systems, consider experimenting with different data types and retrieval strategies. The future of AI lies in its ability to understand and integrate diverse forms of information, and you have the opportunity to be at the forefront of this exciting field.\n\nIf you're interested in diving deeper into specific techniques or have questions about implementing these systems, feel free to reach out or leave a comment below!\n</option_2>\n\n<transcript>\nalthough language models like GPT Claude and llama gain an advanced understanding of the world they don't know everything that's because information is constantly being generated or may not be widely available a popular way to overcome this ignorance is retrieval augmented generation or rag for short in this video I'll discuss how to build multimodal rag systems in other words rag systems that can process text and non-text data I'll start by reviewing three highlevel strategies for doing this then walk through an example implementation with python code and if you're new here welcome I'm sha I make videos about the things I'm learning about and building in Ai and if you enjoy this content please consider clicking the Subscribe button that's a great NOC cost way you can support me in all the videos that I make so here we're going to talk about multimodal rag which will combine the ideas from the previous two videos of this series namely multimodal large language models and multimodal embeddings before we talking about multimodal rag it's worth answering the question what is rag since I talked about this in a previous video I won't get into all the nitty-gritty details but just at a high level rag stands for retrieval augmented generation and it consists of improving in llms responses by automatically providing it the relevant context just to give a simple example of when this might be necessary suppose that I'm trying to remember the name of a python library that a coworker had mentioned in a meeting from yesterday if I were to take that query and pass it to say chat GPT CLA or whatever your favorite large language model is it would probably give a response like this that says I'm sorry but I don't have specific access to the details of your me meeting there's no reason we might expect chaty PT or the like to have access to our meeting notes or transcript so this is a very reasonable way to respond to this query this is a broader limitation of large language models although they have tremendous general knowledge about the world they have no knowledge of things that occurred after their pre-training and their understanding of specialized or domain specific information may be limited rag allows us to overcome these limitations by automatically providing the relevant context to a large language model so what this might look like is we'll take that same query of what was that python library that Rachel mentioned in yesterday's meeting and before passing that query to Chad gbt I'll just take the entire transcript of the meeting and add it into my prompt and then pass it to chat GPT from this the large language model will be able to extract the desired python python Library which may have been unstructured and unstructured is indeed the name of a python library that helps parse files of various different formats which is very relevant for multimodal applications so what I just showed was a specific example of what rag might look like but this is a much broader idea and a basic overview of a rag workflow may look something like this where we start with a user query we take that query to retrieve the relevant context from a knowledge base we then will take the query and the relevant context and format it into a prompt then we'll take that prompt pass it to a large language model so it can generate a response there are many technical details here and knobs and dials that we can adjust to refine and adapt such a system for a particular use case but this view here shows all the Essential Elements if you want to explore rag more deeply you can check out my previous video on the topic so now that we've defined what rag is let's see how we can make such a system multimodal so in other words how can we build a rag system that doesn't just process Text data but that can also process non-text data a simple strategy would be to take a query like we did before then take that query to perform search over a multimodal knowledge base so these blue rectangles here are representing text information while these green rectangles are representing image data then we can in the same exact way as before construct a prompt but now instead of only using context that is text based we can use context that is also image based or Audi based or includes time series data or whatever type of data modality that you might want to work with we can then pass this into a multimodal large language model so this is a large language model that can not only process text but it can also process non-textual data and then it will generate a response for us the two key elements here that make this rag system multimodal are one it's knowledge base containing not just text based data and two is the multimodal large language model which can process multiple types of data so here I'll talk about three different strategies for building multimodal rag systems and we can view each of these different levels of multimodal rag as becoming more and more sophisticated as we go to the next level and then I'll just mention that the discussion here will assume that you already have a basic understanding of multimodal large language models as well as multimodal embedding models which were discussed in the previous two videos of this series starting with level one is to just translate everything into text hearing this your first thought might be well sha that doesn't really sound like a multimodal system it sounds like you're just translating all the different data types into text and just using a regular rag system and it sounds like that because that's exactly what's happening here and I would say anytime it's possible to implement the strategy for your use case I would go with this one and that's because you don't want to over complicate your AI system for the sake of sophistication a general law of engineering is to keep your systems as simple as possible so what this might look like is you can take text documents extract the text and split them into chunks you could take figures and tables and extract their captions and maybe some of their key insights and store them as text chunks and then you can take images and grab their captions or descriptions and store them as text chunks or you can even take images pass them through a multimodal large language model and prompt that model to just generate a descriptive caption for that image and that way you can extract the essential features from an image another example might be if you have videos or audio recordings that consist of people talking you can transcribe that speech and just store that speech into text chunks but no matter what the original modality is this process will translate everything to text and then you can store all these different text chunks and text items in a knowledge base and then you can just dynamically retrieve the most relevant chunks for a given query like a traditional rag system although this is a very simple way to do multimodo rag basically you put all the effort in the pre-processing of the data this has obvious limitations so sometimes there's not an obvious way to translate the original modality to text for example let's say you have time series data of like market indicators or you have time series data of brain activity from EEG there may not be an obvious way to fully capture the information in that signal into text and even if there is a way to do that you don't have a good way of passing that full richness of information to a large language model because the prompt here is text only so one way we can overcome that is level two so here we're going to keep the retrieval process as text only however we are going to use a multimodal large language model so what that looks like is that we will do the knowledgebase step exactly as we did in the previous slide so we'll take all our data modalities and we'll extract text features from them and store them in our knowledge base here it doesn't necessarily have to be a full-blown texal description of the underlying data it could simply be meta tags including like a title or a date or user that generated that content or whatever and then these meta tags could be used in these search process however the key difference here is that once we identify which items are most relevant to our query we will directly input the original data modality into our query and then we can process this multimodal prompt using a multimodal language model and a key detail here is that you have to ensure that the model you're using to process this query can indeed take the modalities that you're passing to it these days processing text and images is quite common however if you wanted to also process audio and video you would have to make sure that the model that you're using can do that the last General approach I'll describe for multimodal rag is to do both multimodal retrieval and use a multimodal language model and so what that will look like here is that let's say you extract text from the text documents let's say you have these PDF reports which consist of text and figures so you're going to extract both those data types and then you extract images directly then what you can do is you can use multimodal embeddings which we talked about in the previous video to generate Vector representations of all these items and store them into a multimodal knowledge base the key benefit of using multimodal embeddings here is that you'll have a shared Vector space which can represent the raw data that you want to include in your knowledge base and then we can perform search over these items directly by Computing the similarity between a vector representation of the query and all the items in the knowledge base so that was probably a bit high level and Abstract so let's see a concrete example of how we can Implement such a multimodal rag system using python so here we're going to walk through the development of a multimodal Blog question answering assistant so in other words an AI assistant that will have access to all the text and images from these two blog posts and we be able to answer any questions based on this content we'll start by importing some helpful libraries here we'll use the Transformers Library again to import clip which is a multimodal embedding model that can represent text and images in a shared Vector space and then we'll import a few different functions from pytorch okay the next step is we're going to load in the text and image data although I won't walk through the data extraction process the code for doing this is freely available on the GitHub repository link down here so if you go here and then you go to the multimodal rag example there'll be a notebook that lays out exactly how I took the blog articles and extracted all the text and extracted all the images from them I'll just load in the text content and image content which are saved as Json files also available on the GitHub and then I'll load in the multimodal embeddings which I generated using clip and then saved as a pie torch tensor and so we can just load those in like this if we print the shape of these tensors we see that the first one is 86x 512 indicating that we have 86 text chunks that are represented by 512 dimensional vectors so it's a vector in a 512 dimensional space and then similarly we have 177 images which are also represented in this 512 dimensional Vector space so now that we've imported the text and image content and their embeddings the next step is to define a query and embed that query in the same space as the text and image content so I'll Define a query that is what is Clips contrast of loss function and to embed this query we'll need to follow four steps first we'll load in clip this is a special type of clip that only processes is text so we'll load that in using the Transformers Library we'll also load in this data processor which will just handle the tokenization of this query before passing it into the model so once we have those imported then we can pre-process the text with this processor we just imported and then we can pass the resulting inputs into clip which is our model here and this will give us the outputs once we have outputs we can just use this text embeds attribute to extract the text embeddings and then if we print it shape we see it's a 1x 512 High torch tensor which is compatible with the representations we saw on the previous slide for our text and image chunks at this point we have Vector representations of our query as well as every item in our knowledge base so basically all the contents of these two blog posts now we can use these Vector representations to perform Vector search so this will consist of computing the similarity between the query embedding and all the embeddings in the knowledge base so we do this in the following way first I'll Define some parameters to constrain the search so here I'll restrict it to the top five most similar items and then have this additional similarity threshold that will exclude any items that have a similarity score below 0.05 starting with just the text items the way we can compute the similarities is by doing a matrix multiplication so what we do is we'll multiply the query embeddings with the text embeddings Matrix we just do this transpose here so the Matrix is the right shape and it's important to know here that if we do this matrix multiplication the elements of this text similarities tensor will be between negative infinity and positive Infinity which makes it hard to Define any kind of Threshold at the outset so a common strategy to rescale these similarities is applying the soft Max function to these values we can do that by first defining a temperature value we'll just take these text similarities divide it by the temperature and pass it through this softmax function from the P torch library and this will give us these text scores which are essentially similarities but instead of ranging from negative Infinity to positive Infinity these range from 0 to 1 and then once we have these scaled text scores we'll sort them here I'm doing ARG sort so this will sort the values but rather than returning the sorted values themselves it'll return the indices of the sorted values you can just imagine this is a one-dimensional tensor and the zeroth element of the tensor will be the index of the largest similarity score the next element will be the index for the second largest similarity score and so on and so forth now we can use these indices to generate a tensor of the actual ual sorted scores and then what this will allow us to do is to do this somewhat sophisticated filtering process to ensure that we're only returning the top K results that are above this predefined threshold we're using Python's list comprehension capability here just to break this down we're creating a tuple which consists of the indices of the sorted scores and the sorted scores themselves then we're going to Loop through the indices and the scores in these tupal and then then we'll extract the index if its score is greater than or equal to our predefined threshold so the result of this will be a list of indices sorted from largest to smallest score and then at the end of it we can just take the top K elements from this list so I know there's a lot of steps here but this is how we can simultaneously filter for this threshold and these topk results and then what we can do is go through our text content list this is what we imported from the Json file and then just return all the content from this I topk filtered list so after all that we are returned just a single search result and the reason is even though K was set equal to five the other four search results had similarity scores below the threshold so they were not included I want to point two things out from looking at this first is that Beyond just the text that was used to do this search there's also the article title and the section title where this text was taken from in the article and so having metadata like this is helpful for both the search functionality because it gives you more flexibility in how you do search but also it allows you to give more context to the downstream model in generating responses so this is just a good practice and then you can check out the data preparation code of how I extracted this metadata on the GitHub repo but the second thing I want to point out is that this text doesn't seem super helpful in answering our original query of what is clip's contrastive loss function indeed the section is about contrastive learning which is definitely similar to our query but just because this text here is similar to the query doesn't necessarily mean that it's helpful in answering it this is one of the main limitations of vector search which is that using these embedding models out of the box even though it allows you to identify similar Concepts it doesn't necessarily help you identify items in your knowledge base that are helpful to answering your query although there are many ways we could mitigate this issue a simple solution is to just have less stringent search parameters to do that I'll first can this whole similarity search process into a userdefined function so we don't have to just keep writing it over and over again and then I will do similarity search over the text chunks and the images separately and this way I can have different search parameters for the text and images here I have more inclusive search parameters than we saw in the previous slide so instead of k equal to 5 I have k equal to 15 the threshold went from 0.05 down to 0.01 and then I kept temperature the same and then for images I just keep k at five I have the threshold as 0.25 and I have the temperature as 0.5 so the way I determined these parameters was just through trial and error on three simple queries and just eyeball in it so that's a fast and easy way to build out an initial version of a retrieval system but if you are serious about optimizing it and improving the model's results it's going to be helpful to generate a data set of example queries and their Associated relevant items then you can do some kind of grid search to find the best choice of search parameters here the results from these two searches are shown here so we have 15 different text items returned but just one image item was returned looking at these texts this one mentions contrast of learning this one mentions clip this one mentions clip this one mentions clip so we see that yes indeed that these items are similar to our input query but it doesn't necessarily mention anything about the loss function that's not a promising result but if we look over to the image this is exactly what we're looking for so this is Clips contrastive loss function laid out mathematically now that we've retrieved our context let's see how we can put this into a prompt to pass it to a multimodal language model so the text results are stored in this list of dictionaries with all the different metadata so we're going to need to translate that data structure into a string representation so we can pass it to a language model the way I'll do that is I'll iterate through all the items in this text results and then just format it according to this code here so what this looks like in text is this this we have the article title with these Asters on either side we have the section that the text was taken from and then we have the text snippet right here and the reason I'm using these asteris is because this translates to bolded text in markdown which is a text formatting language so a trick for adding more structure to your prompts is to just write them in markdown then we can do a similar thing for the image results and so what that looks like is we have the article title the section it was taken from the path of the image and then the image caption then what we can do is we'll generate this promp template and so here we're going to combine the query and the text and image context says given the query and then we'll just insert the query here and the following relevant Snippets and then we'll just include all the search results here please provide a concise and accurate answer to the query incorporating the relevant information from the provided Snippets where possible so once we've constructed this prompt we can pass it to llama 3.2 Vision here I'll run everything locally using ol llama like I did in the first video of this series and since I'm doing it in the same exact way I won't spend too much time on the code here but basically what we're doing is we're loading in llama 3.2 Vision which can understand both text and images and then we'll pass in the prompt as well as all the images from our image search results and then with that we can print out the response the monos response looks like this we can see that it has like this interesting syntax to it which is actually markdown so what we can do is take the raw output of the model and then process it with some kind of markdown reader and it's going to look something like this and then this is another upside of writing your prompts in markdown is that models will tend to write their responses in markdown when prompts use it there are some good things about this response so one it correctly understands what is in the image so it says the image depicts a contrast of loss function for aligning text and image representations in multimodo models however it seems to misunderstand the meaning of positive Pairs and negative pairs in this context it seems to think that a positive pair is any text image pair while negative pairs are text text or image image pairs which don't make any sense in the context of clip all pairs are text image however positive pairs are a text image pair that correspond to one another while negative pairs are text image pairs that don't correspond to one another so the model doesn't really quite understand that and maybe if the text results were more helpful it would have understood that it goes on to talk about text text or image image pairs which just don't come up in clip but it does kind of get this right that it calculates the difference between positive and negative pair similarities how it works text image embeddings generates embeddings for both text and images using multimode encoder so that's true and then it goes on to talk about the benefits which is interesting so lines text and images for better visual content understanding of visual content from text description enhances performance and downstream tasks like image classification retrieval and generation okay so it gets the benefits it doesn't really answer the question of what is clips contras of loss function it does describe some like General features and some important points but even though it had the answer in the image it didn't convey that information very well and I suspect one of the reasons for that is so many of those text search results were not helpful here we just kind of walk through the process and logic of implementing this multimodal rag system step by step but this isn't how you would actually implement this for some kind of real world project so for that also on the GitHub repository I have a radio user interface that kind of packages this all up if you run that Notebook 3 in the example code you should see something like this so let's try a different one so what are three paths described for making llms multimodal although this is something that llama doesn't necessarily need to read my articles to understand and this is something more article specific so let's see how it handles this one so far so good so it's using the Snippets it got the first path llm plus tools path to llm plus adapters so here it seems to have done a much better job and that's likely because the search results are higher quality for this query as opposed to previous queries and then you notice that we're streaming the text here which is better from a user interface standpoint and then you can see how that's implemented in the example code so here we implemented this multimodal rag system and one thing that came up is that the quality of a multimodal rag system is very much dependent on the quality of the search process of this retrieval process and we saw that the search returning irrelevant items can be a major problem there actually a few other ways we can improve this the first is we could use a ranker the way this works is that rather than only relying on Vector search or keyword-based search what you can do is take those top 15 text search results we saw in the example code and we can pass them through yet another language model that's trained via contrast of learning but specifically to identify query and helpful answer pairs so before we used clip embeddings to generally identify items in the knowledge base that were similar to our query the value of a ranker is that we could use a model that was specifically trained to identify positive pairs of qu iies and relevant search items so the output of this will be another set of similarity scores we can use in our rag system another strategy is that rather than using Clips multimodal embeddings out of the box we could fine-tune clip so that rather than simply evaluating the similarity between the query and items in our knowledge base we can f- tune an existing multimodal model to align queries with relevant items in the knowledge base so not just semantically similar ones but items that are helpful in answering the query but of course the downside of fine tuning is that this is going to require us to generate a lot of query item positive pairs in order to do this training process so if either of these techniques sound interesting to you and you want me to cover them in future videos let me know in the comment section below if you enjoyed this video but you want to learn more check out the blog published in towards data science although this will be a member Only Store you can as always access it completely for free using the friend Link in the description below and with that thank you so much for your time and thanks for watching\n</transcript>\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- The writing style is formal and structured, with clear sections and headers. This can be indicative of AI-generated content, as it often follows a formulaic structure.\n- The language is consistently formal and lacks personal anecdotes or unique insights that go beyond the transcript.\n- The content is comprehensive and covers the topic thoroughly, but it lacks the informal language or reasonable tangents that might suggest human authorship.\n- The sentence structures are varied but follow a predictable pattern, which is common in AI-generated content.\n- There is no use of personal opinions or distinctive voice, which are key indicators of human writing.\n\n**Content Quality:**\n- The content is relevant to the video transcript and covers the topic of multimodal RAG systems effectively.\n- The clarity and readability are high, with well-organized sections and clear explanations.\n- The engagement level is moderate, as the content is informative but lacks a personal touch.\n- The structure is appropriate, with sections divided into manageable paragraphs.\n- The title and headers are concise and relevant but lack creativity, which might suggest AI generation.\n\n### Option 2 Analysis:\n\n**Signs of Human Authorship:**\n- The writing includes informal language and personal touches, such as \"Say, I forgot the name of a Python library a colleague mentioned in yesterday\u2019s meeting,\" which suggests a human author.\n- There are references to previous articles and a series, indicating a continuity that a human author might maintain.\n- The writing includes personal opinions and insights, such as the discussion on the limitations of vector search and suggestions for improvement.\n- The sentence structures are varied and include informal elements, which are less common in AI-generated content.\n- The content includes domain-specific knowledge and insights that go beyond the transcript, such as the mention of specific models and techniques.\n\n**Content Quality:**\n- The content is highly relevant to the video transcript and expands on the topic with additional insights and examples.\n- The clarity and readability are good, with a conversational tone that engages the reader.\n- The engagement level is high due to the informal language and personal insights.\n- The structure is appropriate, with sections divided into manageable paragraphs and a logical flow.\n- The title and headers are creative and engaging, suggesting human authorship.\n\n### Decision:\n\nBased on the analysis, Option 2 shows more characteristics of authentic human writing. It includes informal language, personal insights, and a distinctive voice, which are strong indicators of human authorship. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.703989703989704, "r": 0.44716942571019824, "f": 0.5469316335458068}, "rouge-2": {"p": 0.2993241068554876, "r": 0.1901062959934587, "f": 0.23252906613326665}, "rouge-l": {"p": 0.2628700128700129, "r": 0.16697322705906398, "f": 0.20422447194100737}}, "rouge_scores_B": {"rouge-1": {"p": 0.8446691176470589, "r": 0.1878193337420805, "f": 0.30730647048988463}, "rouge-2": {"p": 0.34130634774609014, "r": 0.0758381030253475, "f": 0.12410102023749792}, "rouge-l": {"p": 0.38143382352941174, "r": 0.08481504189658697, "f": 0.13877278047149305}}}, {"index": 5, "video_id": "fpL5fMmJHqk", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing includes informal language and personal insights, such as \"Mo\u2019 data, mo\u2019 problems\" and \"When I was first exposed to TDA, I was really excited.\" These elements suggest a personal touch and a distinctive voice.\n  - The post includes a personal anecdote about the author's initial excitement and subsequent challenges with TDA, which adds a human element.\n  - The sentence structures are varied, with some sections using informal language and others providing more structured explanations.\n  - The post includes domain-specific knowledge, such as references to specific papers and techniques, which are not explicitly mentioned in the transcript.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript, covering the key points of TDA and its applications.\n  - The post is engaging, with a clear structure and use of images to illustrate points.\n  - The title and section headers are concise and engaging, such as \"Mo\u2019 data, mo\u2019 problems\" and \"The Promise.\"\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The language is more formal and lacks the informal, personal touch seen in Option 1.\n  - The writing follows a more formulaic structure, with predictable sentence patterns and comprehensive coverage of the topic.\n  - There are no personal anecdotes or unique insights beyond what is in the transcript.\n  - The content is more generic, with less distinctive voice or perspective.\n\n- **Content Quality:**\n  - The content is relevant and covers the key points of TDA, but it lacks the engaging, personal touch of Option 1.\n  - The structure is clear, but the language is more formal and less engaging.\n  - The title and section headers are more generic, such as \"Introduction to Topological Data Analysis\" and \"The TDA Pipeline: From Data to Insights.\"\n\n**Conclusion:**\n\nOption 1 shows more characteristics of authentic human writing, with informal language, personal anecdotes, and a distinctive voice. It also includes domain-specific knowledge and insights that go beyond the transcript. Option 2, while well-structured and relevant, lacks the personal touch and varied sentence structures that suggest human authorship.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing is formal and structured, with a clear introduction, body, and conclusion. It lacks informal language or personal anecdotes, which are often signs of human authorship.\n  - The content closely follows the transcript, with little deviation or unique insights beyond what is explicitly stated.\n  - The sentence structures are varied but follow a predictable pattern, which is common in AI-generated content.\n  - The voice is generic and lacks a distinctive personal perspective.\n  - There is no use of domain-specific knowledge that wasn't in the transcript.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the main points.\n  - It is clear and readable, with a logical flow.\n  - The engagement level is moderate, as it lacks personal touches or unique insights that might captivate a reader.\n  - The structure is appropriate, with sections and headers that are concise and relevant.\n  - The title and headers are clear but somewhat generic.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing includes informal language, such as \"Mo\u2019 data, mo\u2019 problems,\" which adds a personal touch and suggests human authorship.\n  - The author shares personal experiences and opinions, such as their initial excitement and subsequent challenges with TDA, which are not in the transcript.\n  - The sentence structures are varied and include some tangents, which are more characteristic of human writing.\n  - The voice is distinctive, with a personal perspective and a conversational tone.\n  - The author references external sources and provides links, indicating a broader knowledge base beyond the transcript.\n\n- **Content Quality:**\n  - The content is relevant and covers the main points from the transcript.\n  - It is clear and engaging, with a conversational tone that maintains reader interest.\n  - The structure is appropriate, with sections and headers that are concise and engaging.\n  - The title and headers are creative and less predictable, adding to the engagement.\n\n**Decision:**\n\nOption 2 shows more characteristics of authentic human writing, with informal language, personal anecdotes, and a distinctive voice. These elements suggest that it was written by a human rather than AI.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.5737577639751553, "r": 0.6142975893599335, "f": 0.5933360096346849}, "rouge-2": {"p": 0.2191142191142191, "r": 0.23460898502495842, "f": 0.22659702691844114}, "rouge-l": {"p": 0.26009316770186336, "r": 0.27847049044056527, "f": 0.2689682858289843}}, "rouge_scores_B": {"rouge-1": {"p": 0.6695035460992907, "r": 0.3923524522028263, "f": 0.4947589098532495}, "rouge-2": {"p": 0.23011363636363635, "r": 0.13477537437603992, "f": 0.16998950682056663}, "rouge-l": {"p": 0.29645390070921984, "r": 0.17373233582709893, "f": 0.21907756813417192}}}, {"index": 24, "video_id": "MX7ymkYGiZ0", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing in Option 1 includes some informal language and a conversational tone, such as \"Once you have a solid understanding\" and \"I finish this post with a concrete example.\"\n- **Personal Anecdotes and Unique Insights:** The post mentions the author's personal research interest in ECG signals, which adds a personal touch and unique insight beyond the transcript.\n- **Varied Sentence Structures:** The sentence structures vary, with some longer explanations and shorter, more direct statements.\n- **Distinctive Voice and Perspective:** The author provides a distinctive voice by referencing their own work and including personal opinions, such as the preference for the Wavelet Transform over the Fourier Transform in certain applications.\n- **Domain-Specific Knowledge:** The post includes specific examples and explanations, such as the use of the Symlet wavelet and the maximal overlap discrete wavelet transform, which suggest a deeper understanding of the topic.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is highly relevant to the video transcript and covers all important points, including the practical application of wavelets in ECG signal analysis.\n- **Clarity and Readability:** The post is clear and easy to read, with well-organized sections and visual aids.\n- **Engagement and Interest:** The inclusion of personal research and practical examples makes the content engaging.\n- **Structure and Titles:** The structure is appropriate, with concise and engaging section headers.\n\n### Option 2 Analysis\n\n**Signs of AI Generation:**\n- **Formulaic Structure and Repetitive Patterns:** The post follows a very structured and predictable format, with clear sections and bullet points that are typical of AI-generated content.\n- **Overly Formal and Generic Language:** The language is formal and lacks the personal touch or informal language that might indicate human authorship.\n- **Exhaustive Lists and Comprehensive Coverage:** The post covers the topic comprehensively but lacks focus on specific insights or personal experiences.\n- **Perfect Grammar and Consistent Tone:** The grammar is perfect throughout, and the tone is consistently formal, which is often a sign of AI writing.\n- **Generic Titles and Headers:** The titles and headers are straightforward and lack the creativity or personal touch that might suggest human authorship.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant and covers the topic thoroughly, but it lacks the depth of personal insight found in Option 1.\n- **Clarity and Readability:** The post is clear and well-structured, but it reads more like a textbook than a personal blog post.\n- **Engagement and Interest:** The lack of personal anecdotes or unique insights makes the content less engaging.\n- **Structure and Titles:** The structure is clear, but the titles and headers are generic and lack personality.\n\n### Decision\n\nBased on the analysis, Option 1 shows more characteristics of authentic human writing, with personal insights, varied sentence structures, and a distinctive voice. Option 2, while technically well-written, exhibits signs of AI generation, such as a formulaic structure and overly formal language.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's analyze each option based on the given criteria.\n\n### Option 1 Analysis\n\n**Signs of Human Authorship vs. AI Generation:**\n- **Human Authenticity:** The writing in Option 1 is very structured and follows a formulaic approach, which is typical of AI-generated content. The language is formal and lacks personal anecdotes or unique insights beyond the transcript. The content is comprehensive but lacks a distinctive voice or perspective.\n- **Sentence Structure:** The sentences are consistently well-structured and grammatically perfect, which is often a sign of AI generation. There is little variation in sentence length or complexity.\n- **Domain-Specific Knowledge:** The post sticks closely to the information provided in the transcript, with no additional insights or domain-specific knowledge that wasn't explicitly mentioned.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant and covers the important points from the transcript. It is clear and readable but lacks engagement and reader interest due to its formal tone.\n- **Structure and Titles:** The structure is appropriate, with clear sections and headers. However, the titles and headers are somewhat generic and could be seen as AI-generated.\n\n### Option 2 Analysis\n\n**Signs of Human Authorship vs. AI Generation:**\n- **Human Authenticity:** Option 2 includes informal language and a more conversational tone, which suggests human authorship. The post references previous blog posts in a series, indicating a personal touch and continuity in content creation. There are personal insights and a distinctive voice, particularly in the introduction and conclusion.\n- **Sentence Structure:** The sentence structure is varied, with a mix of short and long sentences. There are occasional informal phrases and a more relaxed writing style.\n- **Domain-Specific Knowledge:** The post includes additional insights and explanations that go beyond the transcript, such as the mention of the author's research and the practical application of wavelets in ECG signal analysis.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant and covers the key points from the transcript. It is engaging and maintains reader interest through a more narrative style.\n- **Structure and Titles:** The structure is logical, and the titles are concise and engaging. The headers are more creative and less predictable than those in Option 1.\n\n### Decision\n\nBased on the analysis, Option 2 shows more characteristics of authentic human writing. It includes personal insights, a distinctive voice, and a more informal, conversational tone. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.5636237897648686, "r": 0.5084217092950717, "f": 0.5346015086913742}, "rouge-2": {"p": 0.18685121107266436, "r": 0.16853932584269662, "f": 0.1772234985231375}, "rouge-l": {"p": 0.21230982019363762, "r": 0.1915159076731129, "f": 0.20137750081994096}}, "rouge_scores_B": {"rouge-1": {"p": 0.6533333333333333, "r": 0.3056768558951965, "f": 0.416489587760306}, "rouge-2": {"p": 0.21762349799732977, "r": 0.1017478152309613, "f": 0.138664398128456}, "rouge-l": {"p": 0.31333333333333335, "r": 0.14660012476606363, "f": 0.1997450063748406}}}, {"index": 2, "video_id": "_Wjn0gm4g20", "answer": "A", "response": "Based on the analysis of the two blog posts, here is the evaluation:\n\n**Option 1:**\n- **Signs of Human Authorship:**\n  - The writing includes personal anecdotes and opinions, such as the author's struggle to find mentors on LinkedIn and the decision to switch to Upwork.\n  - The post contains informal language and a conversational tone, evident in phrases like \"Ben 'Money Bags' Franklin\" and \"different is the norm here.\"\n  - There are varied sentence structures and occasional tangents, such as the mention of the author's previous experience as a freelancer in grad school.\n  - The post includes unique insights and reflections, like the author's personal takeaways and the emphasis on finding a niche.\n  - The use of a personal image and the phrase \"Image by Author\" suggests a personal touch.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and expands on the themes discussed.\n  - The structure is clear, with sections that align with the video content.\n  - The title and headers are engaging and not overly generic.\n  - The post is complete, covering all major points from the transcript and adding personal insights.\n\n**Option 2:**\n- **Signs of AI Generation:**\n  - The writing is more formal and lacks a distinctive personal voice.\n  - The structure is formulaic, with predictable patterns and comprehensive coverage without much focus.\n  - The language is safe and generic, with less personality and fewer unique insights.\n  - The content closely follows the transcript without adding much beyond what was explicitly stated.\n  - The use of a code snippet seems out of place and more like an attempt to add technical content rather than a natural inclusion.\n\n- **Content Quality:**\n  - The content is relevant and covers the key points from the transcript.\n  - The structure is logical, but the headers and title are somewhat generic.\n  - The post is clear and readable but lacks engagement and a personal touch.\n\n**Decision:**\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, a conversational tone, and unique insights that go beyond the transcript. Therefore, the decision is:\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "Based on the analysis of the two blog posts, here is the evaluation:\n\n**Option 1:**\n- **Signs of Human Authorship vs. AI Generation:**\n  - The writing is structured and follows a clear pattern, which is often indicative of AI-generated content.\n  - The language is formal and lacks personal anecdotes or unique insights beyond the transcript.\n  - The sentence structures are consistent and lack the varied, imperfect nature typical of human writing.\n  - The content closely follows the transcript without adding much personal perspective or domain-specific knowledge.\n  \n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the main points discussed.\n  - The clarity and readability are high, but the engagement level is moderate due to the lack of personal touch.\n  - The structure is appropriate, with clear sections and headers.\n  - The title and headers are concise but somewhat generic.\n\n**Option 2:**\n- **Signs of Human Authorship vs. AI Generation:**\n  - The writing includes personal anecdotes, such as the author's struggle to find mentors on LinkedIn and the decision to use Upwork.\n  - The language is informal and conversational, with phrases like \"Ben 'Money Bags' Franklin\" and \"I\u2019m looking forward to putting these learnings into practice.\"\n  - The sentence structures are varied, with a mix of short and long sentences, and occasional tangents.\n  - The content includes unique insights and reflections, such as the author's personal takeaways and optimism about future transitions.\n  \n- **Content Quality:**\n  - The content is highly relevant and engaging, with a strong personal voice that adds depth to the discussion.\n  - The clarity and readability are good, with a natural flow that keeps the reader interested.\n  - The structure is well-organized, with clear sections and headers that guide the reader through the narrative.\n  - The title and headers are creative and engaging, reflecting a personal touch.\n\n**Decision:**\nOption 2 shows more characteristics of authentic human writing, with personal anecdotes, varied sentence structures, and a distinctive voice. Therefore, the blog post that appears to be written by a human is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.8152709359605911, "r": 0.4934774506149832, "f": 0.6148130949616903}, "rouge-2": {"p": 0.3752310536044362, "r": 0.22706935123042504, "f": 0.2829268292682927}, "rouge-l": {"p": 0.43226600985221675, "r": 0.2616474096161014, "f": 0.32598096122591136}}, "rouge_scores_B": {"rouge-1": {"p": 0.7252747252747253, "r": 0.22139396198285502, "f": 0.33923472301541974}, "rouge-2": {"p": 0.23227383863080683, "r": 0.07084265473527218, "f": 0.10857142857142855}, "rouge-l": {"p": 0.32722832722832723, "r": 0.09988818486768543, "f": 0.15305539691604797}}}, {"index": 18, "video_id": "3PIqhdRzhxE", "answer": "A", "response": "After evaluating both blog posts against the provided transcript and criteria, here is the analysis:\n\n**Option 1:**\n\n- **Signs of Human Authorship:**\n  - The writing includes personal anecdotes and opinions, such as the author's initial disappointment with using Google Colab and the excitement upon discovering the MLX library.\n  - There are informal language and reasonable tangents, like the mention of the author's Mac Mini being \"hilarious\" by today's standards and the cooking show analogy.\n  - The post contains varied sentence structures and a distinctive voice, with a conversational tone and personal insights.\n  - The author shares unique insights and domain-specific knowledge, such as the challenges of fine-tuning on Mac and the specific adjustments made to the LoRA script.\n  - The post includes specific examples and personal experiences that go beyond the transcript, like the detailed explanation of the data preparation process and the personal response style.\n\n- **Content Quality:**\n  - The content is highly relevant to the video transcript, covering the same topics and expanding on them with additional details.\n  - The writing is clear and engaging, with a structure that follows the process of fine-tuning step-by-step.\n  - The post is complete, covering all important points from the video and adding personal insights.\n  - The title and section headers are concise and engaging, fitting the content naturally.\n\n**Option 2:**\n\n- **Signs of AI Generation:**\n  - The writing follows a formulaic structure with repetitive sentence patterns, such as the step-by-step instructions that lack personal anecdotes or informal language.\n  - The language is overly formal and lacks personality, with generic observations and a consistent tone throughout.\n  - The content is exhaustive and comprehensive but lacks focus on personal experiences or unique insights.\n  - The information is mostly what is explicitly stated in the transcript, with little additional personal input or domain-specific knowledge.\n  - The title and section headers are generic and predictable, lacking the distinctive voice of a human author.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript but lacks the depth and engagement of personal insights.\n  - The writing is clear and readable but not particularly engaging or interesting.\n  - The post is complete in terms of covering the process but lacks the personal touch and distinctive voice of a human author.\n\n**Decision:**\n\nBased on the analysis, **Option 1** shows more characteristics of authentic human writing, with personal anecdotes, informal language, and unique insights that go beyond the transcript. Therefore, the decision is:\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- The writing is structured in a very formal and instructional manner, which is typical of AI-generated content. \n- The language is consistently formal and lacks personal anecdotes or unique insights beyond the technical explanation.\n- The content follows a predictable pattern with clear sections and steps, which is a common trait of AI-generated content.\n- There is no use of personal experiences or opinions, and the content strictly adheres to the technical aspects of the transcript.\n\n**Content Quality:**\n- The content is relevant to the video transcript and covers the technical aspects of fine-tuning LLMs on a Mac.\n- The structure is clear, with sections and steps that are easy to follow.\n- The title and headers are concise but lack a personal touch or engaging elements that would suggest human authorship.\n\n### Option 2 Analysis:\n\n**Signs of Human Authorship:**\n- The writing includes personal anecdotes and opinions, such as the author's experience with MLX and their initial struggles with fine-tuning on a Mac.\n- The language is more informal and conversational, with occasional tangents and personal insights, which are indicative of human writing.\n- The author references their own previous work and provides links to other articles, suggesting a personal connection to the content.\n- There is a distinctive voice and perspective, with the author sharing their journey and thoughts on the process, which goes beyond the transcript.\n\n**Content Quality:**\n- The content is highly relevant to the video transcript and expands on the technical details with personal insights.\n- The structure is clear, but the writing style is more engaging and varied, which keeps the reader interested.\n- The title and headers are engaging and reflect a personal touch, making them less likely to be AI-generated.\n\n### Decision:\n\nOption 2 shows more characteristics of authentic human writing, with personal anecdotes, a conversational tone, and a distinctive voice. These elements suggest that it was written by a human rather than generated by AI.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7295308187672493, "r": 0.3228170160797883, "f": 0.44758007619585155}, "rouge-2": {"p": 0.3294983893235159, "r": 0.1457654723127036, "f": 0.20211714890613974}, "rouge-l": {"p": 0.31922723091076355, "r": 0.14125788723794017, "f": 0.19585155919288838}}, "rouge_scores_B": {"rouge-1": {"p": 0.795774647887324, "r": 0.11500101770812131, "f": 0.20096034145473946}, "rouge-2": {"p": 0.34132581100141046, "r": 0.0492671009771987, "f": 0.08610567514677103}, "rouge-l": {"p": 0.36619718309859156, "r": 0.052920822308162016, "f": 0.09247732527120754}}}, {"index": 10, "video_id": "0cf7vzM_dZ0", "answer": "A", "response": "Based on the analysis of the two blog posts, here is the evaluation:\n\n**Option 1:**\n- **Signs of Human Authorship:**\n  - The writing includes personal anecdotes and opinions, such as the author's initial skepticism about prompt engineering and how their perspective changed over time.\n  - The language is informal and conversational at times, with phrases like \"Prompt engineering? Psssh, that\u2019s lame.\"\n  - There are reasonable tangents, such as the discussion about the limitations of prompt engineering and the mention of future articles in the series.\n  - The writing style has a distinctive voice, with a mix of technical explanations and personal insights.\n  - The content includes domain-specific knowledge and insights that go beyond the transcript, such as the detailed explanation of LangChain and the Python code examples.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers all the important points discussed in the video.\n  - The structure is appropriate, with clear section headers and a logical flow of information.\n  - The title and section headers are engaging and do not appear AI-generated.\n  - The writing is clear and engaging, with a good balance of technical detail and readability.\n\n**Option 2:**\n- **Signs of AI Generation:**\n  - The writing is more formal and lacks the informal, conversational tone seen in Option 1.\n  - The language is safe and generic, with less personality and distinctive voice.\n  - The structure is formulaic, with predictable patterns and comprehensive coverage that lacks focus.\n  - The content closely follows the information explicitly stated in the transcript, with little additional insight or personal perspective.\n  - The grammar is perfect and the tone is consistent throughout, which is typical of AI-generated content.\n\n- **Content Quality:**\n  - The content is relevant and covers the key points from the video transcript.\n  - The structure is clear, but the writing lacks engagement and reader interest compared to Option 1.\n  - The title and section headers are concise but lack the engaging and natural-sounding quality of Option 1.\n\n**Decision:**\nOption 1 shows more characteristics of authentic human writing, with personal insights, informal language, and a distinctive voice. Therefore, the blog post in Option 1 is more likely to be written by a human.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing is formal and structured, with a clear and consistent tone throughout, which is a common pattern in AI-generated content.\n  - The article lacks personal anecdotes or unique insights beyond the transcript, focusing instead on a comprehensive overview of prompt engineering.\n  - The sentence structures are varied but follow a predictable pattern, and the language is safe and generic.\n  - The content sticks closely to the information provided in the transcript, without introducing new perspectives or domain-specific knowledge not mentioned in the video.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the key points discussed in the video.\n  - The structure is clear, with appropriate section headers and a logical flow.\n  - The title and headers are concise and relevant but lack a distinctive, engaging style that might suggest human authorship.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing includes informal language and a conversational tone, such as \"Prompt engineering? Psssh, that\u2019s lame,\" which suggests a human touch.\n  - The author shares personal opinions and experiences, such as initially scoffing at prompt engineering, which adds a personal dimension not present in the transcript.\n  - The sentence structures are varied and include reasonable tangents, such as discussing the limitations of prompt engineering and the potential for fine-tuning.\n  - The article includes unique insights and a distinctive voice, with humor and personality, such as the playful title \"How to Trick AI into Solving Your Problems.\"\n\n- **Content Quality:**\n  - The content is relevant and covers the main points from the video, but it also expands on them with additional insights and examples.\n  - The structure is clear, with engaging section headers that reflect a human touch.\n  - The writing is engaging and maintains reader interest through humor and a conversational style.\n\n**Decision:**\n\nOption 2 shows more characteristics of authentic human writing, with informal language, personal anecdotes, and a distinctive voice. It includes unique insights and a conversational tone that are less typical of AI-generated content. Therefore, Option 2 is more likely to be written by a human.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7734138972809668, "r": 0.46948982994331445, "f": 0.5842929764498391}, "rouge-2": {"p": 0.37335164835164836, "r": 0.22661330665332666, "f": 0.2820379786240531}, "rouge-l": {"p": 0.3367206811315573, "r": 0.20440146715571858, "f": 0.2543832347753916}}, "rouge_scores_B": {"rouge-1": {"p": 0.8726919339164237, "r": 0.14971657219073026, "f": 0.25558559840614775}, "rouge-2": {"p": 0.4173151750972763, "r": 0.07153576788394198, "f": 0.12213523131672599}, "rouge-l": {"p": 0.4489795918367347, "r": 0.07702567522507503, "f": 0.13149281343389782}}}, {"index": 3, "video_id": "pNg2DJ4spXg", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing includes informal language and personal anecdotes, such as the author's experience using ChatGPT to write code and explain error messages. This adds a personal touch that is less common in AI-generated content.\n- **Personal Anecdotes and Opinions:** The author shares personal insights, such as their own journey as a self-taught Python programmer and their use of ChatGPT as a coding assistant.\n- **Varied Sentence Structures:** The text includes varied sentence structures and occasional tangents, such as the mention of using ChatGPT and Google for coding assistance.\n- **Distinctive Voice and Perspective:** The author provides a unique perspective by discussing their personal experiences and offering specific advice for beginners.\n- **Domain-Specific Knowledge:** The post includes specific advice and insights that go beyond the transcript, such as the recommendation to use Jupyter Notebooks and the mention of specific Python libraries.\n\n**Content Quality:**\n- **Relevance to Video Content:** The content closely follows the video transcript, covering Python basics and an AI project example.\n- **Clarity and Readability:** The post is well-structured and easy to follow, with clear explanations and examples.\n- **Engagement and Reader Interest:** The use of personal anecdotes and practical advice makes the content engaging.\n- **Completeness of Important Points:** The post covers all the key points from the video, including Python installation, data types, and an AI project example.\n- **Factual Accuracy:** The information is accurate and aligns with the video transcript.\n- **Appropriate Structure:** The post is well-organized with clear section headers and concise paragraphs.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure and Repetitive Patterns:** The post follows a predictable structure with a formal tone and lacks the personal touch found in Option 1.\n- **Overly Formal, Safe, or Generic Language:** The language is more formal and lacks the distinctive voice and personal anecdotes present in Option 1.\n- **Exhaustive Lists and Comprehensive Coverage:** The post covers Python basics and an AI project example but lacks the depth and personal insights found in Option 1.\n- **Only Information Explicitly Stated in the Transcript:** The content closely follows the video transcript without adding unique insights or personal experiences.\n- **Perfect Grammar and Consistent Tone:** The writing is grammatically perfect and maintains a consistent tone throughout, which is typical of AI-generated content.\n- **Generic, Predictable Titles and Headers:** The titles and headers are straightforward and lack the creativity and engagement found in Option 1.\n\n**Content Quality:**\n- **Relevance to Video Content:** The content is relevant and covers the key points from the video.\n- **Clarity and Readability:** The post is clear and easy to read, with well-organized sections.\n- **Engagement and Reader Interest:** The content is informative but lacks the engaging personal touch of Option 1.\n- **Completeness of Important Points:** The post covers the main points from the video but lacks additional insights.\n- **Factual Accuracy:** The information is accurate and aligns with the video transcript.\n- **Appropriate Structure:** The post is well-structured with clear section headers and concise paragraphs.\n\n### Decision:\n\nBased on the analysis, **Option 1** shows more characteristics of authentic human writing, including personal anecdotes, varied sentence structures, and a distinctive voice. Therefore, I conclude that Option 1 is more likely written by a human.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "After evaluating both blog posts against the provided transcript and criteria, here is the analysis:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing is structured and follows a formulaic pattern, which is a common sign of AI-generated content.\n  - The language is formal and lacks personal anecdotes or unique insights beyond the transcript.\n  - The sentence structures are consistent and predictable, lacking the varied sentence structures typical of human writing.\n  - The content sticks closely to the information provided in the transcript, without adding personal opinions or domain-specific knowledge.\n  - The voice is generic and lacks a distinctive perspective.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the basics of Python for AI projects.\n  - The clarity and readability are high, but the engagement level is low due to the lack of personal touch.\n  - The structure is appropriate, with clear sections and headers.\n  - The title and headers are concise but appear somewhat generic and AI-generated.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing includes informal language and personal anecdotes, such as the author's experience with Python and AI tools.\n  - There are unique insights and opinions, such as the mention of using ChatGPT as a coding assistant and the author's personal journey in learning Python.\n  - The sentence structures are varied, with a mix of short and long sentences, and occasional tangents that add a human touch.\n  - The voice is distinctive, with a clear perspective and personal engagement with the topic.\n  - The content includes domain-specific knowledge and practical tips that go beyond the transcript.\n\n- **Content Quality:**\n  - The content is highly relevant to the video transcript and provides a comprehensive guide to getting started with Python for AI.\n  - The clarity and readability are excellent, with engaging and interesting content.\n  - The structure is well-organized, with appropriate sections and headers.\n  - The title and headers are engaging and natural-sounding, with a human touch.\n\n**Decision:**\n\nBased on the analysis, Option 2 shows more characteristics of authentic human writing, with personal anecdotes, unique insights, varied sentence structures, and a distinctive voice. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.81136638452237, "r": 0.3178964822930238, "f": 0.4568121861969194}, "rouge-2": {"p": 0.3655881463562141, "r": 0.14321250888415069, "f": 0.2058047493403694}, "rouge-l": {"p": 0.3848246674727932, "r": 0.1507757905957598, "f": 0.21666241170964173}}, "rouge_scores_B": {"rouge-1": {"p": 0.8489968321013728, "r": 0.09522681511311146, "f": 0.17124600638977636}, "rouge-2": {"p": 0.37420718816067655, "r": 0.04193319118692253, "f": 0.0754154239454623}, "rouge-l": {"p": 0.4604012671594509, "r": 0.051640412175766905, "f": 0.09286474973375931}}}, {"index": 6, "video_id": "bAe4qwQGxlI", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing includes informal language and personal anecdotes, such as the author's financial motivation and personal experiences with the tools.\n- **Personal Anecdotes and Unique Insights:** The author shares personal motivations, like their savings running low and the decision to launch a product every month. They also mention specific tools and their personal experiences with them, such as using Cursor and ChatGPT.\n- **Varied Sentence Structures:** The writing style varies, with a mix of short and long sentences, and includes some informal expressions like \"\ud83d\ude05\" to convey emotion.\n- **Distinctive Voice and Perspective:** The author provides a personal perspective on the challenges faced and the learning process, which adds a unique voice to the content.\n- **Domain-Specific Knowledge:** The author discusses specific tools and libraries, such as FastHTML and Google OAuth, and provides insights into their usage beyond what is in the transcript.\n\n**Content Quality:**\n- **Relevance to Video Content:** The blog closely follows the video transcript, expanding on the process and tools used.\n- **Clarity and Readability:** The content is clear and easy to follow, with a logical progression of ideas.\n- **Engagement and Reader Interest:** The use of personal stories and challenges makes the content engaging.\n- **Completeness of Important Points:** The blog covers all major points from the video, with additional insights and personal experiences.\n- **Factual Accuracy:** The content aligns with the video transcript and provides accurate information about the tools and process.\n- **Appropriate Structure:** The structure is well-organized, with clear sections and headers.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure and Repetitive Patterns:** The blog follows a predictable structure with a consistent tone and style throughout.\n- **Overly Formal, Safe, or Generic Language:** The language is more formal and lacks the personal touch and informal expressions found in Option 1.\n- **Exhaustive Lists and Comprehensive Coverage:** The content is comprehensive but lacks focus on personal experiences or unique insights.\n- **Only Information Explicitly Stated in the Transcript:** The blog closely follows the transcript without adding much personal perspective or anecdotes.\n- **Perfect Grammar and Consistent Tone:** The writing is grammatically perfect and maintains a consistent tone, which is typical of AI-generated content.\n- **Generic, Predictable Titles and Headers:** The titles and headers are straightforward and lack the creativity or personal touch seen in human writing.\n\n**Content Quality:**\n- **Relevance to Video Content:** The blog is relevant and covers the main points from the video.\n- **Clarity and Readability:** The content is clear and easy to read, with a logical flow.\n- **Engagement and Reader Interest:** The lack of personal anecdotes and unique insights makes the content less engaging.\n- **Completeness of Important Points:** The blog covers the important points but lacks depth in personal experiences.\n- **Factual Accuracy:** The content is factually accurate and aligns with the video transcript.\n- **Appropriate Structure:** The structure is organized, but the headers and sections are more generic.\n\n### Decision:\n\nBased on the analysis, **Option 1** shows more characteristics of authentic human writing. It includes personal anecdotes, a distinctive voice, varied sentence structures, and domain-specific knowledge that goes beyond the transcript. In contrast, **Option 2** exhibits signs of AI authorship, such as a formulaic structure, consistent tone, and lack of personal insights.\n\n<answer>A</answer>", "answer_swapped": "B", "response_swapped": "Based on the analysis of the two blog posts, here is the evaluation:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing style in Option 1 includes personal anecdotes and insights, such as the author's feelings of being \"a fish out of water\" and the mention of savings dwindling, which adds a personal touch.\n  - The narrative includes varied sentence structures and occasional informal language, such as \"knee-deep in data processing\" and \"tackle this challenge head-on.\"\n  - The post includes a distinctive voice and perspective, with the author sharing their journey and lessons learned, which goes beyond the transcript.\n  - The use of domain-specific knowledge, such as the mention of specific tools like Fast HTML and Google OAuth, is presented in a way that suggests personal experience rather than just information from the transcript.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the key points discussed in the video.\n  - The structure is clear, with appropriate section headers and a logical flow of information.\n  - The title and section headers are engaging and do not appear AI-generated, such as \"Building a YouTube Video to Blog Post Converter in Just Four Days.\"\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing in Option 2 is more formulaic and follows a predictable pattern, with a consistent tone and perfect grammar throughout.\n  - The language is more formal and lacks the personal anecdotes or unique insights that are present in Option 1.\n  - The content closely follows the information explicitly stated in the transcript, with less evidence of personal experience or distinctive voice.\n  - The use of tools and processes is described in a straightforward manner, without the personal touch or varied sentence structures seen in Option 1.\n\n- **Content Quality:**\n  - The content is relevant and covers the main points from the transcript.\n  - The structure is clear, but the section headers and overall tone are more generic and less engaging than in Option 1.\n  - The title and headers, such as \"I Built an AI App in 4 Days \u2014 Here\u2019s How I Did It,\" are more predictable and lack the engaging quality of Option 1.\n\n**Decision:**\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, varied sentence structures, and a distinctive voice. Therefore, the blog post in Option 1 is more likely to be written by a human.\n\n<answer>A</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7299270072992701, "r": 0.5275498241500586, "f": 0.6124532153793808}, "rouge-2": {"p": 0.3717532467532468, "r": 0.2686217008797654, "f": 0.3118828736806265}, "rouge-l": {"p": 0.4468775344687753, "r": 0.32297772567409144, "f": 0.37495746852670975}}, "rouge_scores_B": {"rouge-1": {"p": 0.7761194029850746, "r": 0.365767878077374, "f": 0.4972111553784861}, "rouge-2": {"p": 0.33374844333748444, "r": 0.15718475073313784, "f": 0.21371610845295055}, "rouge-l": {"p": 0.4228855721393035, "r": 0.19929660023446658, "f": 0.2709163346613546}}}, {"index": 13, "video_id": "czvVibB2lRA", "answer": "A", "response": "Based on the analysis of the two blog posts, here is the evaluation:\n\n**Option 1:**\n\n- **Signs of Human Authorship:**\n  - The writing includes personal anecdotes and informal language, such as the analogy of craving pupusas and texting a foodie friend, which adds a personal touch and makes the content relatable.\n  - The post contains varied sentence structures and a distinctive voice, particularly in the way it explains technical concepts with simple analogies.\n  - There are unique insights and domain-specific knowledge, such as the detailed explanation of tokens and pricing, which go beyond the transcript.\n  - The post includes tangents and informal asides, like the note about revoking the API key, which are typical of human writing.\n\n- **Content Quality:**\n  - The content is highly relevant to the video transcript, covering all the key points discussed in the video.\n  - The structure is clear, with well-defined sections and headers that are engaging and not overly formal.\n  - The post is complete, covering both the basics and more advanced topics, and it maintains reader interest with engaging examples and explanations.\n\n**Option 2:**\n\n- **Signs of AI Authorship:**\n  - The writing is more formal and lacks the personal touch and informal language seen in Option 1.\n  - The structure is formulaic, with predictable patterns and a lack of distinctive voice or perspective.\n  - The content sticks closely to the information in the transcript without adding unique insights or personal anecdotes.\n  - The language is safe and generic, with perfect grammar and consistent tone throughout, which is typical of AI-generated content.\n\n- **Content Quality:**\n  - The content is relevant and covers the basics of the OpenAI Python API, but it lacks the depth and engagement seen in Option 1.\n  - The structure is clear, but the headers and sections are more generic and less engaging.\n  - The post is complete but lacks the unique insights and engaging examples that make Option 1 more interesting to read.\n\n**Decision:**\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, varied sentence structures, and a distinctive voice. It goes beyond the transcript with unique insights and informal language, making it more engaging and relatable. Therefore, Option 1 is more likely to be written by a human.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1: \"Getting Started with OpenAI's Python API\"\n\n**Signs of Human Authorship:**\n- The writing is structured and follows a clear, logical progression, but it lacks personal anecdotes or unique insights beyond the transcript.\n- The language is formal and lacks informal language or tangents that might indicate a human touch.\n- The content is comprehensive and covers all necessary points, but it does so in a way that feels formulaic and predictable.\n- The sentence structures are varied but follow a consistent pattern, which is typical of AI-generated content.\n- The headers and sections are clear and relevant but lack a distinctive voice or perspective.\n\n**Content Quality:**\n- The content is relevant to the video transcript and covers all important points.\n- The clarity and readability are high, with well-organized sections and examples.\n- The engagement level is moderate, as the content is informative but lacks a personal touch or engaging narrative.\n- The factual accuracy is maintained throughout, with appropriate examples and explanations.\n\n### Option 2: \"Cracking Open the OpenAI (Python) API\"\n\n**Signs of Human Authorship:**\n- The writing includes informal language and personal anecdotes, such as the pupusa analogy, which adds a human touch.\n- The author shares opinions and insights, such as the potential downsides of using OpenAI's API and the mention of open-source alternatives.\n- The sentence structures are varied and include some informal and conversational elements, suggesting a human author.\n- The content includes domain-specific knowledge and insights that go beyond the transcript, such as the discussion on tokenization and pricing.\n- The headers and sections are engaging and have a distinctive voice, with creative titles like \"Cracking Open the OpenAI (Python) API.\"\n\n**Content Quality:**\n- The content is highly relevant to the video transcript and expands on it with additional insights and examples.\n- The clarity and readability are high, with a conversational tone that engages the reader.\n- The engagement level is high, with personal anecdotes and a narrative style that draws the reader in.\n- The factual accuracy is maintained, with detailed explanations and examples.\n- The structure is appropriate, with concise and engaging titles and headers.\n\n### Decision\n\nOption 2 shows more characteristics of authentic human writing, with informal language, personal anecdotes, and a distinctive voice. It also includes unique insights and opinions that go beyond the transcript, suggesting a human author. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.6982585398526456, "r": 0.4378412431751365, "f": 0.5382034073309241}, "rouge-2": {"p": 0.32060301507537686, "r": 0.2010081915563957, "f": 0.24709527498063513}, "rouge-l": {"p": 0.3198258539852646, "r": 0.2005459890802184, "f": 0.24651522973670625}}, "rouge_scores_B": {"rouge-1": {"p": 0.8155784650630011, "r": 0.1495170096598068, "f": 0.25270629991126886}, "rouge-2": {"p": 0.2958715596330275, "r": 0.05419029615626969, "f": 0.0916030534351145}, "rouge-l": {"p": 0.38258877434135163, "r": 0.07013859722805543, "f": 0.11854480922803903}}}, {"index": 26, "video_id": "ZLbVdvOoTKM", "answer": "A", "response": "Analyzing the two blog posts, here are the observations:\n\n**Option 1:**\n\n- **Signs of Human Authorship:**\n  - The writing style includes informal language and personal opinions, such as \"Although this is not necessary (IMO) for >99% of LLM applications\" and \"Now that you\u2019ve realized you do not want to train an LLM from scratch (or maybe you still do, IDK)\".\n  - The use of first-person perspective and casual expressions like \"back-of-the-napkin math\" and \"Needless to say\" suggest a more conversational tone typical of human writing.\n  - The article includes a personal touch with phrases like \"Note: please do not harm bats,\" which adds a unique voice and perspective.\n  - There are varied sentence structures and occasional tangents, such as the detailed explanation of transformers and the anecdotal style in discussing data curation.\n\n- **Content Quality:**\n  - The content is highly relevant to the video transcript, covering all major points discussed in the video.\n  - The structure is clear, with well-defined sections and headers that are engaging and not overly formal.\n  - The article is comprehensive, yet it maintains reader interest with engaging language and examples.\n  - The use of domain-specific knowledge is evident, with detailed explanations of technical concepts like transformers and training techniques.\n\n**Option 2:**\n\n- **Signs of AI Authorship:**\n  - The writing is more formal and structured, with a consistent tone throughout, which is typical of AI-generated content.\n  - The language is safe and lacks the informal, personal touch seen in Option 1.\n  - The article follows a formulaic structure with predictable patterns, such as listing steps and considerations without much deviation or personal insight.\n  - The content is comprehensive but lacks the distinctive voice and perspective that would suggest human authorship.\n\n- **Content Quality:**\n  - The content is relevant and covers the key aspects of building LLMs, as discussed in the video.\n  - The structure is logical, with clear sections and headers, but it feels more generic and less engaging.\n  - The article is factually accurate and complete, but it lacks the engaging and varied sentence structures seen in Option 1.\n\n**Decision:**\n\nOption 1 shows more characteristics of authentic human writing, with its informal language, personal insights, and varied sentence structures. It has a distinctive voice and perspective, which are indicative of human authorship. Therefore, the decision is:\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "<option_1> appears to be AI-generated content. It exhibits several characteristics typical of AI writing, such as a formulaic structure, exhaustive lists, and comprehensive coverage that lacks focus. The language is overly formal and lacks personality, with perfect grammar and a consistent tone throughout. The content strictly follows the information provided in the transcript without adding personal anecdotes, opinions, or unique insights. The titles and headers are generic and overly explanatory, which is another common pattern in AI-generated content.\n\n<option_2> shows more signs of human authorship. It includes informal language and occasional tangents, such as the use of \"back-of-the-napkin math\" and \"IDK,\" which add a personal touch. The writing style is more conversational and less structured, with varied sentence structures and a distinctive voice. The author provides personal opinions, such as stating that building an LLM from scratch is not necessary for most applications. The content also includes unique insights and domain-specific knowledge that go beyond the transcript, such as the mention of specific datasets and the challenges of data curation.\n\nBased on these observations, <option_2> demonstrates more characteristics of authentic human writing.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7435041716328963, "r": 0.4952365830422356, "f": 0.5944915658057752}, "rouge-2": {"p": 0.3261802575107296, "r": 0.21724630776560266, "f": 0.2607949671146697}, "rouge-l": {"p": 0.3470798569725864, "r": 0.23118450301683074, "f": 0.27751834556370913}}, "rouge_scores_B": {"rouge-1": {"p": 0.8360655737704918, "r": 0.12956494125119086, "f": 0.22436073687104757}, "rouge-2": {"p": 0.3292307692307692, "r": 0.050976655550262026, "f": 0.08828382838283828}, "rouge-l": {"p": 0.45286885245901637, "r": 0.07018100984439504, "f": 0.12152873247181742}}}, {"index": 11, "video_id": "jan07gloaRg", "answer": "B", "response": "Analyzing the two blog posts based on the provided criteria and the transcript, here are the observations:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing style is detailed and technical, with a focus on explaining the Hugging Face Transformers Library. However, it lacks personal anecdotes or unique insights beyond the transcript.\n  - The structure is formulaic, with a clear, step-by-step guide that mirrors the transcript closely.\n  - The language is formal and consistent, with no informal language or tangents that would suggest a human touch.\n  - The content is comprehensive and covers all aspects mentioned in the transcript, but it does not introduce new perspectives or domain-specific knowledge beyond what is explicitly stated.\n\n- **Content Quality:**\n  - The content is relevant and accurately reflects the video transcript.\n  - The structure is clear, with appropriate use of headers and sections.\n  - The engagement level is moderate, focusing on technical details without much variation in tone or style.\n  - The title and headers are straightforward and descriptive, but they lack creativity or a distinctive voice.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing includes a personal touch, with the author mentioning their fascination with NLP and LLMs, which adds a personal perspective.\n  - The language is more varied, with a mix of formal and informal tones, and includes some conversational elements.\n  - The structure is less rigid, with some sections flowing more naturally and including opinions or insights not directly from the transcript.\n  - There is a distinctive voice, with the author expressing excitement about the potential of the Hugging Face Transformers Library.\n\n- **Content Quality:**\n  - The content is relevant and covers the main points from the transcript, but it also adds additional context and examples.\n  - The structure is clear, with engaging and varied sentence structures.\n  - The engagement level is higher, with a more dynamic writing style that keeps the reader interested.\n  - The title and headers are creative and engaging, suggesting a human touch.\n\n**Decision:**\n\nOption 2 shows more characteristics of authentic human writing, with personal insights, varied language, and a distinctive voice. It goes beyond the transcript by adding personal opinions and a more engaging writing style.\n\n<answer>B</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1: Leveraging the Hugging Face Transformers Library for NLP Applications\n\n**Signs of Human Authorship:**\n- The writing is highly structured and follows a formulaic pattern, which is typical of AI-generated content. Each section is neatly divided with clear headers and subheaders, and the content is presented in a very organized manner.\n- The language is formal and lacks personal anecdotes or unique insights that go beyond the transcript. It sticks closely to the information provided in the transcript.\n- The sentence structures are consistent and lack the varied sentence structures that might indicate a human touch.\n- The content is comprehensive and covers a wide range of topics, which is a common trait of AI-generated content that aims to be exhaustive.\n\n**Content Quality:**\n- The content is relevant to the video transcript and covers the key points discussed in the video.\n- It is clear and readable, with a logical flow from one section to the next.\n- The engagement level is moderate, as the content is informative but lacks a personal touch that might make it more engaging.\n- The structure is appropriate, with sections divided into paragraphs and concise headers.\n\n### Option 2: Cracking Open the Hugging Face Transformers Library\n\n**Signs of Human Authorship:**\n- The writing includes informal language and personal touches, such as the use of \"I\" and references to previous articles in a series, which suggests a human author.\n- There are personal insights and opinions, such as the mention of the author's experience with the OpenAI Python API and the cost considerations of API calls.\n- The sentence structures are varied, with a mix of short and long sentences, and the writing style is more conversational.\n- The content includes domain-specific knowledge and insights that are not explicitly stated in the transcript, such as the mention of specific models and their applications.\n\n**Content Quality:**\n- The content is highly relevant to the video transcript and expands on the topics discussed in the video.\n- It is clear and readable, with a conversational tone that makes it engaging for readers.\n- The structure is appropriate, with sections divided into paragraphs and concise headers.\n- The content is complete and covers important points, with additional insights that add value to the reader.\n\n### Decision\n\nBased on the analysis, Option 2 shows more characteristics of authentic human writing. It includes personal insights, varied sentence structures, and a conversational tone that suggests a human author. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7307245253777606, "r": 0.44220398593200466, "f": 0.5509786736780602}, "rouge-2": {"p": 0.3453488372093023, "r": 0.20895872420262665, "f": 0.2603740502630041}, "rouge-l": {"p": 0.3448275862068966, "r": 0.20867526377491208, "f": 0.2600058428279287}}, "rouge_scores_B": {"rouge-1": {"p": 0.7995391705069125, "r": 0.1627198124267292, "f": 0.2704071692967076}, "rouge-2": {"p": 0.31257208765859285, "r": 0.06355534709193246, "f": 0.10563243032547262}, "rouge-l": {"p": 0.3813364055299539, "r": 0.0776084407971864, "f": 0.1289694135982856}}}, {"index": 30, "video_id": "tufdEUSjmNI", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Human Authenticity:**\n- The writing in Option 1 includes informal language and personal insights, such as the analogy of the ice cube and puddle, which is explained in a relatable manner.\n- The post contains varied sentence structures and a distinctive voice, particularly in the sections where the author discusses the challenges of causal discovery and the limitations of certain algorithms.\n- There are personal touches, like the author's commentary on the field being young and the potential of causal discovery, which suggests a human perspective.\n- The use of domain-specific knowledge, such as the detailed explanation of the PC algorithm and the inclusion of Python code, goes beyond the transcript.\n\n**Content Quality:**\n- The content is relevant to the video transcript and expands on the topics discussed, providing a comprehensive overview of causal discovery.\n- The structure is logical, with clear section headers and a progression from theory to practical application.\n- The post is engaging, with the use of images and code examples to illustrate points.\n- The title and section headers are concise and engaging, fitting the content well.\n\n### Option 2 Analysis:\n\n**Human Authenticity:**\n- The writing in Option 2 is more formal and structured, with less variation in sentence structure and a more predictable flow.\n- The language is safe and lacks the personal anecdotes or unique insights that would suggest a human author.\n- The content closely follows the transcript, with little additional commentary or personal perspective.\n- The explanations are clear but lack the distinctive voice or informal touches that would indicate human authorship.\n\n**Content Quality:**\n- The content is relevant and covers the key points from the transcript, but it feels more like a summary than an exploration.\n- The structure is clear, with well-defined sections, but it lacks the engagement and depth found in Option 1.\n- The title and section headers are straightforward but lack the creativity or engagement of Option 1.\n\n### Decision:\n\nOption 1 shows more characteristics of authentic human writing, with its informal language, personal insights, varied sentence structures, and distinctive voice. It goes beyond the transcript to provide a more engaging and comprehensive exploration of causal discovery. Therefore, the decision is:\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1 Analysis\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing is very structured and formal, with no noticeable informal language or tangents. This suggests a lack of human-like imperfections.\n- **Personal Anecdotes, Opinions, or Unique Insights:** The post lacks personal anecdotes or opinions. It sticks closely to the technical content, which is typical of AI-generated content.\n- **Varied Sentence Structures:** The sentence structures are consistent and follow a predictable pattern, which is a common trait of AI writing.\n- **Distinctive Voice and Perspective:** The voice is generic and lacks a distinctive personal touch.\n- **Use of Domain-Specific Knowledge:** The content is comprehensive and technical, but it closely follows the transcript without adding new insights or domain-specific knowledge beyond what is presented.\n\n**Content Quality:**\n- **Relevance to the Video Content:** The content is highly relevant and aligns well with the video transcript.\n- **Clarity and Readability:** The post is clear and easy to read, with well-organized sections.\n- **Engagement and Reader Interest:** The post is informative but lacks engaging elements that would capture reader interest beyond the technical details.\n- **Completeness of Important Points:** It covers the important points thoroughly.\n- **Factual Accuracy:** The information is accurate and aligns with the transcript.\n- **Appropriate Structure:** The structure is appropriate, with clear sections and headers.\n- **Title and Headers:** The title and headers are clear but lack creativity, appearing somewhat formulaic.\n\n### Option 2 Analysis\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing includes informal language and a conversational tone, which is more indicative of human authorship.\n- **Personal Anecdotes, Opinions, or Unique Insights:** The post includes personal insights and a more narrative style, suggesting a human touch.\n- **Varied Sentence Structures:** The sentence structures are varied and less predictable, which is characteristic of human writing.\n- **Distinctive Voice and Perspective:** The voice is more distinctive and personal, with a clear perspective that goes beyond the transcript.\n- **Use of Domain-Specific Knowledge:** The post includes additional insights and explanations that are not directly lifted from the transcript, indicating a deeper understanding of the topic.\n\n**Content Quality:**\n- **Relevance to the Video Content:** The content is relevant and aligns with the video transcript.\n- **Clarity and Readability:** The post is clear and readable, with a more engaging style.\n- **Engagement and Reader Interest:** The narrative style and personal insights make the post more engaging.\n- **Completeness of Important Points:** It covers the important points but also adds additional context and insights.\n- **Factual Accuracy:** The information is accurate and aligns with the transcript.\n- **Appropriate Structure:** The structure is appropriate, with clear sections and headers.\n- **Title and Headers:** The title and headers are concise and engaging, with a more human touch.\n\n### Decision\n\nBased on the analysis, **Option 2** shows more characteristics of authentic human writing, including a conversational tone, personal insights, varied sentence structures, and a distinctive voice. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.6114074681986048, "r": 0.5217086834733894, "f": 0.5630077460797279}, "rouge-2": {"p": 0.2467159277504105, "r": 0.210507880910683, "f": 0.2271782271782272}, "rouge-l": {"p": 0.23717685679113665, "r": 0.20238095238095238, "f": 0.2184016625732099}}, "rouge_scores_B": {"rouge-1": {"p": 0.752, "r": 0.23039215686274508, "f": 0.3527204502814259}, "rouge-2": {"p": 0.28832951945080093, "r": 0.08826619964973731, "f": 0.13515687851971037}, "rouge-l": {"p": 0.38171428571428573, "r": 0.1169467787114846, "f": 0.17904047172339854}}}, {"index": 23, "video_id": "tMiQIxSX64c", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- The writing style in Option 1 is somewhat informal and includes personal touches, such as the use of emojis (e.g., \"if I ever get around to it \ud83d\ude05\") and casual language (\"My watch later playlist is not the only place I hoard technical information\").\n- The author shares personal experiences and opinions, such as mentioning their own \"watch later\" playlist and desktop clutter, which adds a personal touch and suggests a human perspective.\n- The post includes a call to action at the end, inviting readers to ask questions in the comments, which is a common human touch in blog writing.\n- There are occasional informal language choices and a conversational tone, which are less typical of AI-generated content.\n\n**Content Quality:**\n- The content is relevant to the video transcript and covers the same projects mentioned in the video.\n- The structure is clear, with each project having its own section and a logical flow.\n- The post is engaging, with a mix of technical details and personal insights.\n- The titles and headers are concise and engaging, fitting the content well.\n\n### Option 2 Analysis:\n\n**Signs of Human Authorship:**\n- The writing in Option 2 is more formal and structured, with less variation in sentence structure and tone.\n- The language is consistent and lacks the informal, personal touches seen in Option 1.\n- The content closely follows the transcript without adding much personal insight or unique perspective, which is more typical of AI-generated content.\n- The post lacks distinctive voice and perspective, focusing more on delivering information in a straightforward manner.\n\n**Content Quality:**\n- The content is relevant and covers the projects mentioned in the transcript.\n- The structure is clear, with each project having its own section.\n- The post is informative but lacks the engaging, personal touch seen in Option 1.\n- The titles and headers are clear but somewhat generic.\n\n### Decision:\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, informal language, and a distinctive voice. Option 2, while well-structured and informative, lacks these human elements and appears more formulaic and consistent, which are common traits of AI-generated content.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "Analyzing both blog posts against the provided criteria and transcript, here are the observations:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing style is formal and structured, with clear sections and steps for each project. This could suggest AI generation due to its formulaic nature.\n  - The language is consistent and lacks personal anecdotes or unique insights beyond the transcript, which is a common trait of AI-generated content.\n  - The sentence structures are predictable and follow a pattern, which is typical of AI writing.\n  - The content closely follows the transcript without adding much personal perspective or domain-specific knowledge not present in the transcript.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the projects mentioned.\n  - The clarity and readability are high, but the engagement level is moderate due to the lack of personal touch.\n  - The structure is appropriate, with clear sections and headers.\n  - The title and headers are concise but lack a distinctive, engaging style.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing includes informal language and personal touches, such as the use of emojis and casual expressions (e.g., \"if I ever get around to it \ud83d\ude05\").\n  - There are personal insights and opinions, such as the mention of the author's own experience with hoarding technical information and helping companies with AI projects.\n  - The sentence structures are varied, and the writing has a more conversational tone, suggesting a human author.\n  - The content includes unique insights and a distinctive voice, which are not directly derived from the transcript.\n\n- **Content Quality:**\n  - The content is relevant and aligns with the video transcript, but it also expands with personal anecdotes and insights.\n  - The clarity and readability are good, with a more engaging and relatable tone.\n  - The structure is well-organized, with clear sections and headers.\n  - The title and headers are engaging and have a natural, human-like style.\n\n**Decision:**\n\nOption 2 shows more characteristics of authentic human writing, with informal language, personal anecdotes, varied sentence structures, and a distinctive voice. These elements suggest a human author, making it the preferred choice.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.5603053435114503, "r": 0.8125461254612546, "f": 0.6632530120481928}, "rouge-2": {"p": 0.3655804480651731, "r": 0.5302806499261448, "f": 0.432790837854129}, "rouge-l": {"p": 0.4259541984732824, "r": 0.6177121771217712, "f": 0.5042168674698794}}, "rouge_scores_B": {"rouge-1": {"p": 0.6956521739130435, "r": 0.42509225092250924, "f": 0.5277141548327989}, "rouge-2": {"p": 0.2418379685610641, "r": 0.14771048744460857, "f": 0.18340210912425492}, "rouge-l": {"p": 0.35507246376811596, "r": 0.21697416974169742, "f": 0.26935409986257447}}}, {"index": 20, "video_id": "rPUytg38b6Q", "answer": "A", "response": "After evaluating both blog posts against the provided transcript and criteria, here is the analysis:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing style includes informal language and personal reactions, such as \"Wow, that so cool!\" and \"As both a musician and physicist, it brings me great joy to find an excuse to merge the two fields.\" These elements suggest a personal touch and unique insights.\n  - The post includes a personal anecdote about applying FFT to a guitar string, which goes beyond the transcript and adds a personal perspective.\n  - The sentence structures are varied, with some informal tangents and expressions of personal opinion.\n  - The post includes domain-specific knowledge, such as the application of FFT in audio production, which wasn't explicitly detailed in the transcript.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript, covering the FFT and its applications.\n  - The post is clear and readable, with engaging elements like personal anecdotes and informal language.\n  - The structure is appropriate, with sections divided into manageable paragraphs.\n  - The title and headers are concise and engaging, with a touch of personality (\"With a teaspoon of intuition\").\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing is more formal and structured, lacking the informal language and personal anecdotes found in Option 1.\n  - The content closely follows the transcript, with little deviation or unique insights.\n  - The sentence structures are more predictable and formulaic, typical of AI-generated content.\n  - The post lacks a distinctive voice or perspective, focusing on generic explanations.\n\n- **Content Quality:**\n  - The content is relevant and covers the FFT comprehensively, but it lacks engagement and personal touch.\n  - The structure is clear, but the language is overly formal and lacks personality.\n  - The title and headers are generic and appear AI-generated, lacking creativity.\n\n**Decision:**\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, informal language, and unique insights that go beyond the transcript. Therefore, the decision is:\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "Based on the evaluation criteria provided, here is the analysis of each blog post:\n\n**Option 1:**\n\n- **Signs of Human Authorship vs. AI Generation:**\n  - The writing is very structured and follows a formulaic approach, which is a common pattern in AI-generated content.\n  - The language is formal and lacks personal anecdotes or unique insights beyond the transcript.\n  - The content is comprehensive and covers the topic exhaustively, which can indicate AI generation.\n  - The sentence structures are consistent and lack the varied, imperfect nature typical of human writing.\n  - The post does not include any personal opinions or distinctive voice, sticking closely to the technical details.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the topic of FFT thoroughly.\n  - The clarity and readability are high, with well-organized sections and clear explanations.\n  - The engagement level is moderate, as the technical nature might not appeal to all readers.\n  - The structure is appropriate, with clear section headers and logical flow.\n  - The title and headers are concise but lack a personal touch or creativity.\n\n**Option 2:**\n\n- **Signs of Human Authorship vs. AI Generation:**\n  - The writing includes informal language and personal reactions, such as \"Wow, that so cool!\" which suggests human authorship.\n  - There are personal insights and connections, like the author's interest in both physics and music, which are not present in the transcript.\n  - The sentence structures are varied, with some tangents and informal expressions that are typical of human writing.\n  - The post includes a distinctive voice and perspective, with personal anecdotes and opinions.\n  - The content goes beyond the transcript by discussing the author's personal experience and insights into the harmonic series.\n\n- **Content Quality:**\n  - The content is relevant and aligns with the video transcript, but it also adds personal insights and examples.\n  - The clarity and readability are good, though the informal style might not suit all readers.\n  - The engagement level is high due to the personal anecdotes and informal tone.\n  - The structure is appropriate, with clear sections and a logical flow.\n  - The title and headers are creative and engaging, reflecting a personal touch.\n\n**Decision:**\n\nBased on the analysis, Option 2 shows more characteristics of authentic human writing, with personal insights, informal language, and a distinctive voice. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.5807174887892377, "r": 0.4926295767950547, "f": 0.5330589143298173}, "rouge-2": {"p": 0.2058328659562535, "r": 0.17459562321598476, "f": 0.1889317889317889}, "rouge-l": {"p": 0.23094170403587444, "r": 0.19591060389919163, "f": 0.21198868021610495}}, "rouge_scores_B": {"rouge-1": {"p": 0.5481220657276995, "r": 0.22206371849738468, "f": 0.31607445008460233}, "rouge-2": {"p": 0.15863689776733256, "r": 0.06422454804947669, "f": 0.091432441584829}, "rouge-l": {"p": 0.24647887323943662, "r": 0.09985734664764621, "f": 0.14213197969543145}}}, {"index": 22, "video_id": "XpoKB3usmKc", "answer": "A", "response": "<option_1> shows more characteristics of authentic human writing.\n\n1. **Signs of Human Authorship vs. AI Generation:**\n   - **Human Authenticity:** \n     - The writing in Option 1 includes informal language and personal insights, such as the author's experiences with hardware limitations and frustrations with running the code on a Mac. This adds a personal touch that is less common in AI-generated content.\n     - The article contains varied sentence structures and occasional tangents, such as the detailed explanation of quantization and the author's personal challenges with specific hardware.\n     - The use of domain-specific knowledge, like the explanation of quantization and the detailed breakdown of QLoRA's components, suggests a deep understanding of the topic that goes beyond the transcript.\n     - The voice is distinctive, with a clear perspective and personal anecdotes, such as the author's experience with Google Colab and the challenges of using certain libraries on different operating systems.\n\n2. **Content Quality:**\n   - The content is highly relevant to the video transcript, expanding on the concepts introduced in the video with additional details and examples.\n   - The structure is appropriate, with clear section headers and a logical flow of information.\n   - The title and section headers are concise and engaging, fitting the content well without appearing AI-generated.\n\nIn contrast, <option_2> shows more signs of AI generation:\n- The language is more formal and lacks the personal touch and distinctive voice found in Option 1.\n- The structure is formulaic, with predictable patterns and a lack of personal anecdotes or unique insights.\n- The content sticks closely to the information in the transcript, without the additional depth or personal perspective seen in Option 1.\n\n<answer>A</answer>", "answer_swapped": "B", "response_swapped": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Personal Insights and Anecdotes:** The author mentions personal experience in data science and entrepreneurship, which adds a personal touch and suggests human authorship.\n- **Distinctive Voice and Perspective:** The writing includes informal language and analogies, such as comparing fine-tuning to refining a diamond, which adds personality and a unique perspective.\n- **Varied Sentence Structures:** The text includes varied sentence lengths and structures, which is less typical of AI-generated content.\n- **Domain-Specific Knowledge:** The author provides insights into CURA and its components, which suggests a deeper understanding beyond the transcript.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant to the video transcript and covers the key points about CURA and fine-tuning.\n- **Clarity and Readability:** The writing is clear and easy to follow, with a logical flow of information.\n- **Engagement:** The use of analogies and personal insights makes the content more engaging.\n- **Structure:** The blog post is well-structured with appropriate section headers.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure:** The post follows a very structured and predictable format, which is common in AI-generated content.\n- **Overly Formal Language:** The language is more formal and lacks the informal, conversational tone that might indicate human authorship.\n- **Exhaustive Lists:** The post includes detailed lists and explanations, which can be indicative of AI trying to cover all bases.\n- **Perfect Grammar and Consistent Tone:** The writing maintains perfect grammar and a consistent tone throughout, which is typical of AI-generated content.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant and covers the topic of QLoRA in detail, aligning with the video transcript.\n- **Clarity and Readability:** The writing is clear, but the exhaustive detail might overwhelm some readers.\n- **Engagement:** The post is informative but lacks the engaging personal touch found in Option 1.\n- **Structure:** The structure is logical, but the headers and sections feel more mechanical.\n\n### Decision:\n\nOption 1 shows more characteristics of authentic human writing, with personal insights, varied sentence structures, and a distinctive voice. Option 2, while technically well-written, exhibits signs of AI authorship, such as a formulaic structure and overly formal language.\n\n<answer>A</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7251296558227251, "r": 0.4478089969427864, "f": 0.5536855368553685}, "rouge-2": {"p": 0.3225654326809715, "r": 0.19918462434478743, "f": 0.24628679449095325}, "rouge-l": {"p": 0.3055162659123055, "r": 0.18867375163779299, "f": 0.23328233282332825}}, "rouge_scores_B": {"rouge-1": {"p": 0.8028846153846154, "r": 0.09724850778861552, "f": 0.1734839631216725}, "rouge-2": {"p": 0.3140794223826715, "r": 0.03800232964472918, "f": 0.06780101311858684}, "rouge-l": {"p": 0.3954326923076923, "r": 0.047896345901878, "f": 0.08544344890273989}}}, {"index": 27, "video_id": "GgLaP4Des1Q", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing includes informal language and a conversational tone, such as \"I may have (once again) gone too far into the mathematical weeds,\" which suggests a human touch.\n- **Personal Anecdotes and Unique Insights:** The author mentions personal involvement and insights, such as \"As always, I will close with a concrete, practical example,\" and \"this is something that that's relevant to my research.\"\n- **Varied Sentence Structures:** The text includes varied sentence lengths and structures, with some longer, more complex sentences and shorter, simpler ones.\n- **Distinctive Voice and Perspective:** The use of first-person pronouns and a personal narrative style gives the post a distinctive voice.\n- **Domain-Specific Knowledge:** The post includes specific insights and examples, such as the \"COVID birthday party problem,\" which are not directly from the transcript.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is highly relevant to the video transcript and covers all important points discussed in the video.\n- **Clarity and Readability:** The post is clear and easy to follow, with well-organized sections.\n- **Engagement and Interest:** The use of personal anecdotes and a conversational tone makes the post engaging.\n- **Structure and Titles:** The structure is appropriate, with concise and engaging section headers.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure and Repetitive Patterns:** The post follows a predictable structure with a formal tone throughout.\n- **Overly Formal and Generic Language:** The language is formal and lacks the personal touch or distinctive voice found in human writing.\n- **Exhaustive Lists and Comprehensive Coverage:** The post covers the topic comprehensively but lacks focus on unique insights or personal experiences.\n- **Information from Transcript:** The content closely follows the information in the transcript without adding much beyond it.\n- **Perfect Grammar and Consistent Tone:** The grammar is perfect, and the tone is consistent, which is typical of AI-generated content.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant and covers the key points from the video.\n- **Clarity and Readability:** The post is clear and well-structured.\n- **Engagement and Interest:** The post is informative but lacks the engaging, personal touch of human writing.\n- **Structure and Titles:** The structure is logical, but the titles and headers are somewhat generic.\n\n### Decision:\n\nBased on the analysis, **Option 1** shows more characteristics of authentic human writing, including personal anecdotes, a distinctive voice, and varied sentence structures. Therefore, the decision is:\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing is formal and structured, with a clear focus on explaining ICA. It lacks informal language or personal anecdotes.\n  - The post includes a personal anecdote about the author's research with EEG data, which adds a human touch.\n  - The sentence structures are varied, but the overall tone is consistent and lacks distinctive personality.\n  - The content is detailed and technical, focusing on the mathematical foundations and applications of ICA, which could suggest domain-specific knowledge.\n  - The post includes a call to action at the end, asking readers about their data analysis challenges, which is a common human writing technique to engage readers.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript, covering ICA, its assumptions, mathematical foundations, and applications.\n  - The structure is logical, with clear sections and headers, but it feels somewhat formulaic.\n  - The title and headers are concise and relevant but lack creativity or a unique voice.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing includes informal language and a conversational tone, such as \"I may have (once again) gone too far into the mathematical weeds,\" which suggests a human touch.\n  - The post references a previous part in a series and includes personal insights, such as the author's experience with EEG data.\n  - The sentence structures are varied, and the tone is more relaxed and personal compared to Option 1.\n  - The content includes unique insights and explanations that go beyond the transcript, such as the \"COVID birthday party problem\" analogy.\n  - The post includes humor and a distinctive voice, which are strong indicators of human authorship.\n\n- **Content Quality:**\n  - The content is relevant and covers the key points of ICA, its assumptions, and a practical example with EEG data.\n  - The structure is clear, with sections that flow logically, and the writing is engaging and easy to read.\n  - The title and headers are straightforward but include a touch of creativity, such as \"Finding hidden factors in data.\"\n\n**Decision:**\n\nOption 2 shows more characteristics of authentic human writing, with informal language, personal anecdotes, humor, and a distinctive voice. These elements suggest a human author, making it the preferred choice.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.5829411764705882, "r": 0.4910802775024777, "f": 0.5330823023130714}, "rouge-2": {"p": 0.2007062978222484, "r": 0.16906296479920674, "f": 0.18353067814854682}, "rouge-l": {"p": 0.23294117647058823, "r": 0.1962338949454906, "f": 0.21301775147928997}}, "rouge_scores_B": {"rouge-1": {"p": 0.6763636363636364, "r": 0.27651139742319125, "f": 0.3925430882870207}, "rouge-2": {"p": 0.21723300970873785, "r": 0.0887456618740704, "f": 0.12601196761703626}, "rouge-l": {"p": 0.3054545454545455, "r": 0.12487611496531219, "f": 0.1772775237425255}}}, {"index": 25, "video_id": "eC6Hd1hFvos", "answer": "B", "response": "Analyzing both blog posts against the provided transcript, here are the observations:\n\n**Option 1:**\n\n- **Signs of Human Authorship vs. AI Generation:**\n  - The writing is highly structured and follows a formulaic pattern, which is a common trait of AI-generated content.\n  - The language is formal and lacks personal anecdotes or unique insights beyond the transcript.\n  - The content strictly adheres to the information provided in the transcript, with no additional domain-specific knowledge or personal perspective.\n  - The sentence structures are consistent and lack the varied, imperfect nature typical of human writing.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the key points discussed.\n  - The clarity and readability are high, but the engagement level is low due to the lack of a distinctive voice.\n  - The structure is appropriate, with clear sections and headers, but the title and headers are somewhat generic and could be AI-generated.\n\n**Option 2:**\n\n- **Signs of Human Authorship vs. AI Generation:**\n  - The writing includes informal language and a conversational tone, which suggests human authorship.\n  - There are personal insights and analogies, such as comparing fine-tuning to polishing a diamond, which go beyond the transcript.\n  - The sentence structures are varied, and the content includes some tangential thoughts, adding to the authenticity.\n  - The post includes a call to action and personal engagement with the reader, which is more characteristic of human writing.\n\n- **Content Quality:**\n  - The content is relevant and covers the main points from the transcript while adding additional context and examples.\n  - The clarity and readability are good, with engaging language that maintains reader interest.\n  - The structure is well-organized, with concise and engaging titles and headers that do not appear AI-generated.\n\n**Decision:**\n\nBased on the analysis, **Option 2** shows more characteristics of authentic human writing, with informal language, personal insights, and a distinctive voice. Therefore, the decision is:\n\n<answer>B</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's analyze each option based on the given criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- The writing style is formal and structured, with clear sections and headers. This could suggest AI generation, as it follows a formulaic structure.\n- The language is consistently formal and lacks personal anecdotes or unique insights beyond the transcript, which is a common trait of AI-generated content.\n- The content is comprehensive and covers all aspects of fine-tuning, but it lacks any personal touch or distinctive voice.\n- The use of domain-specific knowledge is present, but it closely follows the information provided in the transcript, without additional insights or opinions.\n\n**Content Quality:**\n- The content is relevant to the video transcript and covers the topic of fine-tuning large language models thoroughly.\n- The clarity and readability are high, with well-organized sections and logical flow.\n- The engagement level is moderate, as the content is informative but lacks a personal or engaging tone.\n- The structure is appropriate, with sections divided into clear paragraphs and headers.\n\n### Option 2 Analysis:\n\n**Signs of Human Authorship:**\n- The writing includes informal language and a more conversational tone, which suggests human authorship.\n- There are references to personal experiences, such as the mention of this being the 5th article in a series, which adds a personal touch.\n- The sentence structures are varied, and there are occasional tangents, such as the explanation of LoRA and its benefits, which are not strictly necessary but add depth.\n- The content includes unique insights and explanations that go beyond the transcript, such as the detailed explanation of LoRA and its application.\n\n**Content Quality:**\n- The content is relevant and aligns well with the video transcript, providing a conceptual overview and example code.\n- The clarity and readability are good, with a balance between technical details and accessible explanations.\n- The engagement level is higher due to the conversational tone and inclusion of personal insights.\n- The structure is logical, with sections divided into clear paragraphs and headers, though it is less rigid than Option 1.\n\n### Decision:\n\nOption 2 shows more characteristics of authentic human writing, with a conversational tone, personal insights, and varied sentence structures. It includes informal language and occasional tangents, which are indicative of human authorship. Therefore, Option 2 is more likely written by a human.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.773497688751926, "r": 0.09211009174311927, "f": 0.1646171503525168}, "rouge-2": {"p": 0.3425925925925926, "r": 0.04074142044411819, "f": 0.07282269968837134}, "rouge-l": {"p": 0.4268104776579353, "r": 0.05082568807339449, "f": 0.09083456304312182}}, "rouge_scores_B": {"rouge-1": {"p": 0.7910447761194029, "r": 0.12642201834862385, "f": 0.2180034804619522}, "rouge-2": {"p": 0.3264367816091954, "r": 0.05211965498256561, "f": 0.0898876404494382}, "rouge-l": {"p": 0.3788748564867968, "r": 0.060550458715596334, "f": 0.10441385856668249}}}, {"index": 1, "video_id": "wJ794jLP2Tw", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's analyze each option based on the given criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The writing includes informal language and a conversational tone, such as the anecdote about Andrej Karpathy's \"Operation Vacation\" and the author's personal experience with Airflow.\n- **Personal Anecdotes and Opinions:** The post includes a personal anecdote about a grad student, which adds a human touch and is not directly related to the technical content.\n- **Varied Sentence Structures:** The sentence structures vary, with some longer, more complex sentences and shorter, more direct ones.\n- **Distinctive Voice and Perspective:** The author shares personal insights and experiences, such as the challenges of learning Airflow and the benefits of GitHub Actions for \"poor developers.\"\n- **Domain-Specific Knowledge:** The post includes specific insights into the use of orchestration tools and GitHub Actions, suggesting a deeper understanding beyond the transcript.\n\n**Content Quality:**\n- **Relevance to Video Content:** The post closely follows the video content, expanding on the automation of data pipelines.\n- **Clarity and Readability:** The content is clear and easy to follow, with logical progression and explanations.\n- **Engagement and Reader Interest:** The use of anecdotes and personal insights makes the content engaging.\n- **Completeness of Important Points:** The post covers all major points from the video, including the use of orchestration tools and GitHub Actions.\n- **Factual Accuracy:** The technical details are accurate and align with the video content.\n- **Appropriate Structure:** The structure is well-organized, with clear sections and headers.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure and Repetitive Patterns:** The post follows a predictable structure with clear, segmented sections and headers.\n- **Overly Formal, Safe, or Generic Language:** The language is formal and lacks the personal touch or informal tone found in human writing.\n- **Exhaustive Lists and Comprehensive Coverage:** The post covers the topic comprehensively but lacks focus on unique insights or personal experiences.\n- **Only Information Explicitly Stated in the Transcript:** The content closely mirrors the transcript without adding new perspectives or anecdotes.\n- **Perfect Grammar and Consistent Tone:** The grammar is flawless, and the tone is consistent throughout, which is typical of AI-generated content.\n- **Generic, Predictable Titles and Headers:** The titles and headers are straightforward and lack creativity or personality.\n\n**Content Quality:**\n- **Relevance to Video Content:** The post is relevant and aligns with the video content.\n- **Clarity and Readability:** The content is clear and easy to read, with a logical flow.\n- **Engagement and Reader Interest:** The post is informative but lacks engaging elements like personal stories or opinions.\n- **Completeness of Important Points:** The post covers the key points from the video.\n- **Factual Accuracy:** The technical details are accurate.\n- **Appropriate Structure:** The structure is clear and organized, with distinct sections.\n\n### Decision:\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, varied sentence structures, and a distinctive voice. Option 2, while well-written, exhibits signs of AI authorship, such as a formulaic structure and lack of personal insights. Therefore, Option 1 is more likely written by a human.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1: Automating Data Pipelines with GitHub Actions\n\n**Signs of Human Authorship:**\n- The writing is structured and clear, but it lacks personal anecdotes or unique insights beyond the technical explanation.\n- The language is formal and consistent, with no informal language or tangents that might suggest a human touch.\n- The content is highly focused on technical details, with no personal opinions or experiences shared.\n- The sentence structures are somewhat varied but follow a predictable pattern typical of technical documentation.\n- The post sticks closely to the information that could be derived from the transcript, with no additional domain-specific knowledge or insights.\n\n**Content Quality:**\n- The content is relevant and accurately reflects the video transcript.\n- The structure is logical, with clear sections and steps.\n- The title and headers are concise and relevant but lack a distinctive or engaging style.\n- The post is complete and covers the necessary steps for automating data pipelines using GitHub Actions.\n\n### Option 2: Automating Data Pipelines with Python & GitHub Actions\n\n**Signs of Human Authorship:**\n- The post includes personal anecdotes, such as the reference to Andrej Karpathy's \"Operation Vacation,\" which adds a personal touch and context.\n- The writing style is more informal and conversational, with occasional humor (e.g., \"so they can go on vacation\").\n- The author references previous articles and provides links, indicating a broader context and personal involvement in the topic.\n- The language is less formal and more varied, with a distinctive voice that suggests a human perspective.\n- The post includes opinions and insights, such as the discussion on the complexity of Airflow and the practicality of using GitHub Actions for certain projects.\n\n**Content Quality:**\n- The content is relevant and aligns well with the video transcript.\n- The structure is clear, with logical sections and engaging headers.\n- The post is engaging, with a narrative style that maintains reader interest.\n- The information is accurate and complete, covering the key points of automating data pipelines.\n- The title and headers are concise and engaging, with a natural-sounding style.\n\n### Conclusion\n\nOption 2 shows more characteristics of authentic human writing, with personal anecdotes, a conversational tone, and unique insights that go beyond the transcript. The writing style is less formal and more varied, suggesting a human author. Therefore, Option 2 is more likely to be written by a human.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7570175438596491, "r": 0.303179343052872, "f": 0.43296124419917226}, "rouge-2": {"p": 0.32338745063624397, "r": 0.12947997189037244, "f": 0.1849203362187931}, "rouge-l": {"p": 0.3030701754385965, "r": 0.1213771298085368, "f": 0.1733350056440487}}, "rouge_scores_B": {"rouge-1": {"p": 0.8331242158092849, "r": 0.11663446337607589, "f": 0.20462249614791989}, "rouge-2": {"p": 0.31155778894472363, "r": 0.04356992269852424, "f": 0.07644882860665844}, "rouge-l": {"p": 0.4077791718946048, "r": 0.05708765150184437, "f": 0.10015408320493066}}}, {"index": 7, "video_id": "WqASiuM4a-A", "answer": "A", "response": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1: Causality: An Introduction\n\n**Signs of Human Authorship:**\n- **Imperfect but Natural Writing:** The post includes informal language and a humorous tangent about a banana, which adds a personal touch and breaks the formal tone often seen in AI-generated content.\n- **Personal Anecdotes and Unique Insights:** The author uses a personal voice, evident in the banana anecdote and the conversational tone (\"I know what you\u2019re thinking.. why is there a picture of a banana here?\").\n- **Varied Sentence Structures:** The writing style varies, with a mix of short and long sentences, and the use of rhetorical questions adds a dynamic flow.\n- **Distinctive Voice and Perspective:** The post has a distinctive voice, with humor and a casual tone that suggests a human touch.\n- **Domain-Specific Knowledge:** The post references specific examples and sources not explicitly mentioned in the transcript, such as the Tyler Vigen website and the Judea Pearl quote, indicating additional research and understanding.\n\n**Content Quality:**\n- **Relevance and Completeness:** The post covers the main points from the transcript and expands on them with additional examples and explanations.\n- **Engagement and Reader Interest:** The use of humor and rhetorical questions engages the reader and maintains interest.\n- **Appropriate Structure:** The post is well-structured with clear sections and headers, though it occasionally uses longer paragraphs.\n\n### Option 2: Understanding Causality: A New Perspective on Data Science\n\n**Signs of AI Authorship:**\n- **Formulaic Structure and Repetitive Patterns:** The post follows a predictable structure with clear sections and headers, which is typical of AI-generated content.\n- **Overly Formal and Generic Language:** The language is formal and lacks the personal touch or humor seen in Option 1.\n- **Exhaustive Lists and Comprehensive Coverage:** The post covers the topics in a comprehensive manner but lacks focus on unique insights or personal anecdotes.\n- **Perfect Grammar and Consistent Tone:** The writing is grammatically perfect and maintains a consistent tone throughout, which is often a sign of AI generation.\n- **Generic Observations:** The content sticks closely to the transcript without adding much personal insight or unique perspective.\n\n**Content Quality:**\n- **Relevance and Clarity:** The post is relevant and clear, summarizing the transcript effectively.\n- **Engagement and Reader Interest:** While informative, the post lacks the engaging elements and personal voice that make Option 1 more interesting.\n- **Appropriate Structure:** The structure is clear and concise, with well-defined sections and headers.\n\n### Decision\n\nOption 1 shows more characteristics of authentic human writing, with its informal language, personal anecdotes, varied sentence structures, and distinctive voice. These elements suggest a human author who is engaging with the content in a personal and creative way. In contrast, Option 2 exhibits signs of AI authorship, such as a formulaic structure and a lack of personal touch.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "After evaluating both blog posts against the provided transcript and criteria, here is the analysis:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing is formal and structured, with a clear and predictable pattern. It lacks informal language or personal anecdotes.\n  - The content closely follows the transcript, with little deviation or unique insights beyond what is explicitly stated.\n  - The sentence structures are consistent and lack the varied, imperfect nature typical of human writing.\n  - The voice is generic, focusing on delivering information rather than offering a distinctive perspective.\n  - There is no use of domain-specific knowledge that wasn't in the transcript.\n\n- **Content Quality:**\n  - The content is relevant to the video and covers the main points clearly.\n  - The structure is logical, with appropriate section headers.\n  - The title and headers are informative but lack creativity or engagement.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing includes informal language and humor, such as the banana anecdote, which is not in the transcript.\n  - There are personal touches and a conversational tone, suggesting a human touch.\n  - The sentence structures are varied, with some tangents and informal expressions.\n  - The voice is distinctive, with a playful and engaging style.\n  - The post includes unique insights and examples, such as the banana analogy, which are not in the transcript.\n\n- **Content Quality:**\n  - The content is relevant and covers the main points from the video.\n  - The structure is clear, with engaging section headers.\n  - The title and headers are creative and engaging, adding to reader interest.\n\n**Decision:**\n\nOption 2 shows more characteristics of authentic human writing, with its informal language, personal anecdotes, and distinctive voice. It deviates from the transcript in a way that suggests a human author added unique insights and humor. Therefore, the decision is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.4519005161895824, "r": 0.7317629179331308, "f": 0.5587467362924283}, "rouge-2": {"p": 0.18779342723004694, "r": 0.3041825095057034, "f": 0.23222060957910012}, "rouge-l": {"p": 0.22430783669638668, "r": 0.36322188449848025, "f": 0.27734261676820426}}, "rouge_scores_B": {"rouge-1": {"p": 0.6601671309192201, "r": 0.3601823708206687, "f": 0.46607669616519176}, "rouge-2": {"p": 0.2203626220362622, "r": 0.12015209125475285, "f": 0.15551181102362205}, "rouge-l": {"p": 0.33147632311977715, "r": 0.18085106382978725, "f": 0.23402163225172076}}}, {"index": 16, "video_id": "sxvyBxLVvKs", "answer": "A", "response": "After evaluating both blog posts against the provided transcript and criteria, here is the analysis:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing includes personal anecdotes and insights, such as the author's experience in grad school and their journey from being an overly technical physics grad student to a praised communicator. This adds a personal touch that is characteristic of human writing.\n  - The use of informal language and phrases like \"If I can do it, you can too\" suggests a more conversational and personal tone.\n  - The writing style includes varied sentence structures and occasional tangents, such as the mention of the author's YouTube and Medium success, which are not directly related to the main topic but add depth and personality.\n  - The article includes domain-specific knowledge and examples that go beyond the transcript, such as the detailed explanation of storytelling structures and the use of specific examples and analogies.\n  \n- **Content Quality:**\n  - The content is relevant to the video transcript and expands on the points discussed in the video.\n  - The article is engaging and maintains reader interest through personal stories and practical tips.\n  - The structure is appropriate, with clear section headers and concise paragraphs.\n  - The title and section headers are engaging and do not appear AI-generated.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The writing is more formal and lacks the personal anecdotes and informal language found in Option 1.\n  - The content closely follows the transcript without adding much personal insight or unique perspective.\n  - The sentence structures are more predictable and formulaic, which is a common pattern in AI-generated content.\n  - The article lacks a distinctive voice and feels more generic compared to Option 1.\n\n- **Content Quality:**\n  - The content is relevant and covers the points from the transcript, but it lacks the engagement and personal touch found in Option 1.\n  - The structure is clear, but the language is more formal and less engaging.\n  - The title and section headers are straightforward but lack the creativity and personality seen in Option 1.\n\n**Decision:**\n\nBased on the analysis, Option 1 shows more characteristics of authentic human writing, with personal anecdotes, varied sentence structures, and a distinctive voice. Option 2, while well-structured, lacks the personal touch and varied writing style that suggest human authorship.\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "After evaluating both blog posts against the provided transcript and criteria, here is the analysis:\n\n**Option 1:**\n- **Signs of Human Authorship:**\n  - The writing is polished and follows a structured, formulaic approach, which is typical of AI-generated content.\n  - The language is formal and lacks personal anecdotes or unique insights beyond the transcript.\n  - The content closely mirrors the transcript, with little deviation or additional personal perspective.\n  - The sentence structures are consistent and predictable, lacking the varied sentence structures that might indicate human authorship.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the key points discussed.\n  - The structure is clear, with numbered lists and sections that align with the tips mentioned in the transcript.\n  - The title and section headers are concise and relevant but lack a distinctive, engaging voice.\n\n**Option 2:**\n- **Signs of Human Authorship:**\n  - The writing includes personal anecdotes, such as the author's experience in grad school and their journey in improving communication skills.\n  - There is a distinctive voice and perspective, with informal language and expressions like \"IMO\" (in my opinion) and \"If I can do it, you can too.\"\n  - The content includes unique insights and reflections that go beyond the transcript, such as the mention of empathy and knowing the audience.\n  - The sentence structures are varied, with a mix of short and long sentences, and occasional tangents that add a natural flow to the writing.\n\n- **Content Quality:**\n  - The content is relevant and covers the key points from the transcript while adding personal insights and experiences.\n  - The structure is clear, with numbered tips and sections that are easy to follow.\n  - The title and section headers are engaging and reflect a personal touch, making them more likely to capture reader interest.\n\n**Decision:**\nOption 2 shows more characteristics of authentic human writing, with personal anecdotes, a distinctive voice, and varied sentence structures. Therefore, the blog post that was likely written by a human is:\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7073170731707317, "r": 0.5181006111894687, "f": 0.598100407055631}, "rouge-2": {"p": 0.2742453436095055, "r": 0.20084666039510818, "f": 0.2318761878903068}, "rouge-l": {"p": 0.27599486521181, "r": 0.20216267042783262, "f": 0.2333785617367707}}, "rouge_scores_B": {"rouge-1": {"p": 0.6844396082698585, "r": 0.29572167371885283, "f": 0.41300065659881807}, "rouge-2": {"p": 0.2233115468409586, "r": 0.09642521166509878, "f": 0.13469119579500657}, "rouge-l": {"p": 0.2916213275299238, "r": 0.12599905970850964, "f": 0.17596848325673015}}}, {"index": 8, "video_id": "Ylz779Op9Pw", "answer": "A", "response": "Analyzing both blog posts, here are the observations:\n\n**Option 1:**\n\n- **Signs of Human Authorship:**\n  - The writing includes personal anecdotes and references to previous work, such as the mention of fine-tuning Mistral-7b-Instruct and capturing the author's style.\n  - The post contains informal language and a conversational tone, especially in sections where the author discusses their personal experiences and insights.\n  - There are reasonable tangents, such as the discussion on the limitations of LLMs and the author's personal journey in data science.\n  - The structure is not overly formulaic, with varied sentence structures and a distinctive voice.\n  - The use of domain-specific knowledge, such as the mention of specific models and libraries, goes beyond the transcript.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and expands on the topic with additional insights.\n  - The post is clear and readable, with engaging sections that maintain reader interest.\n  - The structure is appropriate, with sections broken down into manageable paragraphs.\n  - The title and headers are concise and engaging, fitting the content well.\n\n**Option 2:**\n\n- **Signs of AI Authorship:**\n  - The writing is more formal and lacks the personal touch and distinctive voice found in human writing.\n  - The structure is formulaic, with predictable patterns and comprehensive coverage that lacks focus.\n  - The language is safe and generic, without the informal nuances or personal insights.\n  - The content sticks closely to the information in the transcript, without adding unique perspectives or anecdotes.\n  - The grammar is consistently perfect, which is a common trait of AI-generated content.\n\n- **Content Quality:**\n  - The content is relevant and covers the topic thoroughly, but it lacks engagement and a personal touch.\n  - The structure is clear, but the sections feel more like a technical manual than a blog post.\n  - The title and headers are straightforward but lack creativity and engagement.\n\n**Decision:**\n\nBased on the analysis, **Option 1** shows more characteristics of authentic human writing, with personal anecdotes, a conversational tone, and a distinctive voice. **Option 2** appears to be AI-generated due to its formal, formulaic structure and lack of personal insights.\n\n<answer>A</answer>", "answer_swapped": "B", "response_swapped": "To determine which blog post is more likely written by a human, let's evaluate each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Personal Anecdotes and Insights:** The author shares a personal experience about encountering limitations when fine-tuning a model to respond to YouTube comments, which led them to explore RAG. This personal touch suggests human authorship.\n- **Distinctive Voice and Perspective:** The writing includes a personal journey and insights, such as the author's experience in data science and entrepreneurship, which adds a unique perspective.\n- **Varied Sentence Structures:** The writing style is varied, with a mix of technical explanations and personal reflections, which feels natural and less formulaic.\n- **Domain-Specific Knowledge:** The post includes specific insights about the challenges of fine-tuning models and the benefits of RAG, which go beyond the transcript.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant to the video and covers the topic of RAG comprehensively, including practical implementation steps.\n- **Clarity and Engagement:** The writing is clear and engaging, with a logical flow and practical examples.\n- **Structure and Headers:** The structure is well-organized with appropriate headers, and the title is concise and engaging.\n\n### Option 2 Analysis:\n\n**Signs of AI Authorship:**\n- **Formulaic Structure:** The post follows a very structured and predictable format, with clear sections and exhaustive coverage, which is typical of AI-generated content.\n- **Lack of Personal Touch:** The writing lacks personal anecdotes or unique insights, focusing solely on the technical aspects of RAG.\n- **Consistent Tone and Perfect Grammar:** The tone is consistent and formal throughout, with perfect grammar, which is often a sign of AI writing.\n- **Generic Observations:** The content sticks closely to the information in the transcript without adding new perspectives or insights.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant and covers the topic thoroughly, but it lacks the depth and engagement of a human perspective.\n- **Clarity and Engagement:** While clear, the writing is less engaging due to its formal and structured nature.\n- **Structure and Headers:** The structure is clear, but the headers and title are somewhat generic and lack creativity.\n\n### Decision:\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, a distinctive voice, and varied sentence structures. The inclusion of personal experiences and insights adds depth and authenticity to the content, which is less evident in Option 2.\n\n<answer>A</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.6405683192261185, "r": 0.5471210947585851, "f": 0.5901685002088845}, "rouge-2": {"p": 0.2809192621711521, "r": 0.23992768595041322, "f": 0.25881041927845105}, "rouge-l": {"p": 0.28869407496977023, "r": 0.24657887942163698, "f": 0.26597966856983707}}, "rouge_scores_B": {"rouge-1": {"p": 0.7688172043010753, "r": 0.18461141234185385, "f": 0.2977305850510098}, "rouge-2": {"p": 0.3186221743810549, "r": 0.07644628099173553, "f": 0.12330764424078315}, "rouge-l": {"p": 0.36236559139784946, "r": 0.08701265169119546, "f": 0.1403289610660004}}}, {"index": 21, "video_id": "xm9devSQEqU", "answer": "A", "response": "After evaluating both blog posts against the provided transcript and criteria, here is the analysis:\n\n**Option 1:**\n\n- **Signs of Human Authorship:**\n  - The writing includes personal anecdotes and opinions, such as the author's experience interviewing data science freelancers and their personal journey toward becoming a full-stack data scientist.\n  - The language is informal and conversational at times, with phrases like \"IMO\" (in my opinion) and \"learn enough to be dangerous.\"\n  - The article includes unique insights and reflections, such as the author's realization about the value of learning the full tech stack.\n  - There are varied sentence structures and a distinctive voice, particularly in sections where the author shares personal experiences and insights.\n  - The article references specific past articles and invites reader interaction, which suggests a personal touch.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and expands on the concepts discussed.\n  - The structure is clear, with well-defined sections and headers.\n  - The writing is engaging, with a mix of technical information and personal insights.\n  - The title and section headers are concise and engaging, fitting the content well.\n\n**Option 2:**\n\n- **Signs of AI Generation:**\n  - The writing is more formal and structured, with a comprehensive and exhaustive approach that lacks personal anecdotes or unique insights.\n  - The language is consistent and lacks the informal, conversational tone seen in Option 1.\n  - The article follows a predictable pattern, with each section methodically covering the same points without deviation or personal reflection.\n  - The content closely mirrors the transcript without adding much beyond what is explicitly stated.\n  - The title and section headers are generic and appear AI-generated, focusing on comprehensive coverage rather than engagement.\n\n- **Content Quality:**\n  - The content is relevant and covers the key points from the transcript.\n  - The structure is logical, but the writing lacks engagement and personality.\n  - The article is clear and factual but lacks the distinctive voice and perspective seen in Option 1.\n\n**Decision:**\n\nOption 1 shows more characteristics of authentic human writing, with personal anecdotes, informal language, and unique insights that go beyond the transcript. Therefore, the decision is:\n\n<answer>A</answer>", "answer_swapped": "A", "response_swapped": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis:\n\n**Signs of Human Authorship:**\n- **Personal Insights and Anecdotes:** The post includes personal reflections, such as the author's realization about the value of learning the entire tech stack and their journey toward becoming a full stack data scientist. This adds a personal touch that is less common in AI-generated content.\n- **Distinctive Voice and Perspective:** The author shares their own principles for learning, such as \"Have a Reason to Learn\" and \"Learn Just Enough to Be Dangerous,\" which suggests a personal approach and philosophy.\n- **Varied Sentence Structures:** The writing includes a mix of sentence lengths and structures, which contributes to a more natural flow.\n- **Domain-Specific Knowledge:** The post goes beyond the transcript by discussing specific tools and skills in detail, such as Airflow, Docker, and FastAPI, which indicates a deeper understanding of the subject.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is highly relevant to the video transcript and covers all the important points discussed in the video.\n- **Engagement and Interest:** The use of personal insights and reflections makes the content more engaging.\n- **Structure and Clarity:** The post is well-structured with clear section headers and concise paragraphs.\n\n### Option 2 Analysis:\n\n**Signs of Human Authorship:**\n- **Personal Insights and Anecdotes:** The author shares their experience of interviewing data science freelancers and the insights gained from those interviews, which adds a personal dimension.\n- **Distinctive Voice and Perspective:** The post includes the author's opinions, such as the notion that FSDS may seem outdated but is still valuable, which suggests a personal viewpoint.\n- **Varied Sentence Structures:** The writing includes informal language and varied sentence structures, contributing to a natural flow.\n- **Domain-Specific Knowledge:** The post discusses specific contexts where FSDS is beneficial, such as SMBs and lone AI contributors, which indicates a nuanced understanding of the field.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant to the video transcript and covers the key points discussed in the video.\n- **Engagement and Interest:** The use of personal anecdotes and insights makes the content more engaging.\n- **Structure and Clarity:** The post is well-structured with clear section headers and concise paragraphs.\n\n### Decision:\n\nBoth options exhibit signs of human authorship, but Option 2 includes more personal anecdotes and insights, such as the author's experience with interviewing freelancers and their evolving perspective on FSDS. These elements suggest a more authentic human writing style. Therefore, based on the criteria of human authenticity and content quality, Option 2 is more likely to be written by a human.\n\n<answer>B</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.7911392405063291, "r": 0.38504620554466534, "f": 0.5179883217178377}, "rouge-2": {"p": 0.3494530800230282, "r": 0.1700280112044818, "f": 0.22875447522140568}, "rouge-l": {"p": 0.3457997698504028, "r": 0.16830019602352284, "f": 0.226407986438124}}, "rouge_scores_B": {"rouge-1": {"p": 0.837, "r": 0.234388126575189, "f": 0.3662218332968716}, "rouge-2": {"p": 0.38538538538538536, "r": 0.10784313725490197, "f": 0.16852702998467936}, "rouge-l": {"p": 0.427, "r": 0.11957434892187062, "f": 0.18683001531393567}}}, {"index": 29, "video_id": "mj86XmfOniY", "answer": "B", "response": "Analyzing both blog posts against the provided transcript, here are the observations:\n\n**Option 1:**\n\n- **Human Authenticity:**\n  - The writing style is quite formal and structured, with clear sections and headers. It lacks personal anecdotes or unique insights beyond the transcript.\n  - The content closely follows the transcript, with little deviation or additional personal input.\n  - The sentence structures are consistent and somewhat predictable, lacking the varied sentence structures typical of human writing.\n  - The voice is generic and lacks a distinctive personal perspective.\n  - There is no use of domain-specific knowledge that wasn't explicitly in the transcript.\n\n- **Content Quality:**\n  - The content is relevant to the video transcript and covers the main points discussed.\n  - The clarity and readability are good, but the engagement level is moderate due to the lack of personal touch.\n  - The structure is appropriate, with sections divided into paragraphs.\n  - The title and headers are clear but lack creativity and engagement.\n\n**Option 2:**\n\n- **Human Authenticity:**\n  - The post begins with a personal anecdote about being a physics PhD student, which adds a personal touch and context.\n  - The writing includes personal opinions and insights, such as the mention of being a musician and using Fourier Transforms in research.\n  - The sentence structures are varied, with a mix of complex and simple sentences, and the tone is more conversational.\n  - The voice is distinctive, with a clear personal perspective and engagement with the reader.\n  - There is a use of domain-specific knowledge, such as the mention of EEG signal analysis and personal research experiences, which were not explicitly in the transcript.\n\n- **Content Quality:**\n  - The content is relevant and covers the main points of the transcript while adding additional insights and examples.\n  - The clarity and readability are high, with engaging language and a conversational tone.\n  - The structure is well-organized, with clear sections and engaging headers.\n  - The title and headers are creative and engaging, inviting the reader to explore further.\n\n**Decision:**\n\nBased on the analysis, **Option 2** shows more characteristics of authentic human writing, with personal anecdotes, varied sentence structures, and a distinctive voice. Therefore, the decision is:\n\n<answer>B</answer>", "answer_swapped": "B", "response_swapped": "To determine which blog post is more likely written by a human, let's analyze each option based on the provided criteria.\n\n### Option 1 Analysis\n\n**Signs of Human Authorship:**\n- **Personal Anecdotes and Insights:** The author mentions being a physics PhD student at the University of Texas at Dallas and shares personal experiences with mathematical concepts in research. This personal touch suggests human authorship.\n- **Distinctive Voice and Perspective:** The post includes a personal invitation to readers to join future explorations of related topics, which adds a personal touch and a sense of journey.\n- **Varied Sentence Structures:** The writing includes varied sentence structures and informal language, such as \"Are you ready to unlock the potential of your data through the lens of the Fourier Transform? Let's embark on this journey together!\" This suggests a more natural, human-like writing style.\n- **Domain-Specific Knowledge:** The post includes insights into practical applications of the Fourier Transform, such as EEG signal analysis and light spectrum analysis, which go beyond the transcript.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant to the video transcript and covers important points about the Fourier Transform.\n- **Engagement and Reader Interest:** The use of personal anecdotes and future promises of more content engages the reader.\n- **Structure and Clarity:** The post is well-structured with clear section headers and concise paragraphs.\n\n### Option 2 Analysis\n\n**Signs of AI Authorship:**\n- **Formulaic Structure and Repetitive Patterns:** The post follows a predictable structure with exhaustive lists and comprehensive coverage, which is typical of AI-generated content.\n- **Lack of Personal Touch:** The writing lacks personal anecdotes or unique insights, focusing instead on generic explanations.\n- **Consistent Tone and Perfect Grammar:** The tone is consistent and formal throughout, with perfect grammar, which is often a sign of AI writing.\n- **Generic Observations:** The content sticks closely to the information in the transcript without adding new insights or perspectives.\n\n**Content Quality:**\n- **Relevance and Completeness:** The content is relevant and covers the main points from the transcript.\n- **Clarity and Readability:** The post is clear and easy to read, but it lacks engagement due to its formal tone.\n- **Structure:** The structure is appropriate, but the headers and content lack the engaging and natural-sounding quality of human writing.\n\n### Decision\n\nBased on the analysis, **Option 1** shows more characteristics of authentic human writing, with personal anecdotes, varied sentence structures, and a distinctive voice. **Option 2** exhibits signs of AI authorship, such as a formulaic structure and lack of personal touch.\n\n<answer>A</answer>", "rouge_scores_A": {"rouge-1": {"p": 0.5227513227513227, "r": 0.3847352024922118, "f": 0.44324809331538806}, "rouge-2": {"p": 0.1472457627118644, "r": 0.1083398285268901, "f": 0.12483161203412661}, "rouge-l": {"p": 0.20423280423280424, "r": 0.15031152647975077, "f": 0.1731718259309107}}, "rouge_scores_B": {"rouge-1": {"p": 0.6272727272727273, "r": 0.32242990654205606, "f": 0.42592592592592593}, "rouge-2": {"p": 0.2276176024279211, "r": 0.11691348402182385, "f": 0.1544799176107106}, "rouge-l": {"p": 0.30303030303030304, "r": 0.1557632398753894, "f": 0.205761316872428}}}]